{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3avFd2Po30"
      },
      "source": [
        "# **QA System with BeerQA Dataset**\n",
        "In this notebook we are going to explore the [beerqa](https://beerqa.github.io/) dataset, an open-domain question answering dataset that features questions requiring information from one or more Wikipedia documents to answer. In addition to the exploration, we are also goinig to build some QA models.\n",
        "Authors:\n",
        "* Rustam ALIYEV\n",
        "* Vlada PRIKHODCHENKO\n",
        "* Fabio CABECCIA\n",
        "* Filippo SARTORI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:21:31.457736Z",
          "iopub.status.busy": "2024-05-26T12:21:31.457458Z",
          "iopub.status.idle": "2024-05-26T12:21:46.253242Z",
          "shell.execute_reply": "2024-05-26T12:21:46.252190Z",
          "shell.execute_reply.started": "2024-05-26T12:21:31.457710Z"
        },
        "id": "Tes196i7Po31",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import copy\n",
        "import nltk\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from tabulate import tabulate\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
        "from sklearn.cluster import DBSCAN\n",
        "from pandas.core.common import flatten\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:14:53.427930Z",
          "iopub.status.busy": "2024-05-26T12:14:53.427551Z",
          "iopub.status.idle": "2024-05-26T12:14:53.652972Z",
          "shell.execute_reply": "2024-05-26T12:14:53.652089Z",
          "shell.execute_reply.started": "2024-05-26T12:14:53.427894Z"
        },
        "id": "yvE8vGzj2s2b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:21:57.395115Z",
          "iopub.status.busy": "2024-05-26T12:21:57.394253Z",
          "iopub.status.idle": "2024-05-26T12:21:57.399370Z",
          "shell.execute_reply": "2024-05-26T12:21:57.398215Z",
          "shell.execute_reply.started": "2024-05-26T12:21:57.395085Z"
        },
        "id": "rozvtPlKRD-0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "seed = 42\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:14:53.661175Z",
          "iopub.status.busy": "2024-05-26T12:14:53.660875Z",
          "iopub.status.idle": "2024-05-26T12:14:53.670085Z",
          "shell.execute_reply": "2024-05-26T12:14:53.668979Z",
          "shell.execute_reply.started": "2024-05-26T12:14:53.661152Z"
        },
        "id": "KWASE6VtOK81",
        "outputId": "d1a7ed8c-b9fc-43a3-e1b4-61ac6e771ddf",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEa5tSFKSNqX"
      },
      "source": [
        "# Preliminary Analysis\n",
        "# *Data Loading*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6tzmNY5yb3k"
      },
      "source": [
        "If you're using Kaggle platform please make sure this flag is True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:22:00.207657Z",
          "iopub.status.busy": "2024-05-26T12:22:00.207310Z",
          "iopub.status.idle": "2024-05-26T12:22:00.211894Z",
          "shell.execute_reply": "2024-05-26T12:22:00.210754Z",
          "shell.execute_reply.started": "2024-05-26T12:22:00.207631Z"
        },
        "id": "pU6LZ01UbGSC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "KAGGLE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:22:01.620978Z",
          "iopub.status.busy": "2024-05-26T12:22:01.620630Z",
          "iopub.status.idle": "2024-05-26T12:22:05.401405Z",
          "shell.execute_reply": "2024-05-26T12:22:05.400641Z",
          "shell.execute_reply.started": "2024-05-26T12:22:01.620952Z"
        },
        "id": "TEKIcRE6Po32",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "if not KAGGLE:\n",
        "    with open('/content/gdrive/MyDrive/beerqa/beerqa_train_v1.0.json') as f:\n",
        "        json_train = json.load(f)\n",
        "    with open('/content/gdrive/MyDrive/beerqa/beerqa_dev_v1.0.json') as f:\n",
        "        json_dev = json.load(f)\n",
        "    with open('/content/gdrive/MyDrive/beerqa/beerqa_test_questions_v1.0.json') as f:\n",
        "        json_test = json.load(f)\n",
        "else:\n",
        "    with open('/kaggle/input/nlp-assignment/beerqa_train_v1.0.json') as f:\n",
        "        json_train = json.load(f)\n",
        "    with open('/kaggle/input/nlp-assignment/beerqa_dev_v1.0.json') as f:\n",
        "        json_dev = json.load(f)\n",
        "    with open('/kaggle/input/nlp-assignment/beerqa_test_questions_v1.0.json') as f:\n",
        "        json_test = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hWYjhNeSerc"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nafwa8r4ywFs"
      },
      "source": [
        "We need to see what we have as data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:22:14.130700Z",
          "iopub.status.busy": "2024-05-26T12:22:14.130013Z",
          "iopub.status.idle": "2024-05-26T12:22:14.139164Z",
          "shell.execute_reply": "2024-05-26T12:22:14.138254Z",
          "shell.execute_reply.started": "2024-05-26T12:22:14.130668Z"
        },
        "id": "Cml6PJwpRiTB",
        "outputId": "2290ed57-62ce-46d6-e84b-d56e3bacfe9b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set documents struct:  dict_keys(['version', 'split', 'data'])\n",
            "Dev set documents struct:  dict_keys(['version', 'split', 'data'])\n",
            "Test set documents struct:  dict_keys(['version', 'split', 'data']) \n",
            "\n",
            "Train set documents struct:  dict_keys(['id', 'src', 'answers', 'question', 'context'])\n",
            "Dev set documents struct:  dict_keys(['id', 'src', 'answers', 'question', 'context'])\n",
            "Test set documents struct:  dict_keys(['id', 'question']) \n",
            "\n",
            "First document of Train Set:\n",
            " {\n",
            "    \"id\": \"8af07575b8444ae748634478f96b00d4e7dbd170\",\n",
            "    \"src\": \"squad\",\n",
            "    \"answers\": [\n",
            "        \"1793\"\n",
            "    ],\n",
            "    \"question\": \"When did Wordsworth initially attack Burke?\",\n",
            "    \"context\": [\n",
            "        [\n",
            "            \"Edmund Burke\",\n",
            "            \"In the 19th century, Burke was praised by both liberals and conservatives. Burke's friend Philip Francis wrote that Burke \\\"was a man who truly & prophetically foresaw all the consequences which would rise from the adoption of the French principles\\\", but because Burke wrote with so much passion, people were doubtful of his arguments. William Windham spoke from the same bench in the House of Commons as Burke had when he had separated from Fox and an observer said Windham spoke \\\"like the ghost of Burke\\\" when he made a speech against peace with France in 1801. William Hazlitt, a political opponent of Burke, regarded him as amongst his three favourite writers (the others being Junius and Rousseau) and made it \\\"a test of the sense and candour of any one belonging to the opposite party, whether he allowed Burke to be a great man\\\". William Wordsworth was originally a supporter of the French Revolution and attacked Burke in \\\"A Letter to the Bishop of Llandaff\\\" (1793), but by the early 19th century he had changed his mind and came to admire Burke. In his \\\"Two Addresses to the Freeholders of Westmorland\\\", Wordsworth called Burke \\\"the most sagacious Politician of his age\\\", whose predictions \\\"time has verified\\\". He later revised his poem \\\"The Prelude\\\" to include praise of Burke (\\\"Genius of Burke! forgive the pen seduced/By specious wonders\\\") and portrayed him as an old oak. Samuel Taylor Coleridge came to have a similar conversion as he had criticised Burke in \\\"The Watchman\\\", but in his \\\"Friend\\\" (1809\\u20131810) had defended Burke from charges of inconsistency. Later in his \\\"Biographia Literaria\\\" (1817), Coleridge hails Burke as a prophet and praises Burke for referring \\\"habitually to \\\"principles\\\". He was a \\\"scientific\\\" statesman; and therefore a \\\"seer\\\"\\\". Henry Brougham wrote of Burke that \\\"all his predictions, save one momentary expression, had been more than fulfilled: anarchy and bloodshed had borne sway in France; conquest and convulsion had desolated Europe. [...] [T]he providence of mortals is not often able to penetrate so far as this into futurity\\\". George Canning believed that Burke's \\\"Reflections\\\" \\\"has been justified by the course of subsequent events; and almost every prophecy has been strictly fulfilled\\\". In 1823, Canning wrote that he took Burke's \\\"last works and words [as] the manual of my politics\\\". The Conservative Prime Minister Benjamin Disraeli \\\"was deeply penetrated with the spirit and sentiment of Burke's later writings\\\".\"\n",
            "        ]\n",
            "    ]\n",
            "} \n",
            "\n",
            "\n",
            "First document of Dev Set:\n",
            " {\n",
            "    \"id\": \"b3d50a40b29d4283609de1d3f426aebce198a0b2\",\n",
            "    \"src\": \"hotpotqa\",\n",
            "    \"answers\": [\n",
            "        \"Eschscholzia\"\n",
            "    ],\n",
            "    \"question\": \"Which genus contains more species, Ortegocactus or Eschscholzia?\",\n",
            "    \"context\": [\n",
            "        [\n",
            "            \"Eschscholzia\",\n",
            "            \"Eschscholzia is a genus of 12 annual or perennial plants in the Papaveraceae (poppy) family. The genus was named after the Baltic German/Imperial Russian botanist Johann Friedrich von Eschscholtz (1793-1831). All species are native to Mexico or the southern United States.\"\n",
            "        ],\n",
            "        [\n",
            "            \"Eschscholzia\",\n",
            "            \"Leaves are deeply cut, glabrous and glaucous, mostly basal, though a few grow on the stem.\"\n",
            "        ],\n",
            "        [\n",
            "            \"Ortegocactus\",\n",
            "            \"Ortegocactus macdougallii is a species of cactus and the sole species of the genus Ortegocactus. The plant has a greenish-gray epidermis and black spines. It is only known from Oaxaca, Mexico.\"\n",
            "        ]\n",
            "    ]\n",
            "} \n",
            "\n",
            "\n",
            "First document of Test Set:\n",
            " {\n",
            "    \"id\": \"cc7f51db8fe15d93a9649b9336cc186444e64767\",\n",
            "    \"question\": \"How much correspondence did Tesla send Morgan in the five years following 1901?\"\n",
            "} \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check data structure for each set\n",
        "print('Train set documents struct: ', json_train.keys())\n",
        "print('Dev set documents struct: ', json_dev.keys())\n",
        "print('Test set documents struct: ', json_test.keys(), '\\n')\n",
        "# Keep only the 'data' field\n",
        "train_data = json_train['data']\n",
        "dev_data = json_dev['data']\n",
        "test_data = json_test['data']\n",
        "# Print structure of the new sets\n",
        "print('Train set documents struct: ', train_data[0].keys())\n",
        "print('Dev set documents struct: ', dev_data[0].keys())\n",
        "print('Test set documents struct: ', test_data[0].keys(), '\\n')\n",
        "# Clean Memory. json_train is still used later in the model section\n",
        "del json_dev, json_test\n",
        "# Print first document of each set\n",
        "print('First document of Train Set:\\n', json.dumps(train_data[0], indent=4), '\\n\\n')\n",
        "print('First document of Dev Set:\\n', json.dumps(dev_data[0], indent=4), '\\n\\n')\n",
        "print('First document of Test Set:\\n', json.dumps(test_data[0], indent=4), '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp7S5JrnRsPK"
      },
      "source": [
        "Now we have a better understanding of what each field contains:\n",
        "* *id* - unique id of the document.\n",
        "* *src* - source of the document. Basically, beerqa is a composite of squad and hotpotqa datasets, which are the only two possible values.\n",
        "* *answers* - the correct answers to the question. Although it is a list, there are no documents with more than one answer.\n",
        "* *question* - is the text of the question.\n",
        "* *context* - a list containing the paragraphs retrieved from Wikipedia needed to answer the question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgG1W0D3y-fT"
      },
      "source": [
        "Let's check how many words in average we have in the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:22:23.435437Z",
          "iopub.status.busy": "2024-05-26T12:22:23.434686Z",
          "iopub.status.idle": "2024-05-26T12:22:32.204481Z",
          "shell.execute_reply": "2024-05-26T12:22:32.203583Z",
          "shell.execute_reply.started": "2024-05-26T12:22:23.435406Z"
        },
        "id": "NP8bPP6GPo34",
        "outputId": "5d8dd96c-70c4-4d29-ac88-956ebc636ee7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+------------+-----------+--------+\n",
            "|                                         |      Train |       Dev | Test   |\n",
            "+=========================================+============+===========+========+\n",
            "| Number of documents                     | 134043     | 14121     | 14932  |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| Avg context size (in words)             |     92.694 |   100.389 | \\      |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| Avg context vocabulary size (in words)  |    102.218 |    99.144 | \\      |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| Avg question size (in words)            |     14.336 |    12.542 | 12.635 |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| Avg question vocabulary size (in words) |     13.44  |    11.961 | 12.016 |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| 1-hops QAs                              |  58411     |  7970     | \\      |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| 2-hops QAs                              |  50987     |  4230     | \\      |\n",
            "+-----------------------------------------+------------+-----------+--------+\n",
            "| 3-hops or more QAs                      |  24645     |  1921     | \\      |\n",
            "+-----------------------------------------+------------+-----------+--------+\n"
          ]
        }
      ],
      "source": [
        "# Statistics\n",
        "# n of docs in each set\n",
        "n_train_docs = len(train_data)\n",
        "n_dev_docs = len(dev_data)\n",
        "n_test_docs = len(test_data)\n",
        "#---------- CONTEXT\n",
        "# Average length of the context vocabulary of each set\n",
        "avg_train_context_vocabulary = np.mean([len(set(word for element in doc['context'] for word in element[1].split())) for doc in train_data])\n",
        "avg_dev_context_vocabulary = np.mean([len(set(word for element in doc['context'] for word in element[1].split())) for doc in dev_data])\n",
        "# Average number of words in the context of each set\n",
        "avg_train_context_words = np.mean([np.mean([len(context[1].split()) for context in doc['context']]) for doc in train_data])\n",
        "avg_dev_context_words = np.mean([np.mean([len(context[1].split()) for context in doc['context']]) for doc in dev_data])\n",
        "#---------- QUESTION\n",
        "# Average length of the question vocabulary of each set\n",
        "avg_train_question_vocabulary = np.mean([len(set(word for word in doc['question'].split())) for doc in train_data])\n",
        "avg_dev_question_vocabulary = np.mean([len(set(word for word in doc['question'].split())) for doc in dev_data])\n",
        "avg_test_question_vocabulary = np.mean([len(set(word for word in doc['question'].split())) for doc in test_data])\n",
        "# Average number of words in the question of each set\n",
        "avg_train_question_words = np.mean([len(doc['question'].split()) for doc in train_data])\n",
        "avg_dev_question_words = np.mean([len(doc['question'].split()) for doc in dev_data])\n",
        "avg_test_question_words = np.mean([len(doc['question'].split()) for doc in test_data])\n",
        "#---------- HOPS\n",
        "# Number of documents gathered by number of hops required to answer the question.\n",
        "n_hops_train = [sum(len(doc['context']) == 1 for doc in train_data)]+[sum(len(doc['context']) == 2 for doc in train_data)] + [sum(len(doc['context']) >= 3 for doc in train_data)]\n",
        "n_hops_dev = [sum(len(doc['context']) == 1 for doc in dev_data)]+[sum(len(doc['context']) == 2 for doc in dev_data)] + [sum(len(doc['context']) >= 3 for doc in dev_data)]\n",
        "# Headers for the table\n",
        "headers = ['', 'Train', 'Dev', 'Test']\n",
        "# Print with tabulate\n",
        "print(tabulate([['Number of documents ', n_train_docs, n_dev_docs, n_test_docs],\n",
        "                ['Avg context size (in words)', f\"{avg_train_context_words:.3f}\", f\"{avg_dev_context_words:.3f}\", '\\\\'],\n",
        "               ['Avg context vocabulary size (in words)', f\"{avg_train_context_vocabulary:.3f}\", f\"{avg_dev_context_vocabulary:.3f}\", '\\\\'],\n",
        "                ['Avg question size (in words)', f\"{avg_train_question_words:.3f}\", f\"{avg_dev_question_words:.3f}\", f\"{avg_test_question_words:.3f}\"],\n",
        "                ['Avg question vocabulary size (in words)', f\"{avg_train_question_vocabulary:.3f}\", f\"{avg_dev_question_vocabulary:.3f}\", f\"{avg_test_question_vocabulary:.3f}\"],\n",
        "               ['1-hops QAs', n_hops_train[0], n_hops_dev[0],'\\\\'],\n",
        "               ['2-hops QAs', n_hops_train[1], n_hops_dev[1], '\\\\'],\n",
        "               ['3-hops or more QAs', n_hops_train[2], n_hops_dev[2], '\\\\']],\n",
        "               headers=headers, tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wLKqn1rPo34"
      },
      "source": [
        "The only fields of interests for our purpose are answers, question, and context. Thus we are going to cut everything else."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:22:37.337198Z",
          "iopub.status.busy": "2024-05-26T12:22:37.336628Z",
          "iopub.status.idle": "2024-05-26T12:22:37.868622Z",
          "shell.execute_reply": "2024-05-26T12:22:37.867682Z",
          "shell.execute_reply.started": "2024-05-26T12:22:37.337169Z"
        },
        "id": "OXXMuhYXPo35",
        "outputId": "1bd6e547-7d93-4c09-a1e5-fdf5196d08ca",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set documents new keys:  dict_keys(['answers', 'question', 'context'])\n",
            "Dev set documents new keys:  dict_keys(['answers', 'question', 'context'])\n",
            "Test set documents new keys:  dict_keys(['question'])\n"
          ]
        }
      ],
      "source": [
        "train = [{'answers': [ans for ans in doc['answers']], 'question': doc['question'],\n",
        "          'context': [(context) for context in doc['context']]} for doc in train_data]\n",
        "dev = [{'answers': [ans for ans in doc['answers']], 'question': doc['question'],\n",
        "          'context': [(context) for context in doc['context']]} for doc in dev_data]\n",
        "# Test only contains question\n",
        "test = [{'question': doc['question']} for doc in test_data]\n",
        "# Print new keys\n",
        "print('Train set documents new keys: ', train[0].keys())\n",
        "print('Dev set documents new keys: ', dev[0].keys())\n",
        "print('Test set documents new keys: ', test[0].keys())\n",
        "\n",
        "merged_train_dev = train + dev\n",
        "\n",
        "# Free memory\n",
        "del train_data, dev_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xp39OYPUL0p"
      },
      "source": [
        "## *Answers Exploration*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqueBUDU0zvM"
      },
      "source": [
        "During our project work we realized that in the dataset answers are stored in array but we haven't seen any sample that contains more than 1 answer. We need to be sure about this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:29:09.702413Z",
          "iopub.status.busy": "2024-05-26T16:29:09.701499Z",
          "iopub.status.idle": "2024-05-26T16:29:09.744390Z",
          "shell.execute_reply": "2024-05-26T16:29:09.743300Z",
          "shell.execute_reply.started": "2024-05-26T16:29:09.702379Z"
        },
        "id": "gx37kmEW7tus",
        "outputId": "8329f0ca-bb9e-49b4-d936-51fa9d7f0897",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount of samples with more than 1 answer:  0\n"
          ]
        }
      ],
      "source": [
        "listtt = []\n",
        "for t in merged_train_dev:\n",
        "  if len(t[\"answers\"]) > 1:\n",
        "    listtt.append(t[\"answers\"])\n",
        "\n",
        "print(\"Amount of samples with more than 1 answer: \", len(listtt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKFn-bmc1QT4"
      },
      "source": [
        "Then we decided to see how many answers consist of pure digit (years for example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:29:14.466962Z",
          "iopub.status.busy": "2024-05-26T16:29:14.466105Z",
          "iopub.status.idle": "2024-05-26T16:29:14.677956Z",
          "shell.execute_reply": "2024-05-26T16:29:14.676501Z",
          "shell.execute_reply.started": "2024-05-26T16:29:14.466929Z"
        },
        "id": "Zajb-E1tz4Gd",
        "outputId": "c3bbdbd9-d610-46ef-bd1a-af691a5fdccc",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of pure number answers:  11925\n",
            "The number of the rest:  122118\n",
            "The percentage of pure number answers:  8.9 %\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"b9aae0d3-6b66-4573-997d-4989a3dff79e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b9aae0d3-6b66-4573-997d-4989a3dff79e\")) {                    Plotly.newPlot(                        \"b9aae0d3-6b66-4573-997d-4989a3dff79e\",                        [{\"x\":[\"Digit answers\",\"The rest\"],\"y\":[11925,122118],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparison\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b9aae0d3-6b66-4573-997d-4989a3dff79e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking the percentage of numbers only answers\n",
        "count = 0\n",
        "for t in merged_train_dev:\n",
        "    for a in t[\"answers\"]:\n",
        "        if a.isdigit():\n",
        "            count += 1\n",
        "\n",
        "print(\"The number of pure number answers: \", count)\n",
        "print(\"The number of the rest: \", len(train) - count)\n",
        "print(\"The percentage of pure number answers: \", round(count / len(train) * 100, 2), \"%\")\n",
        "print()\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=[\"Digit answers\", \"The rest\"], y=[count, len(train) - count])],\n",
        "    layout_title_text=\"Comparison\"\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIAAbJvo1qIi"
      },
      "source": [
        "Also we want to check how many answers contain mathematical symbols like +, -, * or /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:29:17.008646Z",
          "iopub.status.busy": "2024-05-26T16:29:17.007765Z",
          "iopub.status.idle": "2024-05-26T16:29:17.330665Z",
          "shell.execute_reply": "2024-05-26T16:29:17.329664Z",
          "shell.execute_reply.started": "2024-05-26T16:29:17.008612Z"
        },
        "id": "UCvm1M5qsLD-",
        "outputId": "2787b349-4c12-4984-e60f-1853c0884f82",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of answers containin mathematical symbols 4902\n",
            "The number of the rest 129141\n",
            "The percentage of answers containin mathematical symbols 3.66 %\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"a23403f3-ff05-4966-9db0-59315f146a13\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a23403f3-ff05-4966-9db0-59315f146a13\")) {                    Plotly.newPlot(                        \"a23403f3-ff05-4966-9db0-59315f146a13\",                        [{\"x\":[\"Answers containing mathematical symbols\",\"The rest\"],\"y\":[4902,129141],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparison\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a23403f3-ff05-4966-9db0-59315f146a13');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking the percentage of answers containing mathematical symbols\n",
        "pattern = re.compile(r'[-+*/]')\n",
        "count = 0\n",
        "for t in merged_train_dev:\n",
        "    for a in t[\"answers\"]:\n",
        "        if re.search(pattern, a):\n",
        "              count += 1\n",
        "\n",
        "print(\"The number of answers containin mathematical symbols\", count)\n",
        "print(\"The number of the rest\", len(train) - count)\n",
        "print(\"The percentage of answers containin mathematical symbols\", round(count / len(train) * 100, 2), \"%\")\n",
        "print()\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=[\"Answers containing mathematical symbols\", \"The rest\"], y=[count, len(train) - count])],\n",
        "    layout_title_text=\"Comparison\"\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIUxQsV912OX"
      },
      "source": [
        "And we decided to check the amount of \"yes\" or \"no\" answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:29:20.131528Z",
          "iopub.status.busy": "2024-05-26T16:29:20.130789Z",
          "iopub.status.idle": "2024-05-26T16:29:20.244688Z",
          "shell.execute_reply": "2024-05-26T16:29:20.243698Z",
          "shell.execute_reply.started": "2024-05-26T16:29:20.131496Z"
        },
        "id": "6sZsQJwCxWeM",
        "outputId": "53b1125e-9cc8-4a0d-fe70-c8e5cc3cee30",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of simple answers 5347\n",
            "The number of the rest 128696\n",
            "The percentage of simple answers 3.99 %\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"0d31b6c7-eed9-4c75-b23e-af198f233063\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0d31b6c7-eed9-4c75-b23e-af198f233063\")) {                    Plotly.newPlot(                        \"0d31b6c7-eed9-4c75-b23e-af198f233063\",                        [{\"x\":[\"Simple answers\",\"The rest\"],\"y\":[5347,128696],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparison\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0d31b6c7-eed9-4c75-b23e-af198f233063');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking the percentage of yes/no answers\n",
        "typical_answers = [\"yes\", \"no\"]\n",
        "count = 0\n",
        "for t in merged_train_dev:\n",
        "  for a in typical_answers:\n",
        "    if a.lower() in t[\"answers\"]:\n",
        "      count += 1\n",
        "\n",
        "print(\"The number of simple answers\", count)\n",
        "print(\"The number of the rest\", len(train) - count)\n",
        "print(\"The percentage of simple answers\", round(count / len(train) * 100, 2), \"%\")\n",
        "print()\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=[\"Simple answers\", \"The rest\"], y=[count, len(train) - count])],\n",
        "    layout_title_text=\"Comparison\"\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1BfoWSMPo35"
      },
      "source": [
        "# **Vectorization**\n",
        "The goal of this section is to build a TF-IDF model to identify the sentence that contains the answer to a given question. For starters we are going to build a vectorizer for each field of the train set, and then explore the vectorization obtained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:36:46.611635Z",
          "iopub.status.busy": "2024-05-26T16:36:46.610943Z",
          "iopub.status.idle": "2024-05-26T16:37:09.837529Z",
          "shell.execute_reply": "2024-05-26T16:37:09.836426Z",
          "shell.execute_reply.started": "2024-05-26T16:36:46.611600Z"
        },
        "id": "dusOwGv3qcCF",
        "outputId": "a7be4cee-f7f3-45ed-9506-b0528c7cbdb7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of contexts vocabulary: 48461\n",
            "\n",
            "25 randomly chosen terms from contexts:\n",
            " ['1437', '62nd', '795', 'belgrade', 'code', 'comedienne', 'democratized', 'doo', 'downstairs', 'elaborating', 'franklin', 'fraudulent', 'illusionist', 'manes', 'marias', 'moneypenny', 'perching', 'rack', 'remind', 'sassou', 'sergeant', 'surge', 'usd', 'vanity', 'waterfowl'] \n",
            "\n",
            "Length of questions vocabulary: 18375\n",
            "\n",
            "25 randomly chosen terms from questions:\n",
            " ['aristotle', 'ashcroft', 'blamed', 'bridges', 'britton', 'carthage', 'celtic', 'chico', 'continue', 'fairchild', 'gareth', 'gregg', 'hacker', 'instructor', 'labs', 'laura', 'mixed', 'mpeg', 'number', 'ode', 'peace', 'penguins', 'shapes', 'video', 'witherspoon'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Build vectorizers\n",
        "# context_vectorizer = TfidfVectorizer(max_df=0.8, min_df=5, stop_words='english')\n",
        "context_vectorizer = TfidfVectorizer (\n",
        "    stop_words = 'english',\n",
        "    max_df = 1.0,\n",
        "    min_df = 10\n",
        ")\n",
        "question_vectorizer = TfidfVectorizer(max_df=0.8, min_df=5, stop_words='english')\n",
        "answer_vectorizer = TfidfVectorizer(max_df=0.3, min_df=5, stop_words='english')\n",
        "\n",
        "#-------CONTEXT VECTORIZATION\n",
        "# As first try vectorize the context => we need a unified context for all docs\n",
        "context_vect = [(' '.join([' '.join(context) for context in doc['context']])) for doc in train]\n",
        "# Just some checks\n",
        "# print('Unified context of document 5000: \\n', clean_context_vect[5000]+'\\n')\n",
        "# print('Original list of contexts of document 5000: \\n',train[5000]['context'],'\\n')\n",
        "# Fit the doc to the vectorizer\n",
        "context_vectorizer.fit(context_vect)\n",
        "# Check again vocabulary\n",
        "vocab_context = context_vectorizer.get_feature_names_out()\n",
        "print(f\"Length of contexts vocabulary: {len(vocab_context)}\\n\")\n",
        "# Print 25 randomly chosen terms\n",
        "print('25 randomly chosen terms from contexts:\\n', sorted(random.sample(vocab_context.tolist(),25)),'\\n')\n",
        "\n",
        "#-------QUESTION VECTORIZATION\n",
        "# Fit the doc to the vectorizer\n",
        "question_vect = [doc['question'] for doc in train]\n",
        "question_vectorizer.fit(question_vect)\n",
        "# Check again vocabulary\n",
        "vocab_question = question_vectorizer.get_feature_names_out()\n",
        "print(f\"Length of questions vocabulary: {len(vocab_question)}\\n\")\n",
        "# Print 25 randomly chosen terms\n",
        "print('25 randomly chosen terms from questions:\\n', sorted(random.sample(vocab_question.tolist(),25)),'\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:39:07.051138Z",
          "iopub.status.busy": "2024-05-26T16:39:07.050734Z",
          "iopub.status.idle": "2024-05-26T16:39:30.043044Z",
          "shell.execute_reply": "2024-05-26T16:39:30.041714Z",
          "shell.execute_reply.started": "2024-05-26T16:39:07.051108Z"
        },
        "id": "YuBSTRk3Po36",
        "outputId": "f631374d-45e1-4fb0-8948-a47ab81aa1d4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorized representation of the first word of first document's context:\n",
            "   (0, 47833)\t0.09413434637302566\n",
            "  (0, 47823)\t0.03624313146955895\n",
            "  (0, 47819)\t0.030902076627965208\n",
            "  (0, 47730)\t0.0242917605058111\n",
            "  (0, 47715)\t0.10395576653096215\n",
            "  (0, 47714)\t0.030484232437534294\n",
            "  (0, 47650)\t0.04886905584104634\n",
            "  (0, 47465)\t0.10699838383544882\n",
            "  (0, 47422)\t0.07034887410175401\n",
            "  (0, 47189)\t0.05179118971437162\n",
            "  (0, 46911)\t0.05279522219074008\n",
            "  (0, 46154)\t0.04816076864435092\n",
            "  (0, 44769)\t0.042047848054333946\n",
            "  (0, 44146)\t0.02298186562154748\n",
            "  (0, 43938)\t0.016395905438458515\n",
            "  (0, 43538)\t0.03243693247605507\n",
            "  (0, 43255)\t0.029923598407820388\n",
            "  (0, 42742)\t0.05161061837882814\n",
            "  (0, 42549)\t0.041075194194683834\n",
            "  (0, 42224)\t0.030430840708580983\n",
            "  (0, 42011)\t0.03979415895516385\n",
            "  (0, 41593)\t0.0390199836656537\n",
            "  (0, 41260)\t0.07483542395531176\n",
            "  (0, 41230)\t0.03419131857062649\n",
            "  (0, 41144)\t0.03248632233477978\n",
            "  :\t:\n",
            "  (0, 8257)\t0.01988106743867888\n",
            "  (0, 7973)\t0.8337313103473539\n",
            "  (0, 7171)\t0.043590531810400596\n",
            "  (0, 6835)\t0.05110192475536192\n",
            "  (0, 6651)\t0.03424416136997829\n",
            "  (0, 6260)\t0.0336344446194064\n",
            "  (0, 6212)\t0.04681915831998684\n",
            "  (0, 6193)\t0.037985940584580984\n",
            "  (0, 6148)\t0.030053179264853316\n",
            "  (0, 4936)\t0.036081941454829944\n",
            "  (0, 4419)\t0.04089462285914036\n",
            "  (0, 3742)\t0.04505194121991618\n",
            "  (0, 3409)\t0.029656727636913172\n",
            "  (0, 2959)\t0.023203113598595875\n",
            "  (0, 2754)\t0.03797099638997062\n",
            "  (0, 2721)\t0.0503463674629821\n",
            "  (0, 2650)\t0.043632093761148516\n",
            "  (0, 2300)\t0.029854803855023548\n",
            "  (0, 1094)\t0.052920556035776126\n",
            "  (0, 873)\t0.04411125952655418\n",
            "  (0, 864)\t0.04278319639803663\n",
            "  (0, 856)\t0.04086930358541487\n",
            "  (0, 854)\t0.042607241099925544\n",
            "  (0, 846)\t0.04189358215934679\n",
            "  (0, 834)\t0.043932156510532644\n",
            "\n",
            "Top 10 most used terms:\n",
            " [('burke', 0.8337313103473539), ('windham', 0.10699838383544882), ('coleridge', 0.10515847275459538), ('wordsworth', 0.10395576653096215), ('canning', 0.10287156089100835), ('predictions', 0.09541078192115136), ('wrote', 0.09413434637302566), ('fulfilled', 0.08878266677778834), ('spoke', 0.07483542395531176), ('william', 0.07034887410175401)]\n",
            "\n",
            "Vectorized representation of first document's question:\n",
            "   (0, 8603)\t0.58261701867342\n",
            "  (0, 5005)\t0.22788209559620534\n",
            "  (0, 2749)\t0.5588984128846995\n",
            "  (0, 1611)\t0.5442974592387343\n",
            "\n",
            "Most used terms:\n",
            " [('initially', 0.58261701867342), ('burke', 0.5588984128846995), ('attack', 0.5442974592387343), ('did', 0.22788209559620534)]\n"
          ]
        }
      ],
      "source": [
        "# Now effectively transform the context into vectorized form\n",
        "vector_contexts = context_vectorizer.transform(context_vect)\n",
        "vector_questions = question_vectorizer.transform([doc['question'] for doc in train])\n",
        "# Print first 10 elements of the first context\n",
        "print('Vectorized representation of the first word of first document\\'s context:\\n', vector_contexts[0][0])\n",
        "# Then print 5 most used terms in the first context\n",
        "print('\\nTop 10 most used terms:\\n', sorted([(vocab_context[j], vector_contexts[0, j]) for j in vector_contexts[0].nonzero()[1]], key=lambda x: -x[1])[:10])\n",
        "# Print first question in vectorized form\n",
        "print('\\nVectorized representation of first document\\'s question:\\n', vector_questions[0])\n",
        "# Then print most used terms in the first question\n",
        "print('\\nMost used terms:\\n', sorted([(vocab_question[j], vector_questions[0, j]) for j in vector_questions[0].nonzero()[1]], key=lambda x: -x[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxnM5SI8Po36"
      },
      "source": [
        "# Exploration of the Vectorization\n",
        "Here we use the vectorized version of the fields to measure similarity between randomly chosen documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:39:30.045697Z",
          "iopub.status.busy": "2024-05-26T16:39:30.045069Z",
          "iopub.status.idle": "2024-05-26T16:39:30.178916Z",
          "shell.execute_reply": "2024-05-26T16:39:30.177720Z",
          "shell.execute_reply.started": "2024-05-26T16:39:30.045654Z"
        },
        "id": "x8Vz6U39Po36",
        "outputId": "8eb4f6ec-ae0d-48da-86dd-544e80683e79",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between contexts of document 26476 and 99647: 0.00460\n",
            "Similarity between contexts of document 72869 and 118858: 0.00000\n",
            "Similarity between contexts of document 95638 and 42638: 0.00311\n",
            "\n",
            "\n",
            "Similarity between questions of document 97040 and 93132: 0.00000\n",
            "Similarity between questions of document 54921 and 69986: 0.00000\n",
            "Similarity between questions of document 18717 and 44862: 0.00000\n",
            "\n",
            "\n",
            "\n",
            "Average contexts vocabulary size: 65.097\n",
            "Average questions vocabulary size: 6.999\n"
          ]
        }
      ],
      "source": [
        "# SIMILARITY\n",
        "#------ CONTEXT\n",
        "# Check similarity between some randomly chosen documents' context\n",
        "for i in range(0, 3):\n",
        "    doc_1 = random.randint(0, vector_contexts.shape[0]-1)\n",
        "    doc_2 = random.randint(0, vector_contexts.shape[0]-1)\n",
        "    print('Similarity between contexts of document {} and {}: {:.5f}'.format(doc_1, doc_2, vector_contexts[doc_1].multiply(vector_contexts[doc_2]).sum()))\n",
        "#------ QUESTIONS\n",
        "# Check similarity between some randomly chosen documents' questions\n",
        "print('\\n')\n",
        "for i in range(0, 3):\n",
        "    doc_1 = random.randint(0, vector_questions.shape[0]-1)\n",
        "    doc_2 = random.randint(0, vector_questions.shape[0]-1)\n",
        "    print('Similarity between questions of document {} and {}: {:.5f}'.format(doc_1, doc_2, vector_questions[doc_1].multiply(vector_questions[doc_2]).sum()))\n",
        "print('\\n\\n')\n",
        "# VOCABULARY SIZE\n",
        "# We expect it to be similar to the one computed in the initial analysis\n",
        "# Average vocabulary size of the contexts\n",
        "nonzero_count = vector_contexts.count_nonzero()\n",
        "doc_count = vector_contexts.get_shape()[0]\n",
        "print(f\"Average contexts vocabulary size: {nonzero_count/doc_count:.3f}\")\n",
        "#------ QUESTIONS\n",
        "# Average vocabulary size of the questions\n",
        "nonzero_count = vector_questions.count_nonzero()\n",
        "doc_count = vector_questions.get_shape()[0]\n",
        "print(f\"Average questions vocabulary size: {nonzero_count/doc_count:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI4VB1FSWH0q"
      },
      "source": [
        "# TF-IDF Model\n",
        "As said before, we use this TF-IDF model to look for similarity between the sentences inside the context and the actual question. The higher the similarity, the higher the score for a specific sentence. The idea is to then compute the accuracy in terms of correct words inside the prediction, i.e. how many words of the 'answers' are inside 'tfidf_prediction'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:40:06.159441Z",
          "iopub.status.busy": "2024-05-26T16:40:06.158550Z",
          "iopub.status.idle": "2024-05-26T16:40:06.173713Z",
          "shell.execute_reply": "2024-05-26T16:40:06.172704Z",
          "shell.execute_reply.started": "2024-05-26T16:40:06.159396Z"
        },
        "id": "HlyCETcgWJ6B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tfidf_predictions_(dataset):\n",
        "    \"\"\"\n",
        "    Identify the answer sentence as one whose TF-IDF representation has minimal distance to that of the question.\n",
        "\n",
        "    args:\n",
        "        dataset (list) : a copy of the beerqa (train) dataset\n",
        "    returns:\n",
        "        float: accuracy of the predictions. A prediction is correct if the corresponding answer is contained in tfidf_prediction.\n",
        "    \"\"\"\n",
        "    # Deep copy the dataset\n",
        "    tmp = copy.deepcopy(dataset)\n",
        "    # Change context to a single string for each dcument\n",
        "    if type(tmp[0]['context']) == list:\n",
        "        tmp = [{'answers': [ans for ans in doc['answers']], 'question': doc['question'],\n",
        "          'context': ' '.join([' '.join(context) for context in doc['context']])} for doc in tmp]\n",
        "    # Initialize vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer(\n",
        "        tokenizer = nltk.word_tokenize,\n",
        "        stop_words = stopwords.words('english'),\n",
        "        ngram_range = (1,2),\n",
        "        max_df = 1.0,\n",
        "        min_df = 10\n",
        "    )\n",
        "\n",
        "    # Extract contexts and questions from each doc\n",
        "    contexts = [doc['context'] for doc in tmp]\n",
        "    questions = [doc['question'] for doc in tmp]\n",
        "    # Get the vectorized version of contexts and questions\n",
        "    tfidf_contexts = tfidf_vectorizer.fit_transform(contexts)\n",
        "    tfidf_questions = tfidf_vectorizer.transform(questions)\n",
        "    # Initialize predictions and distances\n",
        "    predictions = []\n",
        "    distances = []\n",
        "\n",
        "    for i, doc in tqdm(enumerate(tmp), total=len(tmp), desc=\"Processing dataset\"):\n",
        "        # Vectorized version of current doc\n",
        "        question_vector = tfidf_questions[i]\n",
        "        context_vectors = tfidf_contexts[i]\n",
        "        # Use the cosine similarity to find the similarity score between question and context\n",
        "        similarities = cosine_similarity(question_vector, context_vectors)\n",
        "        # Find index with highest similarity\n",
        "        max_similarity_index = np.argmax(similarities)\n",
        "        # Get sentence with highest similarity\n",
        "        predicted_sentence = doc['context'].split('.')[max_similarity_index]\n",
        "        # Compute the distance value between question and context\n",
        "        distance_value = np.max(similarities)\n",
        "        # Add the two new fields\n",
        "        doc['tfidf_prediction'] = predicted_sentence\n",
        "        doc['distance_value'] = distance_value\n",
        "        predictions.append(predicted_sentence)\n",
        "        distances.append(distance_value)\n",
        "\n",
        "    total_words = 0\n",
        "    correct_words = 0\n",
        "    # Compute accuracy\n",
        "    for doc in tmp:\n",
        "        answer_words = set(nltk.word_tokenize(doc['answers'][0]))\n",
        "        prediction_words = set(nltk.word_tokenize(doc['tfidf_prediction']))\n",
        "        total_words += len(answer_words)\n",
        "        # Count correct words as intersection between prediction and answer\n",
        "        correct_words += len(answer_words.intersection(prediction_words))\n",
        "\n",
        "    accuracy = correct_words / total_words if total_words > 0 else 0\n",
        "    print(\"TF-IDF Accuracy:\", f\"{accuracy:.5f}\")\n",
        "\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:40:09.580222Z",
          "iopub.status.busy": "2024-05-26T16:40:09.579846Z",
          "iopub.status.idle": "2024-05-26T16:40:40.576313Z",
          "shell.execute_reply": "2024-05-26T16:40:40.575133Z",
          "shell.execute_reply.started": "2024-05-26T16:40:09.580193Z"
        },
        "id": "NXOeBrahWPkJ",
        "outputId": "063db3f1-896b-4d40-ca7b-8d8e2b3ef3b9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing dataset: 100%|██████████| 8000/8000 [00:07<00:00, 1031.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Accuracy: 0.43657\n",
            "CPU times: user 31 s, sys: 87.7 ms, total: 31 s\n",
            "Wall time: 31 s\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the first 8000 documents\n",
        "%time tf_idf_predictions = tfidf_predictions_(train[:8000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:40:49.160208Z",
          "iopub.status.busy": "2024-05-26T16:40:49.159843Z",
          "iopub.status.idle": "2024-05-26T16:40:49.167544Z",
          "shell.execute_reply": "2024-05-26T16:40:49.166621Z",
          "shell.execute_reply.started": "2024-05-26T16:40:49.160180Z"
        },
        "id": "G1RvhlmYX6or",
        "outputId": "1bf17dfa-8760-40e7-834c-201c61f982a6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"answers\": [\n",
            "        \"workers\"\n",
            "    ],\n",
            "    \"question\": \"What group from the munitions plant in Woolwich formed the Arsenal club?\",\n",
            "    \"tfidf_prediction\": \"Arsenal F\",\n",
            "    \"distance_value\": 0.3458339269706324\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Check the prediction of the a random document\n",
        "doc = tf_idf_predictions[random.randint(0, len(tf_idf_predictions)-1)]\n",
        "tmp = {field: doc[field] for field in ['answers', 'question', 'tfidf_prediction', 'distance_value']}\n",
        "print(json.dumps(tmp, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS9e1365Yhz8"
      },
      "source": [
        "# Keyword Based Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:40:51.563355Z",
          "iopub.status.busy": "2024-05-26T16:40:51.562965Z",
          "iopub.status.idle": "2024-05-26T16:43:54.060072Z",
          "shell.execute_reply": "2024-05-26T16:43:54.058528Z",
          "shell.execute_reply.started": "2024-05-26T16:40:51.563327Z"
        },
        "id": "VpAgs21fY1sM",
        "outputId": "27f0eb50-aecd-4a27-fcbb-f21ff4ad8e10",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context query 'italy' results: Italy national football team The Italy national football team ( ) has officially represented Italy in international football since their first match in 1910. The squad is under the global jurisdiction of FIFA and is governed in Europe by UEFA—the latter of which was co-founded by the Italian team's supervising body, the Italian Football Federation (FIGC). Italy's home matches are played at various stadiums throughout Italy, and their primary training ground, Centro Tecnico Federale di Coverciano, is located at the FIGC technical headquarters in Coverciano, Florence. Italy national football team Italy is one of the most successful national teams in the history of the World Cup, having won four titles (1934, 1938, 1982, 2006) and appearing in two other finals (1970, 1994), reaching a third place (1990) and a fourth place (1978). In 1938, they became the first team to defend their World Cup title, and due to the outbreak of World War II, retained the title for a further 12 years. Italy had also previously won two Central European International Cups (1927–30, 1933–35). Between its first two World Cup victories, Italy won the Olympic football tournament (1936). After the majority of the team was killed in a plane crash in 1949, the team did not advance past the group stage of the following two World Cup tournaments, and also failed to qualify for the 1958 edition—failure to qualify for the World Cup would not happen again until the 2018 edition. Italy returned to form by 1968, winning a European Championship (1968), and after a period of alternating unsuccessful qualification rounds in Europe, later appeared in two other finals (2000, 2012). Italy's highest finish at the FIFA Confederations Cup was in 2013, where the squad achieved a third-place finish. Julio Libonatti Julio Libonatti (5 July 1901 – 9 October 1981) was a football manager and former footballer who played as a forward for the Argentina national team and Italy national team. Julio Libonatti Born in Rosario, Argentina, he started his career with Newell's Old Boys in 1917. In 1925 he became the first recorded trans-Atlantic transfer, when he moved to Italian club Torino. With 150 total goals with Torino, he is the second most prolific scorer in the history of the Torinese club after Paolo Pulici (172). He won the Scudetto with Torino in 1926–27 and 1927–28, although the first title was later revoked. Later in his career he also represented Genoa and Libertas Rimini.\n",
            "Question query 'italy' results: Who was the wife of the last King of Italy?\n",
            "Context query 'italy' results: Computer A computer is a machine that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming. Modern computers have the ability to follow generalized sets of operations, called \"programs.\" These programs enable computers to perform an extremely wide range of tasks. A \"complete\" computer including the hardware, the operating system (main software), and peripheral equipment required and used for \"full\" operation can be referred to as a computer system. This term may as well be used for a group of computers that are connected and work together, in particular a computer network or computer cluster. Wolfgang Palm Wolfgang Palm (born 1950) is a German musician and inventor who was the founder and owner of Palm Products GmbH (PPG) and the inventor and creator of various pioneering technical designs for analog and digital synthesizers. He is widely acknowledged as the father of digital synthesis and as a trendsetter in the use of computer technology in the making of electronic music.\n",
            "Question query 'italy' results: Which computer was made first Compucolor II or Orao?\n"
          ]
        }
      ],
      "source": [
        "# Some queries on the already vectorized training set\n",
        "query = 'italy'\n",
        "query_1 = 'computer'\n",
        "\n",
        "query_context = context_vectorizer.transform([query])[0]\n",
        "query_question = question_vectorizer.transform([query])[0]\n",
        "query_context_1 = context_vectorizer.transform([query_1])[0]\n",
        "query_question_1 = question_vectorizer.transform([query_1])[0]\n",
        "\n",
        "index_context = np.argmax([query_context.multiply(vector_contexts[i]).sum() for i in range(vector_contexts.shape[0])])\n",
        "index_question = np.argmax([query_question.multiply(vector_questions[i]).sum() for i in range(vector_questions.shape[0])])\n",
        "print('Context query \\'italy\\' results:', context_vect[index_context])\n",
        "print('Question query \\'italy\\' results:', question_vect[index_question])\n",
        "\n",
        "index_context = np.argmax([query_context_1.multiply(vector_contexts[i]).sum() for i in range(vector_contexts.shape[0])])\n",
        "index_question = np.argmax([query_question_1.multiply(vector_questions[i]).sum() for i in range(vector_questions.shape[0])])\n",
        "print('Context query \\'italy\\' results:', context_vect[index_context])\n",
        "print('Question query \\'italy\\' results:', question_vect[index_question])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nhC-o8WPo38"
      },
      "source": [
        "# **Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPRu-sja3XpV"
      },
      "source": [
        "It would be too naive to use simple approach such as K-means for such a big data. Instead, we will be using topic modelling via LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:43:54.062860Z",
          "iopub.status.busy": "2024-05-26T16:43:54.062448Z",
          "iopub.status.idle": "2024-05-26T16:44:02.593370Z",
          "shell.execute_reply": "2024-05-26T16:44:02.592415Z",
          "shell.execute_reply.started": "2024-05-26T16:43:54.062811Z"
        },
        "id": "6TeTe86bbsef",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Remove punctuation using regex expressions\n",
        "clean_train = [{'answers': [re.sub(r'[^a-zA-Z0-9\\s]', '', ans) for ans in doc['answers']], 'question': re.sub(r'[^a-zA-Z0-9\\s]', '', doc['question']),\n",
        "          'context':   [[re.sub(r'[^a-zA-Z0-9\\s]', '', element) for element in context] for context in doc['context']]} for doc in train]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpEi7Tl82wRD"
      },
      "source": [
        "For LDA clustering the number of words is crucial. The only field that has enough words is the context. Since we have it only in train data, we will divide the train data itself into the training and test parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:44:02.595551Z",
          "iopub.status.busy": "2024-05-26T16:44:02.594644Z",
          "iopub.status.idle": "2024-05-26T16:44:02.805786Z",
          "shell.execute_reply": "2024-05-26T16:44:02.804662Z",
          "shell.execute_reply.started": "2024-05-26T16:44:02.595510Z"
        },
        "id": "1byFGdYNY_RS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "clean_data_clustering = [(' '.join([' '.join(context) for context in doc['context']])) for doc in clean_train]\n",
        "\n",
        "ratio = 0.8\n",
        "split_index = int(len(clean_data_clustering) * ratio)\n",
        "clean_train_clustering = clean_data_clustering[:split_index]\n",
        "clean_test_clustering = clean_data_clustering[split_index:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:44:02.809508Z",
          "iopub.status.busy": "2024-05-26T16:44:02.808702Z",
          "iopub.status.idle": "2024-05-26T16:44:17.758267Z",
          "shell.execute_reply": "2024-05-26T16:44:17.757272Z",
          "shell.execute_reply.started": "2024-05-26T16:44:02.809479Z"
        },
        "id": "x6f2aM9zrPIL",
        "outputId": "4543a510-26f2-4560-cd28-a36e113e63cc",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocabulary: 9364\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english', min_df=100, max_df=0.5)\n",
        "vector_documents_train = vectorizer.fit_transform(clean_train_clustering)\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "print(f\"Length of vocabulary: {len(vocab)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAXbVMae3kBG"
      },
      "source": [
        "However, for LDA the exact number of topics should be specified. To find the optimal one, we will use Elbow method to find the optimal number of topics. Note, that we will be using quite low number of iterations just to save the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:44:17.759642Z",
          "iopub.status.busy": "2024-05-26T16:44:17.759384Z",
          "iopub.status.idle": "2024-05-26T18:34:10.286302Z",
          "shell.execute_reply": "2024-05-26T18:34:10.285122Z",
          "shell.execute_reply.started": "2024-05-26T16:44:17.759619Z"
        },
        "id": "JUeeTHtn6pPl",
        "outputId": "657956f8-e16e-454a-fb55-fd3a8a65a12f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of topics -  2\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  3\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  4\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  5\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  6\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  7\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  8\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  9\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  10\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  11\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  12\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  13\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  14\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  15\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  16\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  17\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  18\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  19\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n",
            "Number of topics -  20\n",
            "iteration: 1 of max_iter: 10\n",
            "iteration: 2 of max_iter: 10\n",
            "iteration: 3 of max_iter: 10\n",
            "iteration: 4 of max_iter: 10\n",
            "iteration: 5 of max_iter: 10\n",
            "iteration: 6 of max_iter: 10\n",
            "iteration: 7 of max_iter: 10\n",
            "iteration: 8 of max_iter: 10\n",
            "iteration: 9 of max_iter: 10\n",
            "iteration: 10 of max_iter: 10\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# --- Elbow method ---\n",
        "\n",
        "vector_documents_test = vectorizer.transform(clean_test_clustering)\n",
        "\n",
        "# In that array we will store the perplexity value to measure the performance\n",
        "performance = []\n",
        "for num_of_topics in range(2, 21, 1):\n",
        "    print(\"Number of topics - \", num_of_topics)\n",
        "    lda = LatentDirichletAllocation(n_components=num_of_topics, verbose=1, learning_method='online', max_iter=10)\n",
        "    lda.fit(vector_documents_train)\n",
        "    performance.append(lda.perplexity(vector_documents_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-UaKwXM4K42"
      },
      "source": [
        "Now let's plot the graph and find the optimal number of topics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T18:34:10.288298Z",
          "iopub.status.busy": "2024-05-26T18:34:10.287952Z",
          "iopub.status.idle": "2024-05-26T18:34:10.549173Z",
          "shell.execute_reply": "2024-05-26T18:34:10.548161Z",
          "shell.execute_reply.started": "2024-05-26T18:34:10.288257Z"
        },
        "id": "O_48opnLYHku",
        "outputId": "c5dcd945-b9f4-4d5d-8981-13bd9af7af6a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(range(2, 21),performance)\n",
        "plt.ylabel('Perplexity value')\n",
        "plt.xlabel('Number of topics')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbm4AOl44VIG"
      },
      "source": [
        "Remember that lower perplexity does not always mean the best performance. As seen from the graph above, the optimal values for the number of topics are in a range from 5 to 10. Let's explore the topics with the case of 5. We will print the most important words corresponding to the topics. But this time we will increase the number of iterations for LDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T18:34:10.550879Z",
          "iopub.status.busy": "2024-05-26T18:34:10.550599Z",
          "iopub.status.idle": "2024-05-26T18:48:09.929183Z",
          "shell.execute_reply": "2024-05-26T18:48:09.928211Z",
          "shell.execute_reply.started": "2024-05-26T18:34:10.550853Z"
        },
        "id": "c3UmuuKQ7KN8",
        "outputId": "76b428ed-8907-45ed-841d-137cc9fd86a8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 of max_iter: 30\n",
            "iteration: 2 of max_iter: 30\n",
            "iteration: 3 of max_iter: 30\n",
            "iteration: 4 of max_iter: 30\n",
            "iteration: 5 of max_iter: 30\n",
            "iteration: 6 of max_iter: 30\n",
            "iteration: 7 of max_iter: 30\n",
            "iteration: 8 of max_iter: 30\n",
            "iteration: 9 of max_iter: 30\n",
            "iteration: 10 of max_iter: 30\n",
            "iteration: 11 of max_iter: 30\n",
            "iteration: 12 of max_iter: 30\n",
            "iteration: 13 of max_iter: 30\n",
            "iteration: 14 of max_iter: 30\n",
            "iteration: 15 of max_iter: 30\n",
            "iteration: 16 of max_iter: 30\n",
            "iteration: 17 of max_iter: 30\n",
            "iteration: 18 of max_iter: 30\n",
            "iteration: 19 of max_iter: 30\n",
            "iteration: 20 of max_iter: 30\n",
            "iteration: 21 of max_iter: 30\n",
            "iteration: 22 of max_iter: 30\n",
            "iteration: 23 of max_iter: 30\n",
            "iteration: 24 of max_iter: 30\n",
            "iteration: 25 of max_iter: 30\n",
            "iteration: 26 of max_iter: 30\n",
            "iteration: 27 of max_iter: 30\n",
            "iteration: 28 of max_iter: 30\n",
            "iteration: 29 of max_iter: 30\n",
            "iteration: 30 of max_iter: 30\n",
            "Topic 1:\t [football, season, league, team, game, born, played, professional, games, national]\n",
            "Topic 2:\t [war, states, united, state, government, british, century, president, french, army]\n",
            "Topic 3:\t [city, new, states, university, united, located, north, york, south, area]\n",
            "Topic 4:\t [used, use, time, church, magazine, published, research, species, work, called]\n",
            "Topic 5:\t [film, american, born, album, series, released, band, known, music, best]\n"
          ]
        }
      ],
      "source": [
        "lda = LatentDirichletAllocation(n_components=5, verbose=1, learning_method='online', max_iter=30)\n",
        "lda.fit(vector_documents_train)\n",
        "\n",
        "for i in range(len(lda.components_)):\n",
        "    sorted_terms = lda.components_[i].argsort()[::-1]\n",
        "    concatenated_terms = '[' + ', '.join(vocab[i] for i in sorted_terms[:10]) + ']'\n",
        "    print (f'Topic {i + 1}:\\t', concatenated_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kytWtswtUsBs"
      },
      "source": [
        "Seems like some topics coincide. Let's try now with 7 topics and 50 iterations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T18:48:09.930984Z",
          "iopub.status.busy": "2024-05-26T18:48:09.930669Z",
          "iopub.status.idle": "2024-05-26T19:11:26.306492Z",
          "shell.execute_reply": "2024-05-26T19:11:26.305419Z",
          "shell.execute_reply.started": "2024-05-26T18:48:09.930956Z"
        },
        "id": "E3-2k67uTPMN",
        "outputId": "d1b85a6a-b596-40ee-b23a-bd77be592219",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1 of max_iter: 50\n",
            "iteration: 2 of max_iter: 50\n",
            "iteration: 3 of max_iter: 50\n",
            "iteration: 4 of max_iter: 50\n",
            "iteration: 5 of max_iter: 50\n",
            "iteration: 6 of max_iter: 50\n",
            "iteration: 7 of max_iter: 50\n",
            "iteration: 8 of max_iter: 50\n",
            "iteration: 9 of max_iter: 50\n",
            "iteration: 10 of max_iter: 50\n",
            "iteration: 11 of max_iter: 50\n",
            "iteration: 12 of max_iter: 50\n",
            "iteration: 13 of max_iter: 50\n",
            "iteration: 14 of max_iter: 50\n",
            "iteration: 15 of max_iter: 50\n",
            "iteration: 16 of max_iter: 50\n",
            "iteration: 17 of max_iter: 50\n",
            "iteration: 18 of max_iter: 50\n",
            "iteration: 19 of max_iter: 50\n",
            "iteration: 20 of max_iter: 50\n",
            "iteration: 21 of max_iter: 50\n",
            "iteration: 22 of max_iter: 50\n",
            "iteration: 23 of max_iter: 50\n",
            "iteration: 24 of max_iter: 50\n",
            "iteration: 25 of max_iter: 50\n",
            "iteration: 26 of max_iter: 50\n",
            "iteration: 27 of max_iter: 50\n",
            "iteration: 28 of max_iter: 50\n",
            "iteration: 29 of max_iter: 50\n",
            "iteration: 30 of max_iter: 50\n",
            "iteration: 31 of max_iter: 50\n",
            "iteration: 32 of max_iter: 50\n",
            "iteration: 33 of max_iter: 50\n",
            "iteration: 34 of max_iter: 50\n",
            "iteration: 35 of max_iter: 50\n",
            "iteration: 36 of max_iter: 50\n",
            "iteration: 37 of max_iter: 50\n",
            "iteration: 38 of max_iter: 50\n",
            "iteration: 39 of max_iter: 50\n",
            "iteration: 40 of max_iter: 50\n",
            "iteration: 41 of max_iter: 50\n",
            "iteration: 42 of max_iter: 50\n",
            "iteration: 43 of max_iter: 50\n",
            "iteration: 44 of max_iter: 50\n",
            "iteration: 45 of max_iter: 50\n",
            "iteration: 46 of max_iter: 50\n",
            "iteration: 47 of max_iter: 50\n",
            "iteration: 48 of max_iter: 50\n",
            "iteration: 49 of max_iter: 50\n",
            "iteration: 50 of max_iter: 50\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(learning_method='online', max_iter=50, n_components=7,\n",
              "                          verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, max_iter=50, n_components=7,\n",
              "                          verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, max_iter=50, n_components=7,\n",
              "                          verbose=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=7, verbose=1, learning_method='online', max_iter=50)\n",
        "lda.fit(vector_documents_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_important_words = []\n",
        "for i in range(len(lda.components_)):\n",
        "    sorted_terms = lda.components_[i].argsort()[::-1]\n",
        "    concatenated_terms = '[' + ', '.join(vocab[i] for i in sorted_terms[:10]) + ']'\n",
        "    most_important_words.append(vocab[sorted_terms[0]])\n",
        "    print (f'Topic {i + 1}:\\t', concatenated_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhwRjPj3YO2Q",
        "outputId": "723b13a9-acf2-489b-821c-dbf4cb057089"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1:\t [used, use, time, magazine, century, language, called, form, developed, published]\n",
            "Topic 2:\t [film, american, series, born, television, directed, known, best, films, actor]\n",
            "Topic 3:\t [war, university, states, united, state, school, government, british, president, air]\n",
            "Topic 4:\t [album, band, music, released, song, rock, american, singer, single, studio]\n",
            "Topic 5:\t [city, new, south, north, states, located, area, united, county, york]\n",
            "Topic 6:\t [football, season, league, team, born, game, played, national, professional, games]\n",
            "Topic 7:\t [family, species, king, church, known, court, john, english, genus, death]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOaPI6F_eWjM"
      },
      "source": [
        "Now this looks way better! Let's try to find the number of the corresponding most important topics in the dataset of contexts!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_important_topics = [0 for i in range(7)]\n",
        "for doc in clean_test_clustering:\n",
        "  topic_vector = lda.transform(vectorizer.transform([doc])[0])[0]\n",
        "  max_i = 0\n",
        "  max_vector_value = topic_vector[0]\n",
        "  for i in range(1, 7):\n",
        "    if topic_vector[i] > max_vector_value:\n",
        "      max_vector_value = topic_vector[i]\n",
        "      max_i = i\n",
        "  most_important_topics[max_i] += 1\n",
        "print(most_important_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk2H4liWMiQ3",
        "outputId": "e97e1679-63b8-4322-a8c7-1329cad30197"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5129, 5589, 4506, 3001, 4270, 2399, 1915]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(most_important_words)\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=most_important_words, y=most_important_topics)],\n",
        "    layout_title_text=\"Comparison\"\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "SjCnD2k1Qb3_",
        "outputId": "7cd34be9-4deb-4051-af3c-97970b9b04e7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['used', 'film', 'war', 'album', 'city', 'football', 'family']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"4633996d-7514-4612-be08-ceac5fd99aec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4633996d-7514-4612-be08-ceac5fd99aec\")) {                    Plotly.newPlot(                        \"4633996d-7514-4612-be08-ceac5fd99aec\",                        [{\"x\":[\"used\",\"film\",\"war\",\"album\",\"city\",\"football\",\"family\"],\"y\":[5129,5589,4506,3001,4270,2399,1915],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparison\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4633996d-7514-4612-be08-ceac5fd99aec');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-2nHshiecv6"
      },
      "source": [
        "# **Word Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:11:26.308348Z",
          "iopub.status.busy": "2024-05-26T19:11:26.307940Z",
          "iopub.status.idle": "2024-05-26T19:11:39.730373Z",
          "shell.execute_reply": "2024-05-26T19:11:39.725145Z",
          "shell.execute_reply.started": "2024-05-26T19:11:26.308318Z"
        },
        "id": "dVL01mD6Po38",
        "outputId": "c7346905-9360-4c10-e954-f285f7cde311",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:11:39.736864Z",
          "iopub.status.busy": "2024-05-26T19:11:39.735942Z",
          "iopub.status.idle": "2024-05-26T19:11:51.488838Z",
          "shell.execute_reply": "2024-05-26T19:11:51.487623Z",
          "shell.execute_reply.started": "2024-05-26T19:11:39.736813Z"
        },
        "id": "sJyRD1gpem91",
        "outputId": "afb3b9a2-041f-4a66-8aa6-edac656a6978",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When did Wordsworth initially attack Burke?\n",
            "The clash between Henry IV and the pope was part of what greater conflict?\n",
            "What historical event brought about the fall of the Robespierres?\n",
            "After splitting into sentences by special signs\n",
            "[['When did Wordsworth initially attack Burke?'], ['The clash between Henry IV and the pope was part of what greater conflict?'], ['What historical event brought about the fall of the Robespierres?']]\n",
            "['when', 'did', 'wordsworth', 'initially', 'attack', 'burke']\n",
            "['the', 'clash', 'between', 'henry', 'iv', 'and', 'the', 'pope', 'was', 'part', 'of', 'what', 'greater', 'conflict']\n",
            "['what', 'historical', 'event', 'brought', 'about', 'the', 'fall', 'of', 'the', 'robespierres']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "18937"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare the data\n",
        "\n",
        "train_ = []\n",
        "# Iterate through each document in the input data\n",
        "# We will be working with questions this time\n",
        "for doc in json_train['data']:\n",
        "    # Add the question to the texts list\n",
        "    train_.append(doc['question'])\n",
        "\n",
        "# To see some examples\n",
        "print(train_[0])\n",
        "print(train_[1])\n",
        "print(train_[2])\n",
        "\n",
        "# Just in case the question contains more than 1 sentence\n",
        "sentences_train = [re.split('[?!.]\\s', doc) for doc in train_]\n",
        "print(\"After splitting into sentences by special signs\")\n",
        "print(sentences_train[:3])\n",
        "\n",
        "#Use the command from pandas library to flatten the structure into one big array of sentences\n",
        "sentences_train = list(flatten(sentences_train))\n",
        "#sentences_train[:20]\n",
        "\n",
        "#Cleaning of data by eliminating non-letter characters and tokenize the sentences based on whitespaces\n",
        "tokenized_sentences_train = [re.sub('\\W', ' ', sentence).lower().split() for sentence in sentences_train]\n",
        "#Remove sentences that are only 1 word long\n",
        "tokenized_sentences_train = [sentence for sentence in tokenized_sentences_train if len(sentence) > 1]\n",
        "\n",
        "for sentence in tokenized_sentences_train[:3]:\n",
        "    print(sentence)\n",
        "\n",
        "#Now we can provide data to the algorithm, since the format is right\n",
        "\n",
        "model_train = Word2Vec(tokenized_sentences_train, vector_size=30, min_count=5, window=10)\n",
        "\n",
        "#Check vocabulary size\n",
        "len(model_train.wv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZStRSEzIexXD"
      },
      "source": [
        "# Inspecting embeddings and finding similar words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:11:51.490616Z",
          "iopub.status.busy": "2024-05-26T19:11:51.490246Z",
          "iopub.status.idle": "2024-05-26T19:11:51.518124Z",
          "shell.execute_reply": "2024-05-26T19:11:51.516922Z",
          "shell.execute_reply.started": "2024-05-26T19:11:51.490581Z"
        },
        "id": "gp5t6ZIreyVL",
        "outputId": "437a4b5f-7cef-48b1-9d30-f0fa6909879a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('city', 0.7048143744468689),\n",
              " ('province', 0.6717204451560974),\n",
              " ('state', 0.6647626161575317),\n",
              " ('county', 0.6576027274131775),\n",
              " ('england', 0.6500034332275391),\n",
              " ('region', 0.620689868927002),\n",
              " ('district', 0.5966678261756897),\n",
              " ('continent', 0.5958325266838074),\n",
              " ('town', 0.5951489806175232),\n",
              " ('ravenna', 0.5920096635818481)]"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "term = 'country'\n",
        "\n",
        "model_train.wv[term]\n",
        "model_train.wv.most_similar(term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeeACg7Xe1rP"
      },
      "source": [
        "## *Using t-SNE to visualize the embedding vectors*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrwmPHYAe-RF"
      },
      "source": [
        "\n",
        "We'll proceed to generate visualizations of certain word vectors in a three-dimensional space utilizing t-SNE. Since we have a large vocabulary, we will consider a random subset composed of 1000 terms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:11:51.520321Z",
          "iopub.status.busy": "2024-05-26T19:11:51.519687Z",
          "iopub.status.idle": "2024-05-26T19:11:51.541434Z",
          "shell.execute_reply": "2024-05-26T19:11:51.540152Z",
          "shell.execute_reply.started": "2024-05-26T19:11:51.520286Z"
        },
        "id": "nSz-v8Y6-zJG",
        "outputId": "ceec03f8-996e-4ad4-f8ee-90c12a151a22",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['humphrey', 'immigrant', 'coloratura', 'chechen', 'fortification', 'fabrice', 'buttons', 'socially', 'trophy', 'mama', 'round', 'anand', 'swear', 'hoosiers', 'athlete', 'newport', 'nutrition', 'throw', 'criticize', 'waht', 'florian', 'thicke', 'ladies', 'keenan', 'chapman', 'saturn', 'pennines', 'kelli', 'heterosexual', 'comeback', 'jewels', 'champ', 'hicks', 'vii', 'hamadan', 'vendéen', 'require', 'stores', 'chapter', 'roosevelt', 'sammy', 'moist', 'lincoln', 'possibility', 'unlv', 'byrd', 'strawberry', 'oval', 'merseyside', 'voice', 'abandoned', 'ekaterina', 'kangxi', 'guzmán', '1931', 'nichols', 'criss', 'archipelago', 'sonam', 'comedy', 'riverside', 'jeux', 'loose', 'arrondissement', 'reform', 'truly', 'interim', 'whats', 'assets', 'schmeling', '1761', 'american', 'compton', 'atlético', '5', 'caribbean', 'underneath', 'arden', 'tube', 'clothing', 'aeneas', 'pizarro', 'estonian', 'ninth', 'mauritius', 'circuit', 'northumbrian', 'lynch', 'portray', 'bretagne', 'mcnabb', 'recruited', 'trick', 'gottfried', 'transmissions', 'judaism', 'peking', 'prototype', 'hulk', 'automaton', 'pops', 'backgrounds', 'stomp', 'sabatini', '1910', 'sant', 'brit', '2nd', 'libre', 'airline', 'villiage', 'chengdu', 'embassy', 'record', '31', 'goes', 'canals', 'elements', 'must', 'seneca', 'account', 'gioachino', 'katrina', 'offspring', 'rama', 'fifteenth', 'clerics', 'rus', 'woolf', '1638', 'catalina', 'conway', 'guidoni', 'aspen', 'dealt', 'positive', 'grey', 'valdez', 'striking', 'ke', 'renáta', 'bikes', 'practice', 'christianity', 'climate', 'ia', 'wasted', 'fisher', 'pyrenees', 'statute', 'tools', 'qinhuangdao', 'asturias', 'hillary', 'facial', '23rd', 'footballers', 'primates', 'griffon', 'locations', 'boorman', 'fils', 'weapon', 'generally', 'advertised', 'go', 'divisions', 'squirrel', 'municipalities', 'purdue', 'clermont', 'fertilization', 'filming', 'remembering', 'fred', 'synagogue', 'gonzales', 'more', 'archdiocese', 'stretch', 'sprague', 'harriet', '330', 'thanksgiving', 'minuit', 'neill', 'poverty', 'deutsche', '1871', 'taught', 'elvey', 'barry', 'nfc', 'monarch', 'mystery', 'accountability', 'legitimacy', 'conform', 'diseases', 'hudson', 'cleo', 'always', 'welterweight', 'symphony', 'resulted', 'fluid', 'arno', 'radical', 'lucassen', 'oversaw', 'gaddafi', 'grandfather', 'tejano', 'honeymoon', 'almqvist', 'libertarian', 'faster', 'lambert', 'mayoral', 'amendments', 'extraction', 'kindergarten', 'randy', 'aspiration', 'maturing', 'swansea', 'becoming', 'military', 'documenting', 'objector', 'denver', 'needed', 'consistently', 'permit', 'eternal', 'tackle', 'kelley', 'bus', 'worcester', 'lonesome', 'willy', 'mechanics', 'retailing', 'dubus', 'ammunition', 'banská', 'william', 'appliance', 'kovacevic', 'rescue', 'providing', 'greenberg', 'storage', 'daylight', 'crosses', 'photograph', 'nails', 'accuse', 'watches', 'garland', 'leach', 'commencement', 'initiatives', 'significance', 'islamic', 'sr', 'ike', 'overall', 'player', 'warned', 'conquest', 'manga', '51', 'dismal', 'nair', 'mehta', 'jordanian', '2007', 'establishment', 'costume', 'paralyzed', 'less', 'gram', 'roh', 'darren', 'sakya', 'relationships', 'gordon', 'entertainers', 'fool', 'heart', 'rowe', 'sees', 'hadley', 'hungary', 'mekas', 'honorific', 'feathers', 'switch', 'elton', 'purposes', 'coin', 'allard', 'ancient', 'dana', 'traces', 'transatlantic', 'paolo', '52nd', 'mobster', 'resolution', 'gurney', 'fighter', 'explaining', 'passive', 'pack', 'tabula', 'casualty', 'halifax', 'copa', 'revived', 'las', 'fraction', 'ling', 'wilmington', 'dressed', 'nyc', 'slightly', 'dandy', 'indira', 'forefront', 'annacone', 'otis', 'shopping', 'spaniel', 'lovers', 'declined', 'mathis', 'sir', 'distinct', 'ayer', 'flavored', 'hayward', 'guidelines', 'slip', 'animator', 'parrott', 'teutul', 'stance', 'hiking', 'digital', 'slovak', 'series', 'marshallese', 'waer', '56', 'adamson', 'himalayas', 'granted', 'burgers', 'davenport', 'fbs', 'cf', 'sctv', 'salvador', 'partnerships', 'collar', 'costello', 'brotherhood', 'annapolis', 'breakthrough', 'refuge', 'summertime', 'goodwill', 'refuse', 'jamal', 'cooling', '1815', 'smuggling', 'did', 'specials', 'tunisia', 'museums', 'incarcerated', 'bulk', 'tidewater', 'modular', 'françoise', 'seahawks', 'pressured', 'joplin', 'ash', 'circle', 'happiness', 'hesburgh', 'gatherer', '1930', 'sitting', 'jang', 'grill', 'fleming', 'motorcycle', 'standard', 'invented', 'poe', 'taxis', 'intelligence', 'rilke', 'reinforced', 'imf', 'beats', 'thursday', 'fulfill', 'revolve', '38', 'newer', 'years', 'decrease', 'lyon', 'promotes', 'alain', 'waiter', 'wai', 'simon', 'hermitage', 'claudia', 'joshua', 'nagy', 'theology', 'nightingale', 'fleury', '83rd', 'snoop', 'cochran', 'sturm', 'deciding', 'piven', 'harrier', 'mental', 'originaly', 'bedroom', 'rooted', 'neighboring', 'connector', 'zorro', 'oahu', 'wimbledon', 'comparing', 'decoders', 'residence', 'mariana', 'infected', 'thinkers', 'apes', 'globally', 'hocking', 'giant', 'already', 'bombs', 'televised', 'saxophone', 'laser', 'preseason', 'stewart', 'engaging', 'midlands', 'identifies', 'mauricio', 'hendricks', 'struggles', 'blood', 'laserdiscs', 'excellent', 'prima', 'tennessee', 'bernese', 'dominions', 'michaël', 'major', 'bop', 'ty', 'loudon', 'mangum', 'flyers', 'montfort', 'accent', '111', 'react', 'examined', 'aristotelia', 'annual', 'antibacterial', 'aren', 'damaging', 'regularly', 'cocoa', 'demand', 'collette', 'serves', 'lease', 'corona', 'islands', 'hugh', 'springer', 'essay', 'afterwards', 'yuan', 'insects', 'shaker', 'rodham', 'gq', 'anthropomorphic', 'eruption', 'león', 'ajax', 'hailed', 'mulberry', 'horne', 'choice', 'céline', 'site', 'flyleaf', 'again', 'guaranteed', 'albanian', 'estonia', 'studios', 'bay', 'lagoon', 'fantastic', 'class', 'compositions', 'explored', 'towers', 'shenzhou', 'economics', 'schoenaerts', 'homestead', 'alphonse', 'loving', 'pricing', 'reagan', 'signing', 'aniston', 'due', 'motivation', 'frosty', 'darts', 'ghai', 'panthers', 'card', 'horace', 'ambassador', '1820', 'cambridge', 'bays', 'return', 'enchanted', 'bogle', 'priced', 'southside', 'assembly', 'laughlin', 'carver', 'force', 'keynes', 'nemo', 'miracle', 'eui', 'tnt', 'beggar', '97', 'ptarmigan', 'kangri', 'bag', 'ghosts', 'waterford', 'pyrite', 'carillo', 'censored', 'ag', 'leoš', 'ultra', 'guns', 'grossed', 'offs', 'submission', 'mountbatten', 'calendula', '29th', 'news', 'palo', 'simulator', 'cypriots', 'bogart', '09', 'angry', 'ka', 'grizzly', 'goat', 'watching', 'shirt', 'took', 'feminine', 'elephant', 'instruments', 'moroccan', 'krusty', 'shtokavian', 'cuba', 'spit', 'apology', 'printmaker', 'land', 'comcast', 'leonardo', 'accurate', 'hubei', 'prodigy', 'kara', 'locale', 'rohinton', 'uscgc', 'mamas', 'smoky', 'announcing', 'headstones', 'underwood', 'preschool', 'sled', 'locality', 'invincible', 'huntington', 'benefited', 'objects', 'riders', 'rubber', 'slavery', 'kourtney', 'svetlana', 'foley', 'nirvana', 'skybridge', 'edit', 'rowing', 'kuznetsova', 'arbor', 'newark', 'ruins', 'daryl', 'caucasian', 'melville', 'wiles', 'songs', 'columbus', 'cain', 'cricket', 'hamlet', 'sour', 'wilde', 'couple', 'autopsy', 'arabic', 'designed', 'westwood', 'venezuela', 'grundy', 'bedřich', 'selkirk', 'screenwriting', 'gatherers', '27', 'riding', 'implementing', 'ordered', 'audio', 'ningbo', 'turkic', 'read', 'inclán', 'variety', 'suburban', 'baseman', 'needle', 'hayley', 'aaron', 'gogh', 'ft', 'specialise', 'sexy', 'concentrated', 'kassir', 'flanagan', 'claudie', 'aragon', 'tender', 'alley', 'unholy', 'industrial', 'mathematics', 'procedure', 'wears', 'interpreted', 'standards', 'channels', 'pearson', 'widow', 'misfits', 'heat', 'inhabited', 'written', 'gregor', 'unanimous', 'masterson', 'mixed', 'traits', 'goodman', 'vinnie', 'capitalist', 'clubs', 'valerie', 'featherweight', 'murdoch', 'boiled', 'chan', 'gibraltar', 'nursery', 'circus', 'nielsen', 'miguel', 'aspect', 'text', 'velvet', 'effected', 'travelled', 'jumper', 'tippett', 'slavic', 'custody', 'holstein', 'bedknobs', 'rifles', 'fresco', 'ordering', 'mcenroe', 'kepler', 'gardens', 'burma', 'genghis', 'lectures', '19th', 'thuringia', 'kmt', 'retired', 'kerr', 'finnic', 'policy', 'balance', 'vacant', 'ephraim', 'flourished', 'fir', 'hello', 'familia', 'portishead', 'legislature', 'sv', 'gabriela', 'insisted', 'ashton', 'morrissey', 'speakers', 'willis', 'petition', 'identification', 'chest', 'milano', 'gospels', 'shangri', 'don', 'spelled', 'dam', 'beta', 'galician', 'depleted', 'manuel', 'margarethe', 'delivering', 'city', 'specification', 'byung', 'examines', 'jehovah', 'qualify', 'citys', 'merrill', 'rutland', 'lok', 'asian', 'dock', 'portugese', 'advises', 'stopped', 'aston', 'nas', 'selim', 'pirates', 'theater', 'presenting', 'tourism', 'lucia', 'leung', 'bands', 'arriving', 'elects', 'restaurants', 'statue', 'forested', 'sons', 'hidden', 'sec', 'predictions', 'banished', 'bug', 'ozone', 'impressive', 'descend', 'varied', 'forks', 'rafters', 'motorway', 'šmíd', 'tenure', 'tongu', 'giving', 'alabama', 'almond', '71st', 'lukas', 'isis', 'part', 'violating', 'contracts', 'aqueduct', 'trainer', 'heroism', 'dim', 'dig', 'čilić', 'dodson', 'ingested', 'gut', 'matterhorn', 'motorcycles', 'galleries', 'depend', 'stepper', 'mayfair', 'anchors', 'hidalgo', 'verne', 'trail', 'pusan', 'sherwood', 'terrible', 'mafia', 'ministerial', 'complex', 'nasdaq', 'indirectly', 'josé', 'packaged', 'bafta', 'marlene', 'pegasus', 'winner', 'rican', 'mes', 'covering', 'antonio', 'django', 'dimensions', 'aiken', 'sia', 'golf', 'dvb', 'relient', 'clueless', 'cheryl', 'ssr', 'cascades', 'parts', 'counties', 'investigative', 'linguists', 'liverpool', 'rhymes', 'underground', 'eddie', 'royale', 'eminem', 'laird', 'tony', 'instrument', 'h2', 'notably', 'seized', 'vida', 'catastrophic', 'invalidated', 'images', 'hiatus', 'diminished', 'naismith', 'valencian', 'supporter', 'suzanne', 'presbyterian', 'machinery', 'devon', 'nightclub', 'roof', 'terriers', '1855', '1809', 'survivors', 'through', 'contagious', 'gather', 'auction', 'scorer', 'jan', 'kleiser', 'flubber', 'siouxsie', 'essentially', 'pirate', 'liberians', 'hull', 'boyle', 'rucker', 'pensacola', 'lions', 'webster', 'jamison', '170', 'camel', 'kafelnikov', 'husbands', '36th', 'seat', 'stereo', 'main', 'copper', 'kline', 'stephan', 'streetcar', 'gonzález', 'evolutionary', 'retailers', 'trent', 'mascot', 'increase', 'stripes', 'introducing', 'adaptation', 'jeremiah', 'eton', 'nigerian', 'laden', 'properly', 'submitted', 'improvement', 'brandenburg', 'clause', 'fault', 'hinds', 'ribble', 'burden', 'coat', 'operative', 'predated', 'antrim', 'requests', 'leads', 'archaemenid', 'gay', '35', 'andrés', 'tallahassee', 'casal', 'undertaken', 'eritrea', 'signatures', 'c', 'ned', 'witherspoon', 'billion', 'wort', 'tennant']\n"
          ]
        }
      ],
      "source": [
        "sampled_train = random.sample(list(model_train.wv.key_to_index), 1000)\n",
        "print(sampled_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:11:51.545769Z",
          "iopub.status.busy": "2024-05-26T19:11:51.543965Z",
          "iopub.status.idle": "2024-05-26T19:11:51.585938Z",
          "shell.execute_reply": "2024-05-26T19:11:51.584698Z",
          "shell.execute_reply.started": "2024-05-26T19:11:51.545726Z"
        },
        "id": "UQWh9t13-33O",
        "outputId": "7873c2a8-5180-4025-c4cb-49eb0a177767",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.1520331 ,  0.00102992,  0.11374427, ...,  0.28551948,\n",
              "         0.04140193, -0.3193955 ],\n",
              "       [-0.15010808,  0.11318211,  0.28637376, ..., -0.09733778,\n",
              "        -0.10468565, -0.4959964 ],\n",
              "       [ 0.05871778,  0.04802268, -0.06460011, ...,  0.0312202 ,\n",
              "         0.02758624, -0.10121597],\n",
              "       ...,\n",
              "       [-0.36891118, -0.22779833, -0.1776077 , ...,  0.5049667 ,\n",
              "         0.39738595, -0.35772583],\n",
              "       [-0.08491669, -0.04774669,  0.12081616, ...,  0.02337912,\n",
              "         0.00192433, -0.17360765],\n",
              "       [ 0.18103692, -0.0752294 ,  0.06733204, ...,  0.14760853,\n",
              "         0.00337984, -0.18921122]], dtype=float32)"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Get the word vectors for the terms\n",
        "word_vectors_train = model_train.wv[sampled_train]\n",
        "word_vectors_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:11:51.595915Z",
          "iopub.status.busy": "2024-05-26T19:11:51.592069Z",
          "iopub.status.idle": "2024-05-26T19:12:01.134148Z",
          "shell.execute_reply": "2024-05-26T19:12:01.133099Z",
          "shell.execute_reply.started": "2024-05-26T19:11:51.595864Z"
        },
        "id": "nxYYR5Goe4-4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Provide the vectors to SNE\n",
        "tsne = TSNE(n_components=3, n_iter=2500)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors_train)\n",
        "\n",
        "#Transform data into 3 columns\n",
        "x, y, z = np.transpose(tsne_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVy-o9dtfFPC"
      },
      "source": [
        "Build the 3D plot, we also label some points to see the words they correspond to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:12:01.135864Z",
          "iopub.status.busy": "2024-05-26T19:12:01.135508Z",
          "iopub.status.idle": "2024-05-26T19:12:13.888970Z",
          "shell.execute_reply": "2024-05-26T19:12:13.887749Z",
          "shell.execute_reply.started": "2024-05-26T19:12:01.135828Z"
        },
        "id": "rLC_CYU7fGHE",
        "outputId": "0ad45816-ddec-4806-fed9-88fe77dbadfc",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.18.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->plotly) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:12:37.006302Z",
          "iopub.status.busy": "2024-05-26T19:12:37.005974Z",
          "iopub.status.idle": "2024-05-26T19:12:37.076063Z",
          "shell.execute_reply": "2024-05-26T19:12:37.075020Z",
          "shell.execute_reply.started": "2024-05-26T19:12:37.006263Z"
        },
        "id": "S1BP_Bj3fIyM",
        "outputId": "9a8c6a7c-586f-46a0-e916-c59ed35bc587",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"b99ec160-061e-439a-aa0d-6b713f642b4a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b99ec160-061e-439a-aa0d-6b713f642b4a\")) {                    Plotly.newPlot(                        \"b99ec160-061e-439a-aa0d-6b713f642b4a\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"line\":{\"width\":3},\"size\":5},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"humphrey\",\"immigrant\",\"coloratura\",\"chechen\",\"fortification\",\"fabrice\",\"buttons\",\"socially\",\"trophy\",\"mama\",\"round\",\"anand\",\"swear\",\"hoosiers\",\"athlete\",\"newport\",\"nutrition\",\"throw\",\"criticize\",\"waht\",\"florian\",\"thicke\",\"ladies\",\"keenan\",\"chapman\",\"saturn\",\"pennines\",\"kelli\",\"heterosexual\",\"comeback\",\"jewels\",\"champ\",\"hicks\",\"vii\",\"hamadan\",\"vendéen\",\"require\",\"stores\",\"chapter\",\"roosevelt\",\"sammy\",\"moist\",\"lincoln\",\"possibility\",\"unlv\",\"byrd\",\"strawberry\",\"oval\",\"merseyside\",\"voice\",\"abandoned\",\"ekaterina\",\"kangxi\",\"guzmán\",\"1931\",\"nichols\",\"criss\",\"archipelago\",\"sonam\",\"comedy\",\"riverside\",\"jeux\",\"loose\",\"arrondissement\",\"reform\",\"truly\",\"interim\",\"whats\",\"assets\",\"schmeling\",\"1761\",\"american\",\"compton\",\"atlético\",\"5\",\"caribbean\",\"underneath\",\"arden\",\"tube\",\"clothing\",\"aeneas\",\"pizarro\",\"estonian\",\"ninth\",\"mauritius\",\"circuit\",\"northumbrian\",\"lynch\",\"portray\",\"bretagne\",\"mcnabb\",\"recruited\",\"trick\",\"gottfried\",\"transmissions\",\"judaism\",\"peking\",\"prototype\",\"hulk\",\"automaton\",\"pops\",\"backgrounds\",\"stomp\",\"sabatini\",\"1910\",\"sant\",\"brit\",\"2nd\",\"libre\",\"airline\",\"villiage\",\"chengdu\",\"embassy\",\"record\",\"31\",\"goes\",\"canals\",\"elements\",\"must\",\"seneca\",\"account\",\"gioachino\",\"katrina\",\"offspring\",\"rama\",\"fifteenth\",\"clerics\",\"rus\",\"woolf\",\"1638\",\"catalina\",\"conway\",\"guidoni\",\"aspen\",\"dealt\",\"positive\",\"grey\",\"valdez\",\"striking\",\"ke\",\"renáta\",\"bikes\",\"practice\",\"christianity\",\"climate\",\"ia\",\"wasted\",\"fisher\",\"pyrenees\",\"statute\",\"tools\",\"qinhuangdao\",\"asturias\",\"hillary\",\"facial\",\"23rd\",\"footballers\",\"primates\",\"griffon\",\"locations\",\"boorman\",\"fils\",\"weapon\",\"generally\",\"advertised\",\"go\",\"divisions\",\"squirrel\",\"municipalities\",\"purdue\",\"clermont\",\"fertilization\",\"filming\",\"remembering\",\"fred\",\"synagogue\",\"gonzales\",\"more\",\"archdiocese\",\"stretch\",\"sprague\",\"harriet\",\"330\",\"thanksgiving\",\"minuit\",\"neill\",\"poverty\",\"deutsche\",\"1871\",\"taught\",\"elvey\",\"barry\",\"nfc\",\"monarch\",\"mystery\",\"accountability\",\"legitimacy\",\"conform\",\"diseases\",\"hudson\",\"cleo\",\"always\",\"welterweight\",\"symphony\",\"resulted\",\"fluid\",\"arno\",\"radical\",\"lucassen\",\"oversaw\",\"gaddafi\",\"grandfather\",\"tejano\",\"honeymoon\",\"almqvist\",\"libertarian\",\"faster\",\"lambert\",\"mayoral\",\"amendments\",\"extraction\",\"kindergarten\",\"randy\",\"aspiration\",\"maturing\",\"swansea\",\"becoming\",\"military\",\"documenting\",\"objector\",\"denver\",\"needed\",\"consistently\",\"permit\",\"eternal\",\"tackle\",\"kelley\",\"bus\",\"worcester\",\"lonesome\",\"willy\",\"mechanics\",\"retailing\",\"dubus\",\"ammunition\",\"banská\",\"william\",\"appliance\",\"kovacevic\",\"rescue\",\"providing\",\"greenberg\",\"storage\",\"daylight\",\"crosses\",\"photograph\",\"nails\",\"accuse\",\"watches\",\"garland\",\"leach\",\"commencement\",\"initiatives\",\"significance\",\"islamic\",\"sr\",\"ike\",\"overall\",\"player\",\"warned\",\"conquest\",\"manga\",\"51\",\"dismal\",\"nair\",\"mehta\",\"jordanian\",\"2007\",\"establishment\",\"costume\",\"paralyzed\",\"less\",\"gram\",\"roh\",\"darren\",\"sakya\",\"relationships\",\"gordon\",\"entertainers\",\"fool\",\"heart\",\"rowe\",\"sees\",\"hadley\",\"hungary\",\"mekas\",\"honorific\",\"feathers\",\"switch\",\"elton\",\"purposes\",\"coin\",\"allard\",\"ancient\",\"dana\",\"traces\",\"transatlantic\",\"paolo\",\"52nd\",\"mobster\",\"resolution\",\"gurney\",\"fighter\",\"explaining\",\"passive\",\"pack\",\"tabula\",\"casualty\",\"halifax\",\"copa\",\"revived\",\"las\",\"fraction\",\"ling\",\"wilmington\",\"dressed\",\"nyc\",\"slightly\",\"dandy\",\"indira\",\"forefront\",\"annacone\",\"otis\",\"shopping\",\"spaniel\",\"lovers\",\"declined\",\"mathis\",\"sir\",\"distinct\",\"ayer\",\"flavored\",\"hayward\",\"guidelines\",\"slip\",\"animator\",\"parrott\",\"teutul\",\"stance\",\"hiking\",\"digital\",\"slovak\",\"series\",\"marshallese\",\"waer\",\"56\",\"adamson\",\"himalayas\",\"granted\",\"burgers\",\"davenport\",\"fbs\",\"cf\",\"sctv\",\"salvador\",\"partnerships\",\"collar\",\"costello\",\"brotherhood\",\"annapolis\",\"breakthrough\",\"refuge\",\"summertime\",\"goodwill\",\"refuse\",\"jamal\",\"cooling\",\"1815\",\"smuggling\",\"did\",\"specials\",\"tunisia\",\"museums\",\"incarcerated\",\"bulk\",\"tidewater\",\"modular\",\"françoise\",\"seahawks\",\"pressured\",\"joplin\",\"ash\",\"circle\",\"happiness\",\"hesburgh\",\"gatherer\",\"1930\",\"sitting\",\"jang\",\"grill\"],\"x\":[-24.273987,-11.338582,2.5895643,11.688861,19.584595,26.318495,26.18093,-24.24071,25.86566,-17.700617,-1.2683392,38.50496,-7.703381,-9.756959,1.5120598,-16.912827,24.248053,-13.864177,7.5968423,-18.871399,12.564093,-7.10935,-1.7157143,-9.760394,-17.503157,22.066776,29.85916,-10.479484,14.308076,8.275703,35.217285,-5.550206,2.2657979,-10.745413,7.8583713,18.391876,16.356833,-14.703061,33.88657,10.525166,16.694933,-9.65086,-23.046085,18.421532,-4.7639613,-30.335108,-31.788671,-14.038934,-19.750998,-16.624622,24.956669,-25.939964,-3.76906,31.034367,16.294548,21.293098,-3.550726,20.207668,0.08635,-16.635,30.47633,-3.1197817,5.6787047,-17.317165,5.8099236,23.304731,-21.939693,9.25385,-4.176108,-13.00057,24.68873,-9.538055,18.344719,-23.609129,14.414947,-6.4259787,16.307919,-17.15317,8.055266,22.337524,1.14196,39.761673,26.556149,-21.386244,-21.964851,5.4500437,-1.6254942,-17.319614,-26.944935,-9.745961,29.921383,-31.303404,-2.2060325,14.979943,-15.588722,18.757532,-11.393632,-0.7137615,-6.8611317,31.41182,-7.4619575,5.253985,11.168651,0.20397772,-16.717312,30.984812,3.7751362,9.00775,3.7901921,33.36386,13.185721,28.530773,-0.24515305,-18.99377,-13.335922,13.5787525,-21.16504,24.647375,-37.74601,31.52332,-15.986957,-14.059067,-10.684605,-17.631895,-13.098994,-20.756155,-33.751507,-35.594536,-16.386806,-25.863743,3.9941483,4.59771,-1.429914,14.936812,-1.3039184,32.392017,-22.295006,25.250546,13.413367,2.8569508,-14.0873375,-9.785658,-3.0949204,-6.668709,-30.852901,-9.978721,3.2746017,17.398577,16.700626,-3.72589,10.731125,-29.709246,-25.685087,-33.00862,16.319183,2.1591582,-6.121964,-12.947898,-15.644303,-21.25849,25.86086,6.0409923,-12.096037,4.659613,-0.9639241,25.407019,18.10299,-19.5255,-28.529171,16.438524,27.133783,-23.575512,-36.681507,13.547517,-21.117706,-23.814726,-13.385293,-22.725412,14.553283,33.392883,17.185253,37.02453,1.6924002,-14.156618,-22.528889,-3.7736616,-41.733303,16.493029,-8.858254,18.996532,-18.385426,18.620794,33.093304,12.649101,-11.959266,-20.512241,11.994448,-8.575634,-22.571491,13.217395,-10.463143,-2.7130425,-22.453115,-3.278225,32.054108,15.905555,25.532616,-26.354057,-29.8611,7.7667837,-27.876059,-2.627733,-1.8929822,-19.677097,-18.189814,23.4225,-21.655104,4.434686,-20.8442,-26.527195,-14.64187,43.868694,31.140543,-3.2994518,-2.5136414,-5.569348,-10.177158,6.1657004,-10.299472,-2.4647787,-3.9607167,-4.1887355,-9.009365,26.898998,1.4295926,-13.939781,-23.87686,3.871623,13.891602,-10.49922,-34.073082,18.163502,-19.380035,22.93356,-5.421117,20.023848,-30.976355,-16.731993,38.515083,11.972506,-18.045706,1.7024539,26.995312,16.565002,11.214239,-17.361034,21.396654,20.16722,-22.837282,-21.908089,-9.659987,-26.532932,-29.633768,-25.189053,8.335195,1.495433,-12.584849,1.1446756,6.5444226,-3.781572,11.158662,29.30714,-10.994761,-32.059418,-19.010899,6.420836,-18.399588,-14.088408,-10.621847,-18.609777,20.539577,-21.827023,28.34365,23.988089,2.2361438,35.673206,-17.382097,-23.182566,8.163766,-1.1691027,-39.559975,14.190183,29.837002,-8.7518015,2.2000155,-18.050995,-13.929294,43.968334,35.243034,-3.2940176,15.937593,-10.682284,15.486165,-18.953245,-2.793404,33.501835,15.773228,-13.630026,6.9818044,-17.92259,-10.641254,13.932236,-35.857143,4.442602,11.396812,2.8671238,-12.100748,-2.163257,-0.54599035,-23.683996,3.552117,-15.664976,17.907452,-20.089758,12.530214,0.3784035,29.297932,-14.488553,-4.86277,16.065548,-33.922714,-10.785966,-0.53244627,-9.387117,23.039062,-28.209187,-2.6752586,-6.9205656,8.890667,12.948043,10.0070305,13.116493,-35.55589,-22.490805,11.374646,-13.17873,3.2882164,-17.765728,-31.45643,19.259811,-9.805059,-7.2138267,9.3868265,12.994389,-3.0443664,3.9543529,17.222202,-14.86099,-18.300875,-28.208805,1.8416907,-2.499333,14.36671,35.858356,-18.739883,-8.883519,18.528915,-20.161901,37.689167,-1.432408,-12.317388,25.016417,26.632301,25.250376,10.83336,21.38838,17.008465,13.052576,27.341839,5.664367,-18.577303,30.429014,19.19992,-16.951424,13.717757,4.9044666,21.824049,21.872484,-36.144577,34.26355,6.640406,-16.864294,-1.5202727,-8.324765,21.204908,6.8137317,-3.380963,32.46053,25.57439,11.281594],\"y\":[1.5429372,-10.010249,11.323707,4.074436,1.7741014,-11.76033,0.73594797,5.7521086,-0.940937,-6.5162477,9.16279,7.6065445,-0.51667625,-19.337727,-3.4501054,13.581106,14.258546,29.161888,11.679085,26.317839,21.095798,12.6503105,20.823517,30.98189,-12.683481,7.105679,0.6062062,12.774109,-15.90276,-0.66424656,-2.0623279,21.082743,10.918894,-10.281517,-2.0534835,-15.098939,-12.895336,15.022915,1.6629823,8.326053,-12.463544,-3.8487022,-7.602648,11.048051,-4.5497804,9.950699,-6.767673,-2.1855469,-8.329771,-0.7990954,-0.028034518,-15.984819,8.032651,8.842742,-3.546494,-0.13952596,-22.407526,-17.155855,-3.063609,-11.893194,1.5859277,10.027534,-1.5369525,-13.86416,-6.161794,12.902683,-11.833598,3.53301,-3.788213,-9.968856,-11.654037,-16.744596,-11.612999,-0.8971705,18.724733,-14.211375,-8.386036,7.193475,-3.1980634,-12.587257,4.3939586,1.2445824,9.089097,17.751987,-8.194691,-9.085465,-13.980406,7.239511,14.507987,9.389731,-0.6356231,3.515407,-29.614958,-5.3815627,26.697094,-2.898469,-3.0996032,0.015350638,-2.63316,2.048336,24.656637,8.169308,-10.456431,12.627177,3.4096906,-2.1218421,8.439762,8.183979,7.0919886,2.1416948,7.5741262,5.6091504,-2.0401044,-11.630598,-1.6199427,-4.313163,19.593988,12.163797,-11.107992,-13.630279,3.0107133,-0.8131013,31.251747,20.747732,-21.244057,-8.541912,6.450962,15.977759,-10.762866,15.00567,-5.280805,18.306921,17.656347,0.0865009,-27.162807,1.4497827,-2.2254012,-6.1811028,-17.302532,-5.351806,-9.036986,1.1927919,-9.299079,28.16855,14.02678,6.2069497,-5.1242566,11.440622,0.8584632,6.0760508,-10.348797,2.4915116,0.7457922,-2.1079962,-0.041703276,3.4481907,-7.148907,-7.795684,0.8489535,18.027603,-15.746155,-5.4272194,-12.781923,13.807787,-24.633999,9.33674,0.70548606,3.8892715,-4.751737,-16.144125,-3.87498,5.9968495,5.738838,-2.9875572,25.958393,-2.2500465,7.229641,-5.3377447,-11.098956,1.8988544,7.8378987,-13.340154,14.39044,-5.104663,-2.9060886,-8.355636,6.6394057,-19.449114,-18.588272,-12.845819,-1.4536238,-18.805126,-14.7815485,-15.054126,0.14748567,3.1049044,15.189117,4.122693,10.685315,-2.8477974,-2.6722531,24.66702,-7.6736193,-5.3820963,-3.511778,-16.12473,-1.5628965,10.359199,-12.880085,6.4796205,14.363917,28.561321,12.280928,-2.5908058,5.595736,-14.605703,8.302795,4.2826686,-7.6328096,-3.3170185,13.856497,1.0853771,-8.334672,-1.0431799,-7.582227,16.656448,-4.36108,-24.54257,-3.521396,-3.7628877,-4.200368,8.95466,10.26112,2.4923372,24.01793,21.724995,-13.6370735,-1.5253804,-6.23396,28.085453,12.522667,-3.6957865,12.566601,9.149826,32.82269,-10.678276,-10.403535,-11.514704,-6.9154263,-1.7328885,7.4021845,-19.244776,-15.962152,-11.715035,0.1893817,-10.348671,-7.1213894,16.503447,8.446453,17.88252,0.77474356,12.065506,6.3843875,-12.893016,-22.623642,6.1169434,10.574731,1.8989491,2.9409003,4.980759,16.286005,-5.275087,8.487185,0.0168677,-6.4672275,-18.849771,28.428059,35.822834,-9.120673,-5.330463,3.0557625,0.5915784,-23.090242,-16.864851,-8.632107,-6.562538,25.082916,-5.1910906,-4.183474,-1.86995,6.746859,7.337255,-10.852355,0.45355,-15.902033,16.246416,-9.018472,-8.46125,-6.9025173,11.315249,-6.773079,4.5306816,12.70168,-7.1220613,-1.284793,-4.740753,5.6830006,19.725811,14.328867,10.239949,19.308867,-24.710468,0.26059872,-3.3201497,-2.8490338,-7.983614,1.3424665,19.126347,-12.514457,-1.5149068,1.9625529,-17.683588,4.342495,14.666806,6.0521,-7.1188564,14.385222,-11.871541,24.370354,-1.8560944,-18.528143,-5.0638194,4.5657024,-5.200987,16.018837,-1.9878197,-13.351897,4.5172577,-8.505085,0.6286751,-8.710022,-20.891596,-16.49168,5.268687,3.8562734,5.9602866,14.013248,-7.106189,5.9607453,-3.203166,-17.59392,2.0265102,7.8362803,2.5612226,-8.366216,-8.009321,-7.1560874,-0.9637011,-13.959019,16.02711,-3.179901,-2.5982306,5.679546,-14.427202,-4.779065,-1.7949673,-5.578364,-0.8993817,-13.90479,-15.490797,22.935617,7.6744537,11.869884,-19.52081,10.809151,9.641124,-2.4571896,20.574219,-7.8868365,21.07759,-14.321985,8.252174,3.5399954,20.884401,-8.142148,6.7214365,-18.061615,-13.103352,18.848114,-15.205861,-19.183323,-7.7028937,-13.2727585,-1.2954519,3.2939076,1.4963802,8.509852,8.073833,-1.7665691,-16.388948],\"z\":[-16.234663,-17.920347,28.864208,-28.756308,4.696061,-13.106841,-11.732981,-14.569982,2.9309988,-16.975779,30.050692,-3.2846198,-2.8599348,6.0788636,-8.251262,10.690863,14.072306,-13.900641,-24.890345,-13.420088,-9.246433,-0.6397022,-15.014147,-16.568233,-6.600321,11.115501,-24.796604,3.8816912,3.9886706,-13.311831,-5.7159534,-6.5948663,-21.568464,-25.56888,-29.181099,18.17927,-2.96873,13.963261,-4.9109383,-0.7987705,-12.064163,-26.058325,-21.980288,19.587547,-6.0578094,9.614036,-5.710646,10.222313,-21.895554,-21.88152,-3.7149162,-4.1990414,17.460978,-15.944732,-10.003367,0.14601965,6.1197596,16.488346,-38.59265,11.578993,-8.713569,3.4491057,-15.334452,-14.027459,-21.0132,4.6252007,3.6537156,9.286846,-39.320675,0.05396049,-2.544568,-16.144632,13.038219,25.439684,5.4897485,19.983988,4.473454,-0.12190273,-17.850565,0.300737,-39.867275,-8.4846945,-17.856237,-19.118425,1.6854829,9.795302,5.454522,9.585108,4.792485,2.0447786,-19.493965,18.51559,-3.1994162,16.12223,-4.7017474,24.845594,-30.41832,-29.059496,-9.115851,-11.774832,-20.54341,-16.17251,-12.105761,0.50492966,18.119858,5.355815,3.7019527,-9.860021,18.763845,7.666887,11.616822,10.514013,-10.515329,-20.616182,-10.438206,-30.781235,-9.520403,-18.888308,-1.9393306,10.114484,5.648401,0.45699605,-19.94117,-18.24752,-1.2570801,-4.666444,18.888678,11.081325,-0.8153866,22.977419,-12.705072,-4.850718,4.8603315,-2.412316,-1.3681947,15.350833,20.329025,0.96318907,0.7912794,8.2971945,-11.055096,-8.276429,-2.5720513,6.931448,13.896277,-30.011877,-16.664171,-3.1487648,-19.996233,-13.344748,7.535969,22.409018,20.93672,11.712583,4.3025246,23.05762,-31.730286,4.9030557,19.725002,9.229986,5.1917915,-9.058526,22.725256,12.937663,0.36071765,-14.390586,18.82541,-23.067509,-5.6040373,-2.589116,1.5906401,18.409182,13.572515,4.539889,3.9200923,3.2567792,9.915295,6.0645204,2.8244383,-1.7367796,11.188614,-12.515479,9.0038,-36.681854,8.338264,3.4397585,9.163359,18.892166,3.309512,5.433154,-13.855879,14.325136,-7.0724254,-5.5927496,-31.114094,4.67067,-14.833537,-3.3899395,28.13992,-15.209995,-35.811897,-6.8285427,20.982092,-35.014015,17.696915,8.408792,16.815283,13.368457,-5.7775536,9.828117,14.850468,-14.181787,-23.110046,13.725699,12.571001,16.499285,21.91255,-18.960062,-14.5342245,21.864067,-15.065011,1.8281505,-11.647919,-10.843959,16.412125,6.7035823,-20.152765,3.5663388,23.052607,-0.15612938,-12.013089,-22.835596,19.663967,2.315655,-8.968192,1.9518082,19.423897,10.95564,-0.3905069,-12.60714,10.216959,9.923848,9.829699,-7.017717,-14.161533,-12.340497,-0.44903916,-10.625435,-0.12381698,-23.770164,-14.8615055,15.260669,0.6079186,26.932865,12.058737,-33.313686,10.341078,-19.391497,3.6533284,19.846575,-22.37814,7.153537,4.5949225,0.23096864,-15.395592,0.89304817,0.7714169,7.5745244,-26.485403,-20.920023,15.662609,12.362585,18.26107,21.444746,-26.915707,-14.551527,-14.360967,-15.028047,13.907447,18.557455,-8.549774,-5.9240403,5.5162516,-3.7458627,-17.528397,6.837035,-17.491087,15.554095,-32.026012,16.806404,11.254654,16.746668,-5.050137,-29.148804,17.360767,22.894833,-36.394894,-2.2258308,-3.9480135,-31.330017,-13.867007,21.444357,4.2042418,23.968227,-19.365568,5.584969,3.2909162,8.366959,-11.956687,24.295286,4.6178274,4.9156933,19.939287,-28.629744,28.557318,15.769189,-16.43945,-3.4386983,-30.463203,15.6429,-12.898147,19.3993,13.652354,17.156338,-30.832731,3.600154,6.388982,-2.4507754,-10.255955,-28.334196,-2.2354722,14.742675,-8.264863,-0.16317658,19.861975,6.2938037,-8.0155525,-15.53916,-0.9322676,15.012252,-8.337973,-5.0613565,-0.18904851,-25.159744,-15.0581,15.456935,-21.223385,-33.858837,14.647188,-0.5380732,-8.586266,-19.418879,18.842655,9.97818,-31.59963,-23.79189,-9.904972,16.174335,6.2130933,2.0851605,5.0683904,-42.07262,7.685515,6.177197,-2.2802682,-12.984752,23.412075,26.517408,-8.681861,-1.7987052,-10.121144,-20.635475,5.9375787,-3.5195951,1.9810519,8.2800865,-13.2860775,14.743056,15.285915,-0.62226814,2.5088193,-5.153299,-14.963108,5.6282706,-7.537827,22.368181,10.777523,9.582158,9.821157,-10.921422,7.0869575,6.8151364,11.7138815,11.869816,19.162834,6.661127,-8.670296,-19.4022,12.857777,-18.693499],\"type\":\"scatter3d\",\"textfont\":{\"size\":15}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b99ec160-061e-439a-aa0d-6b713f642b4a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = px.scatter_3d(x=x[:400],y=y[:400],z=z[:400],text=sampled_train[:400])\n",
        "fig.update_traces(marker=dict(size=5,line=dict(width=3)),textfont_size=15)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn-RBzMYfLkI"
      },
      "source": [
        "Now let's use some numbers to extend the set of words and see if they cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:12:13.891197Z",
          "iopub.status.busy": "2024-05-26T19:12:13.890859Z",
          "iopub.status.idle": "2024-05-26T19:12:26.932031Z",
          "shell.execute_reply": "2024-05-26T19:12:26.930923Z",
          "shell.execute_reply.started": "2024-05-26T19:12:13.891164Z"
        },
        "id": "vZNR8X7tfN6G",
        "outputId": "a035e483-e3f6-46f8-aa96-3c39f5ac5f5e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"9c671c81-0700-439c-9012-929e84579c40\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c671c81-0700-439c-9012-929e84579c40\")) {                    Plotly.newPlot(                        \"9c671c81-0700-439c-9012-929e84579c40\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"line\":{\"width\":3},\"size\":5},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"x\":[6.5303545,3.9155393,6.8018703,4.8029685,4.768361,4.8226047,7.0833564,4.635416,7.1321073,9.2596245,9.76214,7.7677393,9.869612,7.508639,8.277143,1.1195034,-13.922831,10.590886,-3.9927032,-13.751576,-10.988658,5.7984886,-14.39902,17.093002,0.23329024,12.233341,-17.463879,-5.428986,9.89601,16.528408,-4.7811847,-8.504929,11.054554,-4.685712,8.907484,-13.477109,7.4372034,18.295265,-3.6208963,-21.681187,-10.781959,9.49408,3.1082048,5.1098404,10.727972,-13.223317,0.35201594,-16.71427,6.5929704,-6.320911,-8.983024,10.41843,-10.182532,2.7738414,4.519626,-15.507358,-9.236733,-2.560653,1.7416885,15.470221,-5.5171247,-8.127892,16.16183,10.823831,-17.132395,-3.8843362,10.390954,-2.133476,-10.772635,-0.28666374,-4.9252543,-7.800159,-7.1794143,-3.3640478,-15.532225,-5.0146723,0.42759082,-1.562086,6.604467,13.113527,-10.944321,15.721888,15.24138,13.190959,-10.659248,1.2252384,-5.9436846,9.047033,16.323486,4.768361,-5.2844114,3.892443,6.441086,1.3318561,14.862307,-2.5629056,9.057657,5.03014,17.352985,2.2434068,18.542496,-1.1100041,-17.50583,-15.283913,-9.411474,9.789456,9.669579,-1.1054175,-13.452277,-2.046324,4.362046,3.297994,-2.3478763,3.8292458,-2.2721157,-3.0090606,-4.500551,-7.523934,-12.150265,4.541027,-9.9321785,-9.07313,16.375713,19.284277,-9.131187,7.4222965,5.4246597,0.8481287,7.7677574,8.405048,-15.971559,-9.26349,4.035956,10.594733,-7.9366245,9.586831,-10.726713,5.4210863,-9.03183,-10.213742,15.996092,-5.921498,10.223451,-1.7993562,8.03073,4.345566,-2.966089,-12.139004,-6.416558,-6.546462,3.1631842,-10.41466,-7.5395575,19.922216,0.5642929,-4.9573865,6.573846,9.172072,9.835884,0.774905,2.732986,2.823108,-19.734552,-3.6737592,6.857761,3.4097989,0.6880418,-14.089957,17.82012,-4.0100746,14.092666,15.448855,-2.8532531,-12.653151,-11.667856,4.9795547,-1.8126041,1.8828665,4.562265,3.1187775,19.429226,1.8412312,-1.9559228,-0.14288813,17.805908,13.044577,-7.253552,1.9084678,-7.1318603,-20.80681,1.3961794,3.54576,0.17679802,9.860103,-13.295588,8.308652,-6.263841,12.077707,-3.3821208,0.8534665,-15.199902,9.000322,6.451611,-0.838433,-6.5778537,-6.240195,-18.17369,15.811057,12.4174595,-17.522667,-2.3453069,10.097629,13.643055,6.1603866,-4.3142285,-5.2251315,1.7191014,15.200363,-4.030178,5.7733006,3.521246,12.433798,-0.21448043,-5.148822,2.7386327,13.076454,0.84179235,6.6442094,1.7266527,-9.836583,13.148276,-10.381263,-16.907652,11.174007,12.641852,-2.3868613,-11.916221,-5.719118,0.94573915,-9.331584,12.426591,11.679728,13.918707,6.531332,5.5869155,16.458866,10.09942,1.5418605,7.7143087,-5.8452516,16.49981,3.3581553,-3.588414,-2.4250042,4.4089966,-7.930453,-7.3463507,17.143082,-2.9723911,6.0349402,-0.06960851,-24.984009,2.534967,23.154451,11.881593,3.6767929,-12.709177,13.6576395,15.526923,-4.895273,2.7746875,3.8788733,-2.918747,4.9736733,-2.8929276,-7.3330345,-7.2380548,1.4495693,1.7945459,8.02905,-20.856539,3.042403,14.0107975,15.4092245,8.775429,8.673474,-7.9306397,10.400408,1.4242675,-13.135988,-6.535607,-0.83118373,12.665948,9.385092,-12.964675,8.714943,2.3324103,-4.1910505,-3.8110049,-14.061971,15.494948,1.9418117,-23.858768,13.015901,2.3417435,-5.1707506,-4.0725055,7.8883104,-11.137596,8.168996,-11.449478,0.72840476,-1.7520286,2.7293375,1.3523151,-2.1602957,6.3476944,12.370163,6.0858493,-11.942572,9.931909,11.046155,-9.74264,11.930629,-9.442356,8.945933,-2.3172698,22.47295,-6.273499,3.4953842,-21.540583,0.4878115,-7.218554,-7.22816,14.206054,-8.656613,-3.4929607,6.8103957,-10.223093,-0.055602737,-11.772459,1.8608543,-19.95911,-5.165565,0.85149103,0.026677724,-17.563639,6.29609,-5.3873005,-14.635571,0.6049203,-0.359416,-3.989001,-22.391888,1.5895923,-5.0860257,-18.530031,-9.4955845,-3.787141,-3.1773045,-19.873125,-2.6140304,-2.2828622,0.06185078,-8.838137,16.111158,0.98089,-16.384748,-4.133543,6.930365,-13.381152,-6.6102247,1.2050836,15.310356,0.709383,-10.06751,15.329676,15.931271,-8.089033,-14.687142,-14.053358,-11.405433,-5.3248763,-10.074993,3.5724013,9.521829,-9.696059,-14.282977,-2.8121078,13.736733,-19.986513,-0.51278186,7.8275175,2.522286,11.827065,-1.1454811,7.4677577,-4.1700788,11.029306,1.541982,-4.2015924,-2.9663315,-7.6480055,18.259405,10.916009,1.4870371,-10.485101,-18.85781,-10.550565,3.9662497,-1.3243146,2.945711,16.123007,-11.262103,18.06225,-10.991777,11.183621,6.727514,-10.096434,-17.924286,-9.831638,21.873686,-11.528326,-19.031504,-6.359472,1.0349034,13.042659,11.493281,-9.382295,-12.829824,10.867583,15.2651005,15.4381895,9.427997,3.7383757,-11.111,7.091599,-3.9798706,-17.658014,8.834083,-20.158323,-19.905075,1.5400026,-3.25862,7.9368143,6.522519,8.505339,0.2180068,12.72331,2.6246483,-8.04752,-1.0576043,-10.101037,1.6410174,2.4315515,1.0605804,-9.463438,-5.056898,3.4670064,0.5832083,13.119533,6.717351,2.9497268,-5.2177596,10.653975,22.323986,0.85871047,-3.9591162,-12.215009,11.923865,-2.851965,-10.947375,6.129043,9.145717,14.478843,-12.090131,5.1806087,18.363178,-19.42689,4.5415215,3.9693096,-3.3855407,14.655702,-2.2854376,-8.027028,-7.6957045,2.130163,3.0470173,-5.980247,-4.2549934,1.5897962,6.2223177,-9.588373,23.347584,-5.703148,6.786872,-0.81206465,-6.6179366,14.485763,5.2357974,-3.4622257,1.0247344,1.1142069,5.7385306,-4.9316096,18.632204,-5.4027953,5.359249,4.713594,-20.459509,-8.375036,9.249071,0.6467748,-11.373589,14.395034,-4.5474954,-0.29939985,-21.196274,-17.505465,20.335642,-1.9547211,9.092317,7.7291436,-10.558634,16.70798,-4.6106,-14.381521,0.49508974,-6.3746715,15.174644,24.106115,9.74864,-1.6285784,-12.281272,-15.736331,-7.115734,-8.343956,5.4323797,2.405665,-8.512209,6.275078,-7.8941007,-2.3124268,-7.624897,-2.4270082,9.709306,0.052237596,-14.146315,-9.440659,4.504242,-4.545216,-12.184657,9.554153,3.2734945,-18.865492,1.8664376,0.8890304,15.572299,-10.080486,13.134393,2.903133,-1.5684925,3.8284004,-7.000461,11.32356,19.53258,-2.8308012,19.159115,-5.608342,13.662849,5.6476603,16.80688,-6.0523076,-2.8325868,6.2159886,3.7593906,5.972878,1.605802,-3.0625615,14.700347,11.015954,-9.219991,-6.157732,-12.264203,-4.5073524,-11.36488,11.452272,-20.602528,-11.722897,3.3449023,-17.36854,5.7965264,-18.193108,-16.2001,0.97553486,-17.703453,-7.9922366,-7.932637,21.897053,7.597784,3.064018,-14.022511,12.784119,-3.1054463,9.431624,-7.0335035,-2.3067386,-5.12987,6.3995214,-2.5797248,13.697082,-2.8715038,5.733426,-16.359419,-17.42759,5.7755394,-2.7392843,9.248112,-2.5664341,-4.67314,0.39259157,3.3020911,-3.7189736,-6.1704144,-14.271138,8.0765295,-2.4066634,14.015022,-1.6298871,15.299103,-15.051886,-4.569428,-0.46466112,-17.053955,-0.74451786,8.184162,-8.021974,1.161811,7.9252024,-9.270083,3.6276472,-1.3056102,-8.538181,-15.421579,-8.057631,-13.37529,1.3858479,-10.111108,2.3382351,5.1958838,-18.11989,1.0502758,11.557646,-7.0793467,-6.2468014,-19.521072,-0.16008332,14.229482,-11.664428,7.0131183,-8.787273,-4.2345753,-3.2588131,-6.0160937,-4.3876123,-4.5934267,-13.830371,-5.331684,-3.3800046,-16.278692,-2.3438644,20.46793,-10.230154,-7.959818,-10.2591,-16.511517,6.9001656,7.0336514,-12.545266,5.387475,4.445043,-12.334817,-8.235849,9.842565,1.292392,4.341714,7.945552,-0.0023252151,-9.114508,12.600029,15.6806135,-8.229139,3.9589148,6.94371,-8.4420185,-0.043552596,-5.1667843,13.399442,4.0981145,-9.362795,-21.036144,0.32926562,-7.5388947,-10.245451,9.116195,-6.2792897,-5.7610884,0.73371357,-6.1650085,-6.279459,-8.063236,12.276144,5.3359284,0.045988813,-5.1756988,5.2239056,-0.25560883,-10.470231,7.817126,15.579587,-15.739641,8.422304,-4.455497,13.307034,-2.5186396,-20.948225,-6.5647435,9.4040575,-14.723523,16.939632,-1.8455137,-3.172787,-15.296296,12.050594,19.601946,-17.241503,13.484405,-13.55982,-7.1018057,-16.030367,5.0486097,-14.492516,-16.49841,-6.0576315,-13.882435,6.4837866,5.914294,-14.131114,6.4303274,2.805043,11.608293,-4.318206,2.9628217,-4.565588,6.309476,-10.756865,10.176653,0.63131726,-0.8701834,-12.6316,0.21572696,-6.271416,14.436044,-15.928581,-6.8312373,7.818098,2.3021924,11.862667,16.11146,-4.978355,-2.2404752,11.54331,6.4270134,9.914261,-0.109284766,7.0113263,-12.415635,0.9780045,7.5648446,-1.6491536,6.101868,13.793035,-14.010577,16.006678,-2.7582428,-10.365228,2.2325487,-18.382175,9.893054,0.56557316,20.344557,-7.3772635,-12.442305,4.169505,-13.512148,-6.772277,-3.6548705,2.1867151,-5.9637413,5.5816555,-18.339075,-5.7410808,-0.83247817,-5.601623,-5.8487716,-5.1900153,-7.4382567,10.061537,21.986506,0.43762615,-7.9095693,6.5794873,-9.578383,0.99969965,8.43636,1.2049177,0.75896764,11.057873,7.5445585,9.345478,10.693928,8.893915,-2.7947257,-10.218715,3.5522528,-11.662513,-8.971473,-4.1744623,-4.240676,14.708088,-9.05233,-11.94933,5.4626603,-0.28515413,-11.344338,9.579911,1.5666395,-1.7827443,2.4669023,-8.2747135,0.099373944,-5.419437,-0.086282544,3.2745929,-0.7402088,-6.553955,-20.041893,12.623749,17.379202,9.14796,6.4948072,-3.245107,11.678696,2.7604809,-8.817135,-9.828508,10.596803,-7.2103434,0.3534571,-3.4128292,-9.089562,-6.2347484,-3.5707023,-15.459259,-19.276022,-1.7007773,0.5563307,6.368251,3.432427,3.8949213,8.460432,6.5868754,7.106332,9.060444,0.2788881,-17.324678,-3.6942573,7.6173396,-8.057881,-11.212374,-9.612345,16.549469,-5.5828567,-2.5315106,6.6559005,-16.746159,-15.938314,-13.762413,-3.8000386,-11.14391,15.996436,-5.4119544,-10.784632,-4.232132,11.211718,3.830563,-7.0484123,1.4771619,2.3541565,19.486502,0.92536765,3.069761,5.9915676,3.2923868,-4.7840433,6.6260767,2.393276,-4.9443464,19.23093,-6.406672,18.330393,5.938131,3.2748272,-18.868216,4.57626,3.9630435,-5.9742413,-15.0587635,0.24935336,-1.4596192,-11.915971,8.378502,-5.9856586,-3.5774024,7.115258,-1.911065,7.954369,-4.2731547,12.070546,5.7779694,20.529749,-12.306164,5.254873,4.062876,-9.821635,-4.9139237,-12.8519535,-7.184569,6.8790455,11.18769,0.36596015,-0.55535084,-8.102537,3.4655783,7.653794,15.481848,-14.531633,-9.897493,-15.22717,-12.163532,0.779578,-8.250549,-5.6109815,2.7800798,-13.823295,-6.489244,7.6050963,13.222228,-24.787577,-6.7017474,7.3858075,-4.116184,-8.250816,-4.118682,9.460354,-9.2205105,-16.998335,-15.694239,5.8371835,-3.7441218,-14.469759,20.26698,-23.430763,3.1443665,-11.314371,5.918819,-14.537062,14.164002,-18.755001,-7.491283,-18.37516,2.133911,7.88554,16.100107,-16.246153,-0.3987202,14.151427,8.949582,-14.975881,0.31642264,-3.1948674,3.1781754,11.7368555,-14.140161,-4.046535,16.575176,10.682407,11.853318,-11.777366,-0.8317589,16.016142,-10.245365,10.700502,-11.653786,4.0182037,3.927489,12.204026,3.141135,-1.0415243,-21.360802,-14.69544,-4.916127,12.029012,-2.0740757,-8.630688],\"y\":[-19.667423,-22.76784,-23.4158,-20.063744,-23.117786,-21.712803,-20.99091,-19.447277,-23.370516,-20.75586,-21.430994,-18.166056,-17.980751,-18.404606,-23.71841,-9.619738,-10.720276,35.290405,-7.082188,-13.945147,0.5602586,-12.586654,16.784315,-11.572615,0.034849305,-14.275586,10.015385,-3.0604136,-3.712947,-8.532195,-17.138264,15.125277,20.02015,-7.30864,13.180875,5.334775,26.901062,-3.421365,-1.1617202,-8.499443,5.587554,21.10852,14.544588,-10.516432,25.815416,14.157228,17.382969,-9.147511,-14.079957,16.427095,-6.073279,-24.22737,-28.402214,-11.444932,-13.720118,-14.061528,23.208687,-23.566296,-2.442609,15.383438,15.748305,18.37765,5.764639,23.36897,-2.1212761,-19.63106,22.10137,-2.6932983,4.5163198,-14.768082,3.2377713,27.105768,-23.196316,7.1540236,-5.3643913,-15.974462,20.255322,0.24626,20.027822,-22.288164,9.059476,-4.5223365,14.314785,-10.22962,6.7406263,19.371204,-25.267502,28.583618,11.67147,-23.117786,-23.586662,8.208664,5.3470325,-15.640043,-14.010155,-6.8788986,17.809769,-27.349178,-0.060383786,17.114462,-14.618497,23.210472,-11.771061,-1.7028371,-7.1352334,19.884468,-7.7243466,3.2540808,13.533049,0.43335328,-15.21349,25.569378,2.0539618,1.1881672,3.4541779,24.118254,13.78067,22.045956,-1.7942524,-14.571341,-11.033007,9.267833,-3.5312724,10.906349,-31.904222,28.951643,-11.576914,-12.419662,-17.163975,-18.942402,-18.517813,-19.78122,-27.27539,-28.129797,-17.552786,-19.793295,7.936176,4.370029,-4.069902,13.52319,2.2411747,25.968052,-19.44292,23.82498,10.543206,4.3700113,-12.061388,-6.5515637,7.3535485,-11.782005,-24.71564,-12.434345,5.3025327,17.714445,13.1371565,-3.9725218,12.332769,-26.701113,-22.693142,-26.798716,15.316122,4.272784,-7.1667933,-14.43757,-14.443331,-3.7307878,26.131302,9.495178,-9.517669,3.23615,3.6541712,12.39056,20.12407,-19.187794,-25.664652,12.864523,26.26079,-20.184252,-31.379236,12.520739,-16.752752,-19.421127,-13.907173,-18.674871,13.055871,25.67436,11.374528,26.613426,-0.45218444,-14.576008,-16.634802,-2.6486917,-33.47703,22.37843,-15.809124,18.758255,-8.415541,24.270803,27.980837,12.136937,-13.062866,-9.864383,6.250841,-4.8570666,-19.064123,12.323352,-12.063859,-0.616666,-17.629726,-5.8624797,24.388525,16.580744,15.787143,-20.537863,-26.498487,5.446065,-24.681038,-2.591148,-4.773716,-20.312353,-13.792202,22.762384,-19.64271,2.9237635,-7.1082335,-22.47899,-12.158048,34.59745,23.361998,-3.5095475,1.8642905,-7.8408513,-4.3077073,0.023372406,-3.7090778,2.2697957,-4.4477663,-5.25161,-6.2471724,27.211658,-0.2235835,-18.952066,-23.795214,7.637875,19.038998,-8.767591,-26.096033,15.942643,-13.6993885,18.497566,-4.576814,16.499083,-27.78403,-14.844786,32.65367,9.514693,-16.783182,5.8935423,30.447254,20.36514,9.965784,-16.01714,19.424631,7.7953115,-12.83099,-17.095552,-8.249041,-14.933663,-21.524439,-24.641762,12.977249,-1.3480668,-9.533102,4.0561295,10.988626,-3.7894566,8.782249,25.391022,-7.4270425,-28.89633,-16.057798,10.467231,-13.955837,-11.935616,-4.127433,-16.687103,20.435652,-11.244771,31.700226,20.099384,7.2879,27.743023,-18.258257,-21.528572,6.095438,1.5968416,-32.55261,12.638832,27.643316,-10.074432,7.1155877,-20.839457,-13.590799,31.67198,28.991331,-12.123804,12.525645,-4.5744157,12.319724,-16.239529,-3.499201,25.805658,11.689761,-8.16631,4.6490645,-15.854371,-6.6387677,7.9616055,-31.494558,2.9794083,13.993064,6.044798,-10.480756,2.5150547,-4.548659,-22.002527,2.5386074,-5.8336163,9.058518,-15.250512,1.1135716,1.6355693,30.036852,-15.617339,-3.7695906,12.141144,-33.88026,-6.3886404,0.7445462,-8.087842,19.017345,-23.835394,3.5636435,-6.1009245,5.046356,12.198661,12.448614,10.592789,-33.672604,-21.451508,8.156275,-10.48881,-0.12134603,-16.7249,-25.17969,17.239056,-13.223446,-6.6427717,8.271674,9.514561,-4.5761304,1.2292988,14.901389,-13.786401,-20.142513,-12.930729,4.693822,-4.374701,12.918625,29.818308,-18.476759,-7.6735682,23.07466,-20.318974,29.38319,1.006066,-8.6940975,8.716454,27.762215,20.735226,14.958856,16.03854,15.271592,6.0875425,23.152618,4.841455,-20.409233,22.101318,16.512476,-17.900198,14.845787,4.571262,25.448387,19.932055,-28.341124,26.543396,2.0754206,-17.236187,1.4783634,-5.0989227,23.374926,6.0480485,0.8015938,16.854258,16.150896,11.683846,-8.514375,-17.006447,-4.6185904,26.535316,-4.9745502,-14.855566,-1.7616379,-10.227824,-0.54989356,0.96971935,-3.1314464,-30.523376,-17.577803,4.388882,-0.2080083,-5.05374,-6.3541956,15.627739,12.240552,-4.0488997,6.9581084,5.285501,19.08358,-6.365105,-12.1329365,-19.041414,-22.94189,25.00462,-9.01488,-14.842892,27.968132,8.179749,-15.778128,25.072912,-0.6472852,-12.083628,15.186787,-20.472202,33.153408,19.836784,11.032421,-1.037533,31.34017,25.053505,18.40497,22.83384,8.881651,-17.506205,28.148054,22.750708,-8.5037565,-18.488472,-4.3149447,15.673334,26.43745,-4.963601,-11.028863,-1.0745871,-14.754764,9.350178,-12.933445,-0.76350653,17.583017,9.025766,30.42692,-19.21973,-11.104839,-16.239662,4.0070834,25.211521,-11.164396,0.67005587,-13.912809,-1.6114194,20.6877,-3.282351,20.969807,25.00083,3.5467145,-12.475909,-11.149464,7.152916,9.589245,-32.635006,22.761774,-1.6710893,-6.391186,-7.8250074,6.903123,-0.72449696,9.385471,6.7700534,23.989563,18.83815,-6.0471764,5.6996837,-6.540671,-4.507427,26.045818,-14.351546,-7.5038223,-9.469193,1.3355347,-12.536309,12.478797,-17.798544,7.921424,-30.634262,23.166569,27.890486,-30.269499,-12.10636,4.268843,-2.6219912,17.883038,-17.644686,-29.0989,-9.98987,11.301969,12.814578,19.427073,28.799774,-12.263731,17.896852,8.775652,15.186774,-1.7803736,3.220773,5.6430097,-32.349842,21.300514,1.2930598,-1.5777041,-1.1284711,-24.458567,-25.24692,-32.90778,-18.85904,6.807139,-22.73884,-3.125673,-0.5431921,-23.424906,5.4837747,-22.113546,12.017029,-5.232848,0.5615882,10.231023,-4.114309,-4.6741943,-7.5406723,12.850893,-25.229828,-6.4697504,30.207174,17.763613,-8.013365,-4.6234794,1.4607116,-7.9709964,-3.82771,6.991764,-4.057106,26.523993,-17.5573,16.206015,22.636133,14.728248,9.856206,-24.451946,30.00024,6.6794705,-23.007896,4.1149087,17.0274,-11.275513,23.534414,31.43229,21.241068,-8.299575,7.8930316,-20.568388,31.462053,-5.045864,13.474157,6.084448,10.215779,33.489826,-3.0069594,-9.980828,-7.9746003,-12.8037,12.443252,21.621378,14.334024,3.716254,17.199331,4.2603664,-25.485659,4.415272,33.540035,-18.214754,21.150229,-4.4044633,23.57919,12.75063,11.377817,-9.774696,6.45298,17.533604,-14.41594,19.081923,2.9044316,-5.033793,0.33323714,11.292065,19.979645,0.65378004,18.06887,20.008211,30.321642,-27.92484,-10.00881,-6.349093,-14.585108,27.844275,21.912598,9.347593,13.73954,-1.7419952,25.96021,30.605684,-16.762344,7.56793,14.639674,8.537674,7.693112,12.458212,-16.683573,2.3516188,-16.926456,-12.417756,-23.227692,-8.973592,2.9624298,-15.190368,11.472364,-15.20506,-8.442998,-1.4028338,23.62935,3.1308389,14.402912,-14.432222,-20.246405,-19.808693,-14.627215,-2.7532442,13.271375,-13.180285,-10.397842,-10.155308,-15.814805,-1.7534562,-9.18367,-25.541069,25.768661,16.965282,1.5796621,25.12676,-26.033964,-17.489439,23.28003,-7.9830093,6.015645,0.4128281,7.4160857,21.673111,-16.580105,-20.82806,-10.137656,13.708724,-19.396036,-11.011755,-13.068287,12.8317795,-22.39632,-6.444953,-26.485762,-21.598299,-7.4097276,21.602877,-2.9653509,-10.596364,-8.96218,-25.85805,27.320053,31.317347,-19.823345,24.526129,16.43802,-1.4942552,-9.3723755,16.512342,9.259351,33.714893,-22.246923,-20.758156,-0.87667114,-2.8455646,-1.7179086,-21.38527,-9.553041,0.032546517,12.038152,21.748636,-10.027449,-21.43358,-5.3133163,18.439932,18.586302,-6.4771667,-6.9492006,-11.894645,8.280876,15.481091,24.537172,-7.5837355,-3.7392132,-3.791563,-6.5668383,14.689828,-8.430871,19.58573,-4.050474,-16.585804,4.6426644,-18.47059,-26.505455,-27.624027,-12.646457,-5.379853,33.172863,13.1538725,-5.9551215,-24.882627,31.986568,-5.8404417,-3.0344296,0.7622936,27.174824,7.122207,13.797278,9.939252,-25.403784,-26.258797,15.515262,-0.57554424,-30.075258,-24.15102,16.73329,-9.264224,-10.260419,32.04291,-26.211006,-15.722551,14.84477,25.02402,17.713417,-11.961778,3.3027165,5.1854973,7.7415977,-22.601847,14.444468,-4.209692,5.9727817,14.206015,7.7117453,-27.432693,-5.9292917,7.361504,11.442642,17.884586,-3.4112089,15.760515,8.881386,-13.416564,24.682543,-27.257462,3.1620286,-3.4912498,2.995851,-13.327913,-1.5712614,0.61387455,-35.193882,1.8770785,18.475523,17.085485,-30.448092,0.587154,17.594769,11.068728,23.481781,8.744264,-21.935726,-12.059852,17.90338,22.233992,-6.5803804,-4.053998,20.860687,6.9185057,-0.95106804,-20.385187,-1.2782745,-14.687796,-8.524121,9.530979,-7.9574747,16.25319,10.023108,-24.98122,-23.501575,14.999087,-9.978053,13.839524,21.635263,-7.899049,30.52638,33.320507,10.464791,14.417754,10.562709,-12.144375,27.40124,31.436325,-25.4947,9.829542,-9.693318,20.833256,-7.715794,-21.501247,6.854147,4.752623,6.169192,4.457059,-30.242834,-2.9618793,6.549285,32.087467,-15.666937,13.5333395,5.9882736,11.257595,-8.718793,-0.8180418,22.779432,13.801339,5.0053387,12.775344,12.446451,-15.028989,-14.816749,17.572086,12.000244,-3.3203287,5.7654834,-30.720934,-7.9156237,4.3029737,17.047016,-2.7769191,11.157989,-30.163355,10.16759,1.0407805,-15.884436,-0.71214455,4.124924,27.959793,7.174155,-14.822242,0.3041105,4.9918003,-19.811598,-9.119393,1.184909,-0.396174,4.3913746,7.656935,-11.364651,-7.53122,6.716149,11.711935,5.574854,16.986782,25.55119,-30.618814,-30.192984,6.97586,-6.903043,-5.8408628,36.41608,-18.556736,-9.117268,24.440865,0.9749449,-2.1284645,0.89835376,-7.4835453,-3.483922,-5.910232,5.0148153,8.401513,-2.243894,-0.2550733,-7.8314843,3.9997833,21.376156,19.018572,-18.580757,-1.0396231,-11.375404,-26.783028,-1.9366928,23.724352,1.3874407,2.0646899,19.504366,0.24796578,12.646547,-1.5302675,-28.346888,12.12124,-13.204849,23.262701,-5.7855287,-17.844332,11.1989765,7.550879,-11.720288,0.9294113,3.2637353,10.589939,-8.24917,-2.9496255,-6.8982077,8.108732,-7.066068,0.9246485,3.2766333,10.7548,19.912027,-4.073321,2.9655886,-0.89278156,-30.75606,-3.6903448,-22.613293,-32.17184,21.614498,-3.3377552,19.167967,-1.3339684,-19.572886,2.3593009,-7.121235,-23.972086,-27.17843,12.178305,15.339565,-4.834997,2.0476632,-10.796829,-7.842421,5.221416,-2.6660466,17.367487,-8.362423,4.8228507,-15.248574,-0.7170926,28.680565,19.595758,9.066548,-11.34609,27.731098,14.202055,27.839333,11.783377,-17.164127,5.5666957,-11.440914,-13.201762,-11.920312,29.01656,17.253042,0.31183335,-24.355518,8.123607,-19.053232,8.472352,18.284632,-15.462513,9.236089,15.207329],\"z\":[-21.384508,-20.298216,-19.997843,-18.405708,-16.842314,-13.793237,-16.271053,-15.627813,-14.031078,-19.287031,-15.183757,-17.729044,-15.391335,-13.48455,-16.803755,-5.9156814,11.424669,-5.4380665,-0.27033207,9.926652,-3.4422388,19.172285,16.500807,-16.383268,-24.516556,-17.213371,-17.272356,3.8414617,-8.253855,-18.805475,-3.446392,13.6842375,-15.999752,10.314079,-4.345613,-11.743655,-10.007513,-12.032217,-21.783712,-13.450171,-21.718035,10.762793,-3.982732,21.899906,-9.108241,3.7792306,-10.212505,-15.20735,-1.2314801,19.599318,0.34939098,17.68998,-5.7927856,7.786601,-3.0327213,-10.89128,0.0852171,-3.456466,19.429888,-7.3878875,-7.059611,2.9164722,-11.266616,9.960266,-27.088585,3.0677636,-2.7137837,6.824195,-12.081046,-7.679107,-9.538742,-14.084888,3.963296,10.004,-27.524744,0.9026581,-3.2871304,-3.608059,6.0436873,8.420138,12.273425,0.79348654,-2.8004112,10.131189,-14.609124,-0.63111436,-15.231495,-4.8326044,-9.469085,-16.842314,6.5839458,6.7337775,1.8478805,15.990343,22.139225,7.6444798,-12.444649,13.978069,-5.573946,13.1241045,-10.107445,18.993862,-18.560678,-19.479076,-2.8412898,-4.38552,-19.332348,-18.347395,-5.6994114,4.441547,9.874825,-1.6340705,9.922407,-13.854171,19.865349,-2.831982,13.017068,7.7092476,-4.62188,-5.662097,-4.953093,-24.71545,-4.185119,-9.910161,-4.044333,6.2200294,10.933393,2.2350814,-22.452597,-10.892278,4.2864995,-4.3303246,17.241182,23.824942,0.30745125,22.856716,-7.313447,-18.240215,10.506318,0.26554567,-6.210714,7.6638927,10.333624,1.2775524,-3.384433,4.3613043,-3.9483852,-4.8260684,3.8254251,11.192545,22.139158,-19.647123,-10.506296,1.3560116,-15.562222,-8.359864,6.210759,12.659305,12.34564,9.909854,4.065511,21.449371,-20.86277,4.6591988,9.2266865,24.223757,12.488696,-6.28442,-0.7422853,15.936008,-7.403482,-12.392804,13.949312,-9.592474,-6.1697516,-4.685446,1.2313014,18.447464,16.52209,6.20091,13.927404,2.7743583,16.64301,5.3198586,-3.354106,-7.958477,12.269559,-17.73051,12.257348,-22.81667,6.444475,-0.6635586,19.436586,14.6289215,8.383556,-0.80913204,-15.109588,12.032438,-14.937118,-3.1687996,-19.497307,13.514825,-12.295218,-1.6284709,21.965302,-11.951863,-23.326214,-11.4075,3.077417,-24.31747,7.566603,-3.6352067,6.539524,17.380014,-5.6347666,11.2619505,20.010605,-16.717812,-21.970362,6.363035,15.322295,6.863999,21.582624,-16.480759,-4.8985124,12.414401,-17.069279,-0.9949742,-11.276163,-3.9874156,11.323815,10.647664,-8.117693,-3.6050003,13.14128,-1.1811687,-1.8688718,-19.234343,14.5776825,3.864179,-9.177074,17.290987,1.3336993,13.096361,-4.309905,-14.901457,21.169281,8.179141,18.462145,-21.689787,-19.856375,-10.200312,-1.7891887,-4.9550767,-10.250913,-18.334377,16.478294,1.5964073,9.813071,21.364187,12.098503,-19.268093,7.250132,-9.551067,15.355489,27.60323,-13.103726,19.790142,19.352966,0.24308164,-24.440762,-20.113758,8.5956955,9.807332,-19.157698,-16.374838,22.914795,7.759036,16.601154,11.190949,-14.58705,-21.938921,-16.662483,-22.612494,7.6403522,5.5214186,-16.226765,-7.0829406,15.475083,0.7390067,-8.247892,-5.0215592,-14.3017235,4.963726,-23.621737,13.365158,18.671791,17.123003,-8.516455,-19.007729,4.201888,25.669065,-22.246794,0.9650745,-9.1139555,-24.223345,-8.050217,20.40195,7.798081,0.6649428,-12.290475,-4.408819,5.739457,27.515144,-10.297236,25.532396,27.78574,-1.1118519,11.710278,-20.77895,21.302027,10.39127,-9.180515,-12.7469425,-30.58407,7.827262,-13.4261265,-2.2038481,14.683004,24.037764,-14.7538595,3.1635559,-9.323931,-0.50495696,-12.130823,-22.382423,-5.3706746,9.298691,-7.9599366,1.4708056,20.63534,5.029641,3.682674,-11.409361,-3.2244847,13.980494,-5.8621564,-8.455999,-3.3494506,-10.746847,-16.012693,14.822531,-24.276772,-19.7323,15.87111,2.0342233,0.8076401,-13.947562,19.802904,12.243891,-21.572538,-8.653082,-6.702158,10.474712,6.644524,24.341698,5.5805297,-30.082188,9.022112,2.162022,-1.6506591,-7.733553,18.045862,7.81921,-16.501522,2.9655664,-11.282862,-9.001021,-11.098296,2.5188422,6.6920485,12.501397,-9.990586,22.068205,5.773364,-21.711403,3.3749986,-3.3976095,-16.214396,13.50591,-5.6111236,22.448002,12.913484,3.3780096,26.128513,-17.381212,-0.7170475,7.568262,3.8533068,11.988344,13.393375,6.4878144,-5.1245637,-7.512564,4.69763,-7.7125344,-19.778816,-0.7945599,16.865067,3.146103,20.010784,-8.414618,1.8896273,-0.9725179,3.545701,-15.578709,-15.96309,21.888012,21.81347,-6.911292,-0.8229684,0.3690189,-9.811158,0.3425794,21.519247,-22.854977,-15.642144,15.135662,6.941949,5.348087,18.290623,-15.416872,17.458557,2.7769887,11.935976,-11.03536,0.24798478,-20.018734,-22.697931,5.639587,-3.6349454,-13.094498,-13.955713,21.079922,-5.224301,-10.31329,-0.30604473,-21.63806,-3.783163,13.821319,15.911641,-8.622477,1.3993709,24.478079,-11.630134,-0.0021481493,18.748417,5.7145987,6.077182,-0.077126384,8.647899,-13.728952,19.69682,15.852412,3.6920493,-9.778983,17.086258,24.692314,-17.556942,9.881095,6.782345,-12.690993,25.044865,14.098883,-14.253396,-3.8443408,16.065979,-13.45653,-19.763155,16.147732,10.829005,13.119537,-2.6145954,-11.307509,9.696873,-22.646809,26.882442,14.618458,-14.167203,3.9703197,14.601363,0.18753743,-6.571457,-14.627163,-15.123399,-5.898612,-12.823694,-5.4542284,-4.8236966,0.86246973,18.594875,8.868541,29.42201,17.301432,14.651759,-13.532495,14.6659775,18.947363,15.619302,1.2275488,7.9335976,19.94378,-4.743261,2.3352861,13.91036,0.5053131,7.254887,-22.326424,1.1706706,14.862129,-1.9741704,8.409022,18.229198,17.742664,7.2774367,-0.82413805,-16.868778,2.9348874,-8.030818,-10.448088,-0.723107,11.927897,1.9060838,-27.431856,-4.9526095,-0.9930083,1.7069069,-25.448072,14.200455,21.607141,9.588675,-10.185417,-0.96490425,-1.8311973,-22.162233,2.2443419,-26.263836,0.15579909,-3.2055583,-3.4900308,22.173903,-12.446412,5.0435,-5.00952,13.633584,16.85687,-7.050795,0.65266883,-15.208252,20.936176,20.352999,-11.799985,-15.450117,-4.500554,-6.079449,-15.807614,-8.779277,1.0339658,25.514751,-2.4281147,17.591848,13.588222,-16.457537,17.76383,8.086297,10.224742,0.043819763,5.722411,-5.5095963,-0.24174236,11.547344,-7.6634536,-15.784609,8.659818,-16.319324,-8.57455,-8.528903,-2.033187,-7.470658,-3.2061923,-1.7066137,-1.2975768,-1.7165205,-7.0516677,-2.6221058,7.4027286,-12.18089,5.2928977,8.221811,-17.063742,-14.196614,20.406767,2.374823,1.1641673,-6.541201,-12.644242,0.49057102,-15.456888,9.886919,-9.459307,-9.837927,-14.998254,-23.790955,3.0541184,0.5675337,24.046118,5.851681,-14.456003,9.848517,21.0758,-28.342344,-7.8655224,-3.838794,10.391474,-11.668653,11.269012,-21.075363,-1.5212225,4.373773,11.83121,-1.8759059,22.706823,14.287579,-4.084229,-8.69988,18.5843,-7.9073987,4.543401,-6.286988,3.0293162,17.57516,3.6546,-21.830671,9.427224,2.8097239,5.7338686,-15.469782,-1.8757557,12.355355,17.58242,-6.021692,14.488465,7.9058003,-2.258739,-12.862442,-15.181585,-18.91492,3.9063199,-7.130952,2.5784917,-12.9656725,-6.179212,-2.2903564,6.023788,-15.437342,23.741667,-15.165835,-11.459017,-26.09495,-8.755703,-10.243649,-13.425894,4.5307055,0.24114662,-11.376091,-19.71719,-3.8502197,15.255649,21.36351,9.111104,3.3891914,3.873972,-12.340003,0.3746399,-7.0512743,18.63283,-12.360181,3.2402864,17.341488,9.074158,22.699118,5.5791564,17.67706,23.202177,-8.99333,21.862835,-1.6330307,-18.5682,0.41442707,-17.66601,-18.671635,-12.790076,-0.83974737,11.955919,-8.703176,9.310475,-9.1896105,-5.8815446,-6.4651246,2.311806,0.3722759,-4.1681385,-5.0048103,10.254661,19.000559,20.010695,-11.640791,15.3781,15.109055,16.634674,-7.379507,-24.220118,4.5985284,19.25095,6.226583,-27.03996,-18.21458,-14.522459,-14.65518,-22.024668,20.881546,-9.685227,-9.230136,-0.06516691,-16.726374,-13.011429,-15.722014,-17.98844,-3.611483,-21.874166,4.1527095,15.115796,0.57648414,-3.9395108,-12.301105,20.521643,23.017925,-3.2669585,14.993873,7.134566,-11.267633,-4.4392242,13.384785,-3.4629366,-1.7213641,-8.038071,16.708279,-0.47574902,13.219617,-8.053056,0.3041095,-3.6702802,14.528418,-0.72884464,8.39207,8.381048,8.126355,2.672765,-23.191053,-4.7556944,0.84199584,9.923118,14.822239,-8.716346,-7.792802,15.861608,3.7440345,-23.000523,-2.2670603,3.1304371,-1.9411031,-8.852796,-6.2985525,10.497059,-12.247703,-3.3839726,13.927398,-15.985381,17.917051,19.238409,3.8788261,-11.230593,18.180847,-0.72689617,-22.818073,-5.2136803,2.41618,9.918636,22.385126,18.693657,-14.144592,-2.2982142,13.923409,0.8186693,11.570647,-10.222972,10.585104,20.252594,-11.594525,6.3392367,-7.2336454,1.2267356,24.201551,1.7707615,12.52857,18.35306,6.965237,23.791187,-10.669806,3.1177783,4.586691,-10.601981,-8.747229,4.3767114,3.870586,-7.299214,-11.269238,-26.312183,17.890064,5.8156276,-6.591207,-0.630195,16.417784,-15.070372,-22.12414,-7.3855176,23.190144,-2.5604072,-7.235008,19.26864,10.054631,7.712765,23.667559,8.925719,-14.715585,2.4956133,-8.36524,0.44848683,-2.4005873,22.559752,-3.705569,0.81336945,-9.222666,-0.9825743,14.582189,6.995947,12.977155,17.43425,13.098765,-13.77821,24.014467,0.48810762,1.4951115,-8.141272,-13.289037,11.699481,5.481967,-6.180188,2.237438,11.882087,24.947275,22.83804,3.2634175,7.8701186,5.18925,8.273283,-0.8758515,-1.7379235,-8.587417,-3.3067286,-30.847223,1.8116468,-2.7643979,8.923597,9.273046,-16.114256,8.613295,-25.419456,5.1459603,6.099751,-19.483633,-20.117855,-1.5037903,11.9435215,-14.323414,6.597263,18.280537,-18.374588,3.9798057,-10.998707,7.091048,1.4262934,-14.548449,-11.793103,21.044817,8.036542,11.642123,2.9360735,3.5288584,21.66081,-10.070382,-6.024943,14.027694,-19.850466,-7.507811,-23.033985,1.0544025,-26.441744,-28.774279,16.810768,20.170416,5.8104,-1.2807583,8.90972,14.102506,24.633057,-19.899382,7.482479,-7.945032,21.047298,4.0407066,-15.962881,6.809428,11.366811,9.472895,-26.45345,5.694721,-4.2311177,4.600979,-0.21195966,9.254465,-1.901532,14.383517,22.108387,-6.4859233,-17.25476,-15.711674,-2.5728762,-10.755079,-8.274054,18.634804,2.3315406,19.132011,0.86382633,-15.089864,-1.6059545,-3.7093754,-12.813093,-2.2380354,-13.742203,3.9654858,0.5639602,-6.1468143,5.2772255,-6.075821,4.43052,3.84373,4.343266,18.264679,-4.673281,-10.724577,6.2093205,-5.0413537,21.464947,12.442758,-9.015769,1.4105222,17.27194,-16.944098,-21.640106,-26.485903,0.69499576,5.4687552,4.0595894,-14.692426,21.701614,1.4271843,17.657057,18.946228,20.259962,13.657879,-3.5225196,10.419078,-1.6404215,18.880863,-0.09568551,17.608274,11.161709,16.16659,14.053989,6.5547967,-23.04011,-6.5641727,-11.9639015,11.465316,-1.9819044,6.2539144,10.178796,17.37689,-18.801792,2.9136295,-5.260151,-6.449945,22.178799,-12.323853],\"type\":\"scatter3d\",\"textfont\":{\"size\":15}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"},\"range\":[-400,400]},\"yaxis\":{\"title\":{\"text\":\"y\"},\"range\":[-400,400]},\"zaxis\":{\"title\":{\"text\":\"z\"},\"range\":[-400,400]}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c671c81-0700-439c-9012-929e84579c40');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "numbers = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15']\n",
        "\n",
        "word_vectors = model_train.wv[numbers+sampled_train]\n",
        "\n",
        "tsne = TSNE(n_components=3)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)\n",
        "\n",
        "r = (-400,400)\n",
        "fig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=numbers + [None] * 1000)\n",
        "fig.update_traces(marker=dict(size=5,line=dict(width=3)),textfont_size=15)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19gG4E4Wi3bm"
      },
      "source": [
        "Same with the animals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T19:12:26.933906Z",
          "iopub.status.busy": "2024-05-26T19:12:26.933523Z",
          "iopub.status.idle": "2024-05-26T19:12:37.002679Z",
          "shell.execute_reply": "2024-05-26T19:12:37.000723Z",
          "shell.execute_reply.started": "2024-05-26T19:12:26.933868Z"
        },
        "id": "Gvt5KCQg_Y_e",
        "outputId": "9abbb7c3-c161-4059-c9e3-2e20ee8c5091",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>                            <div id=\"31fe2dbb-fc40-43f6-a19f-1b9f3f9af487\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"31fe2dbb-fc40-43f6-a19f-1b9f3f9af487\")) {                    Plotly.newPlot(                        \"31fe2dbb-fc40-43f6-a19f-1b9f3f9af487\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"line\":{\"width\":3},\"size\":5},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"lion\",\"tiger\",\"elephant\",\"panda\",\"leopard\",\"cheetah\",\"gorilla\",\"monkey\",\"chimpanzee\",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"x\":[-24.273987,-11.338582,2.5895643,11.688861,19.584595,26.318495,26.18093,-24.24071,25.86566,-17.700617,-1.2683392,38.50496,-7.703381,-9.756959,1.5120598,-16.912827,24.248053,-13.864177,7.5968423,-18.871399,12.564093,-7.10935,-1.7157143,-9.760394,-17.503157,22.066776,29.85916,-10.479484,14.308076,8.275703,35.217285,-5.550206,2.2657979,-10.745413,7.8583713,18.391876,16.356833,-14.703061,33.88657,10.525166,16.694933,-9.65086,-23.046085,18.421532,-4.7639613,-30.335108,-31.788671,-14.038934,-19.750998,-16.624622,24.956669,-25.939964,-3.76906,31.034367,16.294548,21.293098,-3.550726,20.207668,0.08635,-16.635,30.47633,-3.1197817,5.6787047,-17.317165,5.8099236,23.304731,-21.939693,9.25385,-4.176108,-13.00057,24.68873,-9.538055,18.344719,-23.609129,14.414947,-6.4259787,16.307919,-17.15317,8.055266,22.337524,1.14196,39.761673,26.556149,-21.386244,-21.964851,5.4500437,-1.6254942,-17.319614,-26.944935,-9.745961,29.921383,-31.303404,-2.2060325,14.979943,-15.588722,18.757532,-11.393632,-0.7137615,-6.8611317,31.41182,-7.4619575,5.253985,11.168651,0.20397772,-16.717312,30.984812,3.7751362,9.00775,3.7901921,33.36386,13.185721,28.530773,-0.24515305,-18.99377,-13.335922,13.5787525,-21.16504,24.647375,-37.74601,31.52332,-15.986957,-14.059067,-10.684605,-17.631895,-13.098994,-20.756155,-33.751507,-35.594536,-16.386806,-25.863743,3.9941483,4.59771,-1.429914,14.936812,-1.3039184,32.392017,-22.295006,25.250546,13.413367,2.8569508,-14.0873375,-9.785658,-3.0949204,-6.668709,-30.852901,-9.978721,3.2746017,17.398577,16.700626,-3.72589,10.731125,-29.709246,-25.685087,-33.00862,16.319183,2.1591582,-6.121964,-12.947898,-15.644303,-21.25849,25.86086,6.0409923,-12.096037,4.659613,-0.9639241,25.407019,18.10299,-19.5255,-28.529171,16.438524,27.133783,-23.575512,-36.681507,13.547517,-21.117706,-23.814726,-13.385293,-22.725412,14.553283,33.392883,17.185253,37.02453,1.6924002,-14.156618,-22.528889,-3.7736616,-41.733303,16.493029,-8.858254,18.996532,-18.385426,18.620794,33.093304,12.649101,-11.959266,-20.512241,11.994448,-8.575634,-22.571491,13.217395,-10.463143,-2.7130425,-22.453115,-3.278225,32.054108,15.905555,25.532616,-26.354057,-29.8611,7.7667837,-27.876059,-2.627733,-1.8929822,-19.677097,-18.189814,23.4225,-21.655104,4.434686,-20.8442,-26.527195,-14.64187,43.868694,31.140543,-3.2994518,-2.5136414,-5.569348,-10.177158,6.1657004,-10.299472,-2.4647787,-3.9607167,-4.1887355,-9.009365,26.898998,1.4295926,-13.939781,-23.87686,3.871623,13.891602,-10.49922,-34.073082,18.163502,-19.380035,22.93356,-5.421117,20.023848,-30.976355,-16.731993,38.515083,11.972506,-18.045706,1.7024539,26.995312,16.565002,11.214239,-17.361034,21.396654,20.16722,-22.837282,-21.908089,-9.659987,-26.532932,-29.633768,-25.189053,8.335195,1.495433,-12.584849,1.1446756,6.5444226,-3.781572,11.158662,29.30714,-10.994761,-32.059418,-19.010899,6.420836,-18.399588,-14.088408,-10.621847,-18.609777,20.539577,-21.827023,28.34365,23.988089,2.2361438,35.673206,-17.382097,-23.182566,8.163766,-1.1691027,-39.559975,14.190183,29.837002,-8.7518015,2.2000155,-18.050995,-13.929294,43.968334,35.243034,-3.2940176,15.937593,-10.682284,15.486165,-18.953245,-2.793404,33.501835,15.773228,-13.630026,6.9818044,-17.92259,-10.641254,13.932236,-35.857143,4.442602,11.396812,2.8671238,-12.100748,-2.163257,-0.54599035,-23.683996,3.552117,-15.664976,17.907452,-20.089758,12.530214,0.3784035,29.297932,-14.488553,-4.86277,16.065548,-33.922714,-10.785966,-0.53244627,-9.387117,23.039062,-28.209187,-2.6752586,-6.9205656,8.890667,12.948043,10.0070305,13.116493,-35.55589,-22.490805,11.374646,-13.17873,3.2882164,-17.765728,-31.45643,19.259811,-9.805059,-7.2138267,9.3868265,12.994389,-3.0443664,3.9543529,17.222202,-14.86099,-18.300875,-28.208805,1.8416907,-2.499333,14.36671,35.858356,-18.739883,-8.883519,18.528915,-20.161901,37.689167,-1.432408,-12.317388,25.016417,26.632301,25.250376,10.83336,21.38838,17.008465,13.052576,27.341839,5.664367,-18.577303,30.429014,19.19992,-16.951424,13.717757,4.9044666,21.824049,21.872484,-36.144577,34.26355,6.640406,-16.864294,-1.5202727,-8.324765,21.204908,6.8137317,-3.380963,32.46053,25.57439,11.281594,-7.6138344,-13.465104,1.6523955,28.805288,-7.714596,-18.305056,-3.9909868,-10.032829,-4.5579834,2.391088,-2.933445,-36.51015,-33.539757,4.385781,-0.555618,-12.494997,-4.9672275,6.6329317,13.388546,-6.3480935,14.943858,2.955766,27.727245,-19.186743,-21.39768,-17.43984,-29.006725,29.132397,-12.883789,-16.502398,35.383392,10.544183,-14.552093,26.752857,-6.160532,-14.340173,19.870277,-23.501326,39.00231,32.064922,15.981358,6.146269,43.328278,23.134047,23.6627,26.895292,8.014032,-19.876978,34.98214,24.018026,-1.9303206,-17.421001,-8.760904,19.090374,23.494589,-2.8872101,-14.679753,-1.228451,-18.68771,22.09281,-15.269987,-0.7601649,16.48042,5.764889,29.194492,-17.843054,-16.371565,-23.937828,-2.0738366,27.832243,-16.046923,-5.133086,-14.037984,-5.5654655,19.460104,1.0682378,19.477985,26.122627,6.483594,-5.6474214,-16.233559,7.0256143,11.365054,-31.342438,19.821686,2.5958946,-7.3739324,-9.435545,8.548144,5.647235,13.080241,0.8557859,22.061655,19.042456,-6.2163315,3.182108,-10.964113,-9.163783,23.725956,-15.960239,-6.3864446,-13.542714,-4.998122,-7.5662475,14.091268,-21.934084,11.556072,-28.303438,14.943236,28.949963,-33.443607,-11.4859915,0.024321496,3.5566804,22.491388,-19.164223,-34.610565,-2.2804475,8.10714,11.879331,16.448248,27.914377,-10.632876,33.54838,4.116904,13.077966,-0.6734087,7.4297757,5.817163,-36.807,23.310123,0.89956856,-4.287371,2.155751,-28.718319,-5.1584687,-31.213556,-18.633383,11.628591,-24.23383,8.008428,1.395862,-24.819336,5.099815,-25.737898,21.153124,-11.4832735,5.4627566,14.095642,-7.2797565,-24.766914,-8.362306,18.232012,-34.650272,-11.315384,34.329556,23.397387,-8.613809,-2.2253792,-5.0339904,-9.785934,-8.972135,10.124315,-19.242311,22.730095,-18.88099,18.146887,18.93342,11.18415,7.5678587,-25.668375,29.770239,7.3466296,-22.164444,0.901964,19.116184,-21.170616,34.047504,34.55754,18.38823,-7.2537374,5.444417,-23.68193,35.550198,-6.850755,18.346136,3.8095305,7.596138,37.659363,-3.295421,-15.3888035,-13.84778,-26.012407,22.675074,32.289433,20.427202,1.9015152,19.866724,2.1844823,-2.1516721,0.70134753,35.65289,-20.157356,24.098373,-4.810874,29.156418,8.834084,7.268895,-8.611555,2.9816208,23.168188,-20.71864,24.509579,2.5895643,-17.216656,4.1903825,14.687739,25.953733,-5.50118,16.277004,24.103436,43.773155,-30.285856,-18.82171,-8.870991,-14.969803,27.469149,31.767834,9.361181,11.727919,-4.02753,27.618961,39.26072,-14.85353,5.7982774,19.109678,12.047667,10.661699,11.743039,-11.523773,7.085689,-16.18592,-14.883256,-28.120451,-13.976411,1.4858652,-15.87663,11.610421,-12.125783,-9.526989,8.641858,26.404951,2.0180387,14.83072,-13.909022,-22.18764,-19.54686,-13.585062,-2.4747624,12.093528,-13.574058,-13.167376,-4.141532,-19.983631,0.5409584,-9.617592,-23.619757,27.72599,13.141335,3.0444326,36.934963,-29.311567,-33.90673,25.619562,-8.79194,6.6380234,0.3444243,12.565098,26.659492,-23.900164,-19.67095,-11.829814,16.903908,-21.152643,-25.4466,-10.595417,10.522124,-27.197075,-7.7110343,-29.096468,-22.011816,-6.9393563,22.168617,-1.8981755,-11.271161,-10.958515,-26.5215,21.697025,42.565228,-17.907677,27.902554,24.22327,-6.160563,-12.25576,19.161568,13.766517,39.248337,-27.258642,-21.944324,-5.9155245,0.96686083,-0.33673504,-26.644577,-17.742865,-1.6740352,6.808538,25.599426,-21.36035,-22.045027,-0.76618564,20.092213,28.755936,-7.109095,-7.877553,-13.889951,8.402667,10.776447,30.917322,-10.481579,-4.1198,-4.00292,-5.1252203,14.81713,-6.2916493,19.724344,-1.0078205,-12.367589,-1.2844995,-18.63881,-32.174976,-32.75294,0.30079952,-9.425308,35.41341,26.683428,-5.957575,-29.780622,39.99317,-5.870919,-5.1546297,-2.4737818,30.505812,10.675362,12.531614,7.2109423,-27.886927,-32.500885,10.233881,2.8064675,-32.87632,-28.869173,23.465452,-10.740608,-11.329063,35.152775,-28.28347,-22.000425,27.33593,27.941202,12.314278,-6.5439596,7.037788,7.711393,4.3281856,-24.382793,29.363537,-8.839838,1.6899745,18.54323,0.75397545,-32.78942,-6.1653886,5.136008,10.474307,17.02575,-2.2333877,21.290081,9.319111,-10.061759,32.967514,-28.837286,1.4686697,-8.29596,-3.036024,-15.104017,-8.336322,-0.9448879,-35.03639,2.446088,20.766634,24.711563,-37.447304,-8.413934,21.0837,14.176667,24.408974,10.533879,-26.817963,-18.761442,17.310879,28.011635,-13.675151,-0.0014443444,22.893085,9.965876,2.2817492,5.204253,-2.2009268,-18.52258,-11.217049,10.214583,-5.7520914,17.68,6.419856,-27.838657,-22.133177,10.913086,-12.568395,17.951435,34.85602,-10.620239,36.801888,39.973602,12.446431,16.026941,11.467761,-15.270659,30.557285,37.45634,-25.254555,-0.45365477,-5.55777,16.657602,-13.183432,-23.665487,1.8499393,-0.9543524,6.7170734,7.045734,-23.078594,-8.791054,7.4994493,29.042494,-11.749985,15.557609,1.3166518,9.669528,-15.423811,-0.6388165,21.075012,16.823563,1.5063193,18.818703,10.853328,-22.413422,-20.80631,16.40584,10.203208,-5.2814484,7.4518614,-32.926834,-6.913514,5.477596,23.249794,1.5747494,31.783947,-33.726154,11.846006,-1.677471,-16.943777,-2.9813514,6.7268586,29.799292,8.51458,-17.941204,2.093825,0.020310894,-17.485018,-10.510521,-0.4496048,-0.046087507,8.442051,4.6716657,-11.5461235,-12.625317,7.111285,20.015299,9.372149,17.49876,27.483345,-36.59628,-29.640507,2.3893795,-9.136282,-9.057903,39.38306,-21.793701,-8.498604,30.51493,3.7784688,-6.940573,3.3054254,-15.968261,-5.3313084,0.23261097,8.205729,4.5054793,-1.7619549,-2.9092124,-12.16449,4.2591076,24.205406,33.91459,-22.614529,-7.0957537,-12.480866,-30.832994,-4.3919883,31.776007,3.741299,-5.378658,18.93717,-1.0221243,18.112318,-3.146809,-32.86088,19.133171,-18.121273,33.24319,-6.574864,-17.942513,13.924812,9.997907,-14.809421,-0.6711545,1.1279064,11.875463,-7.6502995,-2.30686,-7.725724,10.402745,-9.005068,13.343893,2.747058,11.533857,19.080994,-4.0828733,3.8688567,6.2108426,-26.056248,-3.1704073,-16.81003,-38.040115,32.493774,-5.9194555,23.210041,-5.5273194,-23.24289,3.5025418,-2.493417,-20.456326,-34.24579,15.617169,20.849874,-1.8116419,1.2064245,-12.059757,-6.023369,6.3406157,-5.3547335,27.02826,-10.968196,8.802901,-17.237135,-0.50649863,34.120045,19.64099,6.2815833,-10.588699,30.604246,9.867481,21.410257,18.192236,-17.93009,2.2984526,-6.1365833,-22.616734,-13.182039,31.730057,15.327654,-4.11886,-29.654266,8.349143,-20.606766,6.891854,18.233252,-24.637579,10.778502,14.263631],\"y\":[1.5429372,-10.010249,11.323707,4.074436,1.7741014,-11.76033,0.73594797,5.7521086,-0.940937,-6.5162477,9.16279,7.6065445,-0.51667625,-19.337727,-3.4501054,13.581106,14.258546,29.161888,11.679085,26.317839,21.095798,12.6503105,20.823517,30.98189,-12.683481,7.105679,0.6062062,12.774109,-15.90276,-0.66424656,-2.0623279,21.082743,10.918894,-10.281517,-2.0534835,-15.098939,-12.895336,15.022915,1.6629823,8.326053,-12.463544,-3.8487022,-7.602648,11.048051,-4.5497804,9.950699,-6.767673,-2.1855469,-8.329771,-0.7990954,-0.028034518,-15.984819,8.032651,8.842742,-3.546494,-0.13952596,-22.407526,-17.155855,-3.063609,-11.893194,1.5859277,10.027534,-1.5369525,-13.86416,-6.161794,12.902683,-11.833598,3.53301,-3.788213,-9.968856,-11.654037,-16.744596,-11.612999,-0.8971705,18.724733,-14.211375,-8.386036,7.193475,-3.1980634,-12.587257,4.3939586,1.2445824,9.089097,17.751987,-8.194691,-9.085465,-13.980406,7.239511,14.507987,9.389731,-0.6356231,3.515407,-29.614958,-5.3815627,26.697094,-2.898469,-3.0996032,0.015350638,-2.63316,2.048336,24.656637,8.169308,-10.456431,12.627177,3.4096906,-2.1218421,8.439762,8.183979,7.0919886,2.1416948,7.5741262,5.6091504,-2.0401044,-11.630598,-1.6199427,-4.313163,19.593988,12.163797,-11.107992,-13.630279,3.0107133,-0.8131013,31.251747,20.747732,-21.244057,-8.541912,6.450962,15.977759,-10.762866,15.00567,-5.280805,18.306921,17.656347,0.0865009,-27.162807,1.4497827,-2.2254012,-6.1811028,-17.302532,-5.351806,-9.036986,1.1927919,-9.299079,28.16855,14.02678,6.2069497,-5.1242566,11.440622,0.8584632,6.0760508,-10.348797,2.4915116,0.7457922,-2.1079962,-0.041703276,3.4481907,-7.148907,-7.795684,0.8489535,18.027603,-15.746155,-5.4272194,-12.781923,13.807787,-24.633999,9.33674,0.70548606,3.8892715,-4.751737,-16.144125,-3.87498,5.9968495,5.738838,-2.9875572,25.958393,-2.2500465,7.229641,-5.3377447,-11.098956,1.8988544,7.8378987,-13.340154,14.39044,-5.104663,-2.9060886,-8.355636,6.6394057,-19.449114,-18.588272,-12.845819,-1.4536238,-18.805126,-14.7815485,-15.054126,0.14748567,3.1049044,15.189117,4.122693,10.685315,-2.8477974,-2.6722531,24.66702,-7.6736193,-5.3820963,-3.511778,-16.12473,-1.5628965,10.359199,-12.880085,6.4796205,14.363917,28.561321,12.280928,-2.5908058,5.595736,-14.605703,8.302795,4.2826686,-7.6328096,-3.3170185,13.856497,1.0853771,-8.334672,-1.0431799,-7.582227,16.656448,-4.36108,-24.54257,-3.521396,-3.7628877,-4.200368,8.95466,10.26112,2.4923372,24.01793,21.724995,-13.6370735,-1.5253804,-6.23396,28.085453,12.522667,-3.6957865,12.566601,9.149826,32.82269,-10.678276,-10.403535,-11.514704,-6.9154263,-1.7328885,7.4021845,-19.244776,-15.962152,-11.715035,0.1893817,-10.348671,-7.1213894,16.503447,8.446453,17.88252,0.77474356,12.065506,6.3843875,-12.893016,-22.623642,6.1169434,10.574731,1.8989491,2.9409003,4.980759,16.286005,-5.275087,8.487185,0.0168677,-6.4672275,-18.849771,28.428059,35.822834,-9.120673,-5.330463,3.0557625,0.5915784,-23.090242,-16.864851,-8.632107,-6.562538,25.082916,-5.1910906,-4.183474,-1.86995,6.746859,7.337255,-10.852355,0.45355,-15.902033,16.246416,-9.018472,-8.46125,-6.9025173,11.315249,-6.773079,4.5306816,12.70168,-7.1220613,-1.284793,-4.740753,5.6830006,19.725811,14.328867,10.239949,19.308867,-24.710468,0.26059872,-3.3201497,-2.8490338,-7.983614,1.3424665,19.126347,-12.514457,-1.5149068,1.9625529,-17.683588,4.342495,14.666806,6.0521,-7.1188564,14.385222,-11.871541,24.370354,-1.8560944,-18.528143,-5.0638194,4.5657024,-5.200987,16.018837,-1.9878197,-13.351897,4.5172577,-8.505085,0.6286751,-8.710022,-20.891596,-16.49168,5.268687,3.8562734,5.9602866,14.013248,-7.106189,5.9607453,-3.203166,-17.59392,2.0265102,7.8362803,2.5612226,-8.366216,-8.009321,-7.1560874,-0.9637011,-13.959019,16.02711,-3.179901,-2.5982306,5.679546,-14.427202,-4.779065,-1.7949673,-5.578364,-0.8993817,-13.90479,-15.490797,22.935617,7.6744537,11.869884,-19.52081,10.809151,9.641124,-2.4571896,20.574219,-7.8868365,21.07759,-14.321985,8.252174,3.5399954,20.884401,-8.142148,6.7214365,-18.061615,-13.103352,18.848114,-15.205861,-19.183323,-7.7028937,-13.2727585,-1.2954519,3.2939076,1.4963802,8.509852,8.073833,-1.7665691,-16.388948,4.2054915,-20.834665,20.6801,-2.0426557,10.614049,-14.349656,-16.281185,-6.9563756,-19.642572,-2.3705819,29.896824,11.472689,5.06419,-13.054256,-0.8168265,-17.973536,-1.3698227,11.381753,13.107411,25.298952,11.543924,-3.6301117,9.681249,5.76129,11.365008,27.877373,4.8477545,-15.948996,2.395406,4.798781,-11.785681,2.7436206,-1.0734862,-14.73217,9.871271,-7.0210533,-0.04261414,7.745559,3.6651473,-3.1005216,-19.78601,10.013567,-3.7062669,-17.486435,9.186451,-7.763891,-4.49673,13.42837,-8.681866,-9.406549,21.044813,-10.107014,3.0025365,-10.019705,-20.024284,18.71843,11.613352,12.616223,-9.08485,15.341798,7.800253,9.813116,8.690216,-10.383774,-13.049778,6.9834642,18.310705,2.6242654,22.042126,4.9716015,10.770167,24.960325,-4.2777905,3.5587697,-6.099749,8.981275,7.4243536,-11.7271595,11.810505,8.603708,19.430597,0.45430174,-0.4425279,-15.110373,-5.1036477,-23.214083,1.3214824,33.985664,1.4072953,-22.870476,1.4480466,-8.349002,5.521818,-8.39622,12.736865,0.61858404,21.730057,3.1144037,2.1702397,29.00337,17.354584,12.511988,2.1360312,-18.631445,10.387502,9.775087,-10.524868,-20.900734,-19.745626,-4.775684,-8.12683,-6.3441877,-10.28128,30.343925,-8.273045,-1.9125715,9.936481,21.405676,-17.0689,2.9667892,9.153959,-7.9040084,6.3510284,8.097675,-13.884789,-11.753745,13.840611,0.1002186,-11.118803,-13.427454,-2.3898978,10.408418,3.680877,15.265803,-1.8115098,4.936004,-15.52727,-10.950433,5.349196,-8.764442,15.395871,1.6171505,-9.641478,-14.121431,7.867438,-9.919748,-11.656169,-19.960773,19.725859,6.9513583,-7.3431563,-12.128899,-7.3169217,10.597203,12.14586,-12.833412,-1.3387301,-5.098964,22.385462,27.795809,8.495633,-16.808277,16.555782,16.272617,-8.885822,24.024284,5.6242943,-0.6501704,-10.45864,-5.64163,-13.23438,-10.813459,-12.737841,-15.27725,-6.0418987,-1.336409,0.0055603334,8.281493,-18.63615,-15.99624,19.712109,-13.561373,-5.6201763,-0.46232203,-12.2496195,-15.964712,-10.396572,-7.4478245,-0.2536149,1.7455264,-1.7152407,2.8671072,9.26286,-20.62291,-9.3997,17.765614,-14.217802,-5.816525,-19.351362,4.932713,-3.9641623,-19.690992,1.4484754,-7.2571807,23.172125,-14.548381,-20.467533,5.365981,-13.5536585,-0.3871926,-2.3313594,22.853205,1.542024,11.323707,25.002785,-22.415468,7.5165825,3.7649958,-6.3994536,-11.867932,13.677593,-6.7527432,-8.70028,10.009761,-12.2535095,7.5813146,-18.064337,11.424623,-14.269561,-3.988576,4.1439886,-5.6406817,1.610814,-14.305968,21.074297,-2.997571,-2.738018,3.0421748,-1.8646791,-18.179756,5.601882,-8.365157,2.4467945,8.946156,7.7037086,3.0394633,-3.2744024,-1.8843265,6.742257,-7.298252,10.820322,-13.410315,6.9229712,-6.4255733,3.958521,-13.7957735,-15.478811,-10.907396,7.512724,13.856725,-0.14510001,-3.3406005,14.8687105,-0.9892942,7.4216995,30.157377,-16.64466,-0.062374216,-8.058125,1.9472625,-3.6608105,5.8060284,2.6244087,-8.376024,-2.6264672,-1.4487953,-2.068806,-21.530403,-6.455605,14.068335,19.756273,-3.0322015,12.137258,-0.55269754,17.317453,-12.457309,-1.9982378,11.870565,0.95098925,17.91552,-14.052825,28.368269,-7.7445154,3.0771804,-7.523451,12.516682,-9.36732,-21.468937,0.9026687,-6.370617,9.790158,10.297282,5.985374,-1.1045096,-0.0494982,-25.852015,1.7032075,-5.6670427,6.482419,7.3444104,10.653666,17.9426,7.1214566,14.532229,-13.081832,-21.272087,6.3199563,14.576219,-8.864559,-8.97168,6.524913,-0.396304,-1.7223492,34.9059,13.374783,-11.245868,-15.754981,-15.273782,32.270718,-6.8689694,28.441824,-0.05610017,0.30197212,-2.299221,-11.093614,22.920559,-19.611935,-10.96395,3.417279,11.505074,11.437108,7.635649,3.9674995,-9.516319,5.1331973,-7.839042,3.0658367,-4.251958,-9.24946,1.9635434,-2.7418432,-4.6248794,-1.3504548,-12.672643,-4.300787,-12.00231,2.5045118,12.480054,14.248855,-3.4319298,-1.831233,-3.5753703,36.48323,-7.13334,-1.4353998,0.52893496,3.9242415,2.2541256,-8.076429,-8.927351,-10.520386,8.091015,-18.136248,-5.0820246,-16.127275,6.387369,-1.9760166,-9.9723835,-4.004984,-16.993807,2.7414138,-6.3739295,-0.08175292,2.8138764,14.4097,2.4849336,14.115369,-12.430866,2.8985865,8.663503,-10.637418,3.6427832,6.125999,3.0520968,-4.603134,10.035615,5.5298333,-16.984835,10.981747,-3.8621848,7.3585973,13.001719,22.849123,-4.102313,-13.35821,-10.277142,18.796404,-1.7567447,5.5933547,5.376893,-4.360887,3.70779,18.730179,-10.029526,-18.713028,22.156975,21.489376,-18.100748,1.7389553,2.1287038,-7.0628834,15.650799,7.911845,-15.5372715,-7.8964677,-19.694763,-5.5310125,13.176089,1.2314415,0.19877252,15.751041,-2.772015,-2.6373384,11.882561,-1.6769717,7.0913353,13.009114,-8.68496,-14.51431,-12.101315,12.701322,15.659256,5.871949,3.0528483,-18.45405,-6.920555,-21.226572,-10.7587595,9.370028,-20.065928,-2.716484,11.54859,-21.125546,10.453341,17.1017,-8.6793,3.219516,5.456299,-7.9314556,1.8204942,-3.1691377,-16.120419,1.4370272,-4.9375806,19.568647,16.723108,-10.609183,-13.790285,7.371277,3.6239483,-12.62406,-7.0700355,-6.9243574,-2.8445742,-13.353843,13.7210455,-12.934979,3.2413545,-3.1589026,-1.6591054,-0.18494132,-2.8017344,-9.416677,-2.1266956,32.219387,7.620584,-20.304901,-2.292035,23.967377,-3.3411858,14.134698,7.6019144,-9.348727,27.269247,5.48544,-8.915606,-19.337967,12.42597,10.960045,-11.303722,0.6646256,-14.018203,-20.247938,10.161808,20.309414,5.0615797,6.8868384,-5.5231915,-4.2076106,10.364157,11.1145315,-1.284174,27.427565,7.952674,24.064405,-22.22068,-7.0770793,11.591544,0.636081,19.546026,18.247791,5.7063975,3.4644742,10.118607,-21.44399,2.6046085,-5.3587704,1.1394815,6.249658,17.380283,-15.873116,-13.097217,-8.546778,-21.401823,6.8092666,-7.454419,8.1139345,13.564717,-1.6634089,29.446735,1.7319237,-4.258386,-3.2716303,2.3326614,4.5707064,-13.362753,10.136244,-3.7872014,-2.9167237,-1.9386041,-17.653261,24.171627,-26.631063,1.2389355,-7.2258005,-5.4581294,1.8838662,14.36522,-21.844973,-18.677721,3.1550252,-23.235401,7.473064,4.278543,-3.7305822,-27.055897,12.141845,10.129374,7.187418,16.018513,-22.583647,5.4845786,20.581467,11.044764,-5.9757385,-10.602282,16.040543,-10.726476,17.543406,11.560714,17.951984,15.877708,23.246464,8.599914,9.067069,-3.6437137,-14.88634,-0.15307373,13.145353,-11.305065,-6.402946,-22.340683,13.925205,2.7041774,-14.752845,5.15425,2.3431082,6.491899,-20.39742,-9.445821,-15.679461,0.18964265,4.3939824,-5.6434684,1.4603533,-10.444753,4.839391,8.036627,-6.1895475],\"z\":[-16.234663,-17.920347,28.864208,-28.756308,4.696061,-13.106841,-11.732981,-14.569982,2.9309988,-16.975779,30.050692,-3.2846198,-2.8599348,6.0788636,-8.251262,10.690863,14.072306,-13.900641,-24.890345,-13.420088,-9.246433,-0.6397022,-15.014147,-16.568233,-6.600321,11.115501,-24.796604,3.8816912,3.9886706,-13.311831,-5.7159534,-6.5948663,-21.568464,-25.56888,-29.181099,18.17927,-2.96873,13.963261,-4.9109383,-0.7987705,-12.064163,-26.058325,-21.980288,19.587547,-6.0578094,9.614036,-5.710646,10.222313,-21.895554,-21.88152,-3.7149162,-4.1990414,17.460978,-15.944732,-10.003367,0.14601965,6.1197596,16.488346,-38.59265,11.578993,-8.713569,3.4491057,-15.334452,-14.027459,-21.0132,4.6252007,3.6537156,9.286846,-39.320675,0.05396049,-2.544568,-16.144632,13.038219,25.439684,5.4897485,19.983988,4.473454,-0.12190273,-17.850565,0.300737,-39.867275,-8.4846945,-17.856237,-19.118425,1.6854829,9.795302,5.454522,9.585108,4.792485,2.0447786,-19.493965,18.51559,-3.1994162,16.12223,-4.7017474,24.845594,-30.41832,-29.059496,-9.115851,-11.774832,-20.54341,-16.17251,-12.105761,0.50492966,18.119858,5.355815,3.7019527,-9.860021,18.763845,7.666887,11.616822,10.514013,-10.515329,-20.616182,-10.438206,-30.781235,-9.520403,-18.888308,-1.9393306,10.114484,5.648401,0.45699605,-19.94117,-18.24752,-1.2570801,-4.666444,18.888678,11.081325,-0.8153866,22.977419,-12.705072,-4.850718,4.8603315,-2.412316,-1.3681947,15.350833,20.329025,0.96318907,0.7912794,8.2971945,-11.055096,-8.276429,-2.5720513,6.931448,13.896277,-30.011877,-16.664171,-3.1487648,-19.996233,-13.344748,7.535969,22.409018,20.93672,11.712583,4.3025246,23.05762,-31.730286,4.9030557,19.725002,9.229986,5.1917915,-9.058526,22.725256,12.937663,0.36071765,-14.390586,18.82541,-23.067509,-5.6040373,-2.589116,1.5906401,18.409182,13.572515,4.539889,3.9200923,3.2567792,9.915295,6.0645204,2.8244383,-1.7367796,11.188614,-12.515479,9.0038,-36.681854,8.338264,3.4397585,9.163359,18.892166,3.309512,5.433154,-13.855879,14.325136,-7.0724254,-5.5927496,-31.114094,4.67067,-14.833537,-3.3899395,28.13992,-15.209995,-35.811897,-6.8285427,20.982092,-35.014015,17.696915,8.408792,16.815283,13.368457,-5.7775536,9.828117,14.850468,-14.181787,-23.110046,13.725699,12.571001,16.499285,21.91255,-18.960062,-14.5342245,21.864067,-15.065011,1.8281505,-11.647919,-10.843959,16.412125,6.7035823,-20.152765,3.5663388,23.052607,-0.15612938,-12.013089,-22.835596,19.663967,2.315655,-8.968192,1.9518082,19.423897,10.95564,-0.3905069,-12.60714,10.216959,9.923848,9.829699,-7.017717,-14.161533,-12.340497,-0.44903916,-10.625435,-0.12381698,-23.770164,-14.8615055,15.260669,0.6079186,26.932865,12.058737,-33.313686,10.341078,-19.391497,3.6533284,19.846575,-22.37814,7.153537,4.5949225,0.23096864,-15.395592,0.89304817,0.7714169,7.5745244,-26.485403,-20.920023,15.662609,12.362585,18.26107,21.444746,-26.915707,-14.551527,-14.360967,-15.028047,13.907447,18.557455,-8.549774,-5.9240403,5.5162516,-3.7458627,-17.528397,6.837035,-17.491087,15.554095,-32.026012,16.806404,11.254654,16.746668,-5.050137,-29.148804,17.360767,22.894833,-36.394894,-2.2258308,-3.9480135,-31.330017,-13.867007,21.444357,4.2042418,23.968227,-19.365568,5.584969,3.2909162,8.366959,-11.956687,24.295286,4.6178274,4.9156933,19.939287,-28.629744,28.557318,15.769189,-16.43945,-3.4386983,-30.463203,15.6429,-12.898147,19.3993,13.652354,17.156338,-30.832731,3.600154,6.388982,-2.4507754,-10.255955,-28.334196,-2.2354722,14.742675,-8.264863,-0.16317658,19.861975,6.2938037,-8.0155525,-15.53916,-0.9322676,15.012252,-8.337973,-5.0613565,-0.18904851,-25.159744,-15.0581,15.456935,-21.223385,-33.858837,14.647188,-0.5380732,-8.586266,-19.418879,18.842655,9.97818,-31.59963,-23.79189,-9.904972,16.174335,6.2130933,2.0851605,5.0683904,-42.07262,7.685515,6.177197,-2.2802682,-12.984752,23.412075,26.517408,-8.681861,-1.7987052,-10.121144,-20.635475,5.9375787,-3.5195951,1.9810519,8.2800865,-13.2860775,14.743056,15.285915,-0.62226814,2.5088193,-5.153299,-14.963108,5.6282706,-7.537827,22.368181,10.777523,9.582158,9.821157,-10.921422,7.0869575,6.8151364,11.7138815,11.869816,19.162834,6.661127,-8.670296,-19.4022,12.857777,-18.693499,-26.142048,-8.776201,13.484232,9.743689,13.265812,-17.8049,18.418575,-6.8305902,18.354168,-21.508015,-9.286391,18.466715,-4.435393,-17.077835,-6.30119,18.384214,-15.639098,-5.005389,18.554958,14.967984,-8.936925,19.08381,11.391542,-6.4588017,5.9451013,-19.431768,7.0332465,14.651392,7.6932025,-18.57555,4.3020716,-25.682451,-36.096275,12.509962,-11.847079,-25.10051,-19.432774,25.103817,-2.5026486,-16.242693,2.2285957,-22.075308,-6.5260787,5.386393,20.483322,-10.792314,-4.73146,20.550344,-6.6393247,2.311443,18.559502,8.451825,2.7136066,0.32882488,16.624327,-9.06101,13.638515,12.632783,19.003738,-19.193884,12.789649,20.905146,-16.000048,16.01394,1.0349246,-25.081207,15.741411,10.245415,-0.847167,-3.9529045,7.096795,-3.2632685,-32.741398,16.398468,14.172199,14.23781,-2.0606682,-8.173677,8.3055725,-31.2983,10.996323,13.115609,-18.318796,8.1742325,19.458107,10.146618,-10.984841,-6.470704,-19.757086,-2.0759065,-12.201333,-14.186982,0.44355053,6.713255,11.126084,3.4003959,9.820417,16.370995,21.808594,-7.9528623,15.850441,10.209994,19.300707,-9.381109,6.215282,11.63122,-3.1935995,5.063783,13.886584,-2.367928,9.3889265,-35.701862,-8.210638,10.850366,-2.822797,19.129812,14.13204,21.103159,19.632809,-5.734761,-19.541397,5.2104964,-12.119103,-12.897381,7.8751917,16.478418,-3.0915678,-35.95541,-14.151764,1.7617496,-2.0829482,-30.611,13.330538,19.748095,15.029373,-39.565598,1.3121915,-2.926116,-23.358412,14.824069,-25.712917,-3.8442297,-4.2545657,1.729142,26.933075,-18.967691,11.529744,-5.402553,-0.07181849,17.952965,-16.748016,22.033278,-21.375685,6.93911,16.181232,-3.117982,-20.980078,-10.768338,-17.984545,-1.5815138,-16.959017,17.751896,11.636405,-8.807131,19.028694,5.3884487,-11.879274,23.361145,11.1983,12.349663,11.53443,6.675571,-3.8057096,19.9547,16.002348,-7.7904778,-16.043083,12.054333,-5.023419,-18.028086,-14.721453,-8.891065,-3.3722682,1.0557601,-17.62266,0.6051993,-9.528415,-10.189587,4.49243,2.0232944,-17.270218,-5.6682105,-13.129193,-11.4148655,-15.605681,14.996788,12.842879,-0.5051548,3.3026128,-40.227818,-0.8075482,-2.564963,17.922903,-9.853505,-12.924496,-10.173457,-18.433496,-5.2148743,-9.311228,26.413198,6.2061644,-12.140212,8.430481,28.864208,14.211738,-7.6715126,-7.168942,13.569483,-16.910788,18.561388,-5.8891296,-5.379612,6.4029965,-0.90413874,-15.1278,21.922295,6.902344,-5.379015,-21.764736,24.856955,-9.452759,8.599913,-5.050163,1.0282893,12.52603,3.8319135,-27.86718,1.7854004,-1.934406,1.1279951,-11.712144,-4.074165,13.65469,16.138168,-7.5840116,13.17189,22.17008,-6.0204134,-21.648336,-26.370335,-19.97762,19.43739,-8.078963,9.134045,-20.959759,-7.7704988,-4.4910197,5.5085015,-18.440395,21.866333,-25.59526,-15.3767,-30.071316,-21.934565,-13.977043,-7.8885612,1.7877687,-1.8561535,-21.650055,-29.45228,-10.669158,19.932087,-6.168857,10.45847,5.7441893,-1.7886851,-15.254811,5.383995,-14.453139,13.278791,-17.95379,0.7285082,14.447968,22.913246,2.7656484,5.272693,20.281128,20.826357,-14.187634,14.983501,-2.8411372,-17.578697,5.121662,-22.50487,-31.181046,-9.181075,-0.26684055,5.308086,-4.449918,3.4294758,1.7254452,0.08876594,-9.692166,-4.8402157,-3.665955,1.0303893,0.090521075,11.262859,27.964958,22.218988,-14.041486,11.564722,12.33843,1.9892943,-22.04215,-21.128107,6.474913,3.6695192,8.0914955,-38.1735,-9.071618,-21.97482,-24.00692,-16.415985,22.424438,-20.567617,-12.094289,18.729198,-11.505852,-22.210072,-11.656423,-27.354692,-7.82138,-32.695156,10.347919,9.542237,-5.859205,-14.210235,-26.170694,17.088509,20.41984,-2.5711749,13.345119,12.945651,-11.979081,-10.132654,14.771025,10.402232,7.162401,-7.1866665,20.692015,2.0759168,8.9676285,-10.552968,5.8395953,-2.9999905,8.881622,-4.3387895,5.141405,20.504293,10.016749,13.168479,-15.703371,-12.123677,12.430063,25.614693,13.023859,-15.179899,-7.932826,21.617283,-2.6415756,-26.635357,2.9077296,1.5340823,12.0749445,-15.52705,-17.719719,21.049755,-17.350023,-13.345944,15.721601,-26.156046,18.08676,20.05627,-2.3701847,-15.316775,15.501647,3.0698054,-33.935383,3.6568837,3.90289,4.673097,7.9217787,23.239502,-26.249363,-7.094732,11.388302,4.670999,8.715997,-12.882175,15.148802,14.474677,0.60757333,8.553666,-17.51984,6.1847315,17.499237,1.7208085,4.8320007,26.02512,16.200296,28.127,-12.004828,14.320428,12.246917,-13.988943,-20.871714,-3.776213,0.8835441,-12.182044,-15.906578,-27.79719,19.68646,17.157993,-5.601232,-2.1406777,20.567732,-11.893761,-29.658829,-12.596826,17.311897,8.752836,-0.27257437,14.545615,11.650135,6.1182446,19.132246,12.50434,-4.991303,3.640708,-9.000612,0.39750168,-2.077455,25.184141,13.008445,-0.21836706,1.4763359,1.1647556,13.362687,6.9003096,20.965406,17.333712,3.0730002,-21.642803,19.821577,-3.2849839,-9.018469,-10.798141,-19.904312,15.679681,6.360315,1.5964184,7.917559,13.929268,14.077066,13.033397,9.204505,8.70369,2.0315888,0.38174313,1.9439833,8.881181,-16.830194,-8.023147,-30.385395,-15.059109,-1.2808833,5.9545994,12.3862,-28.748497,4.9759054,-34.68518,0.74148256,1.070558,-12.571282,-22.4101,-10.898451,5.1958237,-15.055258,8.873855,16.203772,-15.495423,6.0344067,-6.0600915,1.4686046,3.4294863,-9.072529,-13.199875,22.1483,10.970771,15.377009,5.590762,18.714745,8.003932,-7.5024834,1.5284663,8.543274,-31.41131,-7.628506,-28.637125,-3.7579029,-36.560787,15.579579,12.500574,15.983151,12.317007,-4.3220224,5.8736486,16.476828,18.602049,-0.9962285,9.900519,-15.395652,15.861409,18.307793,-26.094534,15.6056595,10.339976,12.705741,-20.976767,0.68740195,-7.6919446,10.039518,-0.700649,6.5240717,0.79686344,13.408699,14.708501,-10.274323,-14.247118,-29.639938,-5.5681944,-11.6698,-14.664291,17.625778,-3.1628768,17.188828,2.4976907,-23.703987,-5.905838,0.5537273,-10.878645,-9.719448,-17.451853,6.223922,-3.832514,-12.177738,-0.5353661,0.9853248,6.7781234,-1.6867124,1.1377066,15.369273,4.443393,-20.068577,-2.0665596,-15.1468525,19.250362,9.1813345,-15.382498,-0.3144438,7.8959155,-9.222394,-9.9407015,-37.655525,2.7580864,-1.9466485,24.838238,5.880024,16.083078,-3.8695636,11.84135,9.964793,16.876835,11.396853,0.52593255,21.193604,-8.644058,24.036224,23.900387,26.22362,14.587413,11.14445,10.004245,20.738598,-31.404766,-4.2398095,-16.85233,10.295953,-2.2947037,11.385977,11.716148,16.004435,-33.13728,-4.451445,-5.94753,-4.144802,22.319246,-19.346931],\"type\":\"scatter3d\",\"textfont\":{\"size\":15}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"},\"range\":[-400,400]},\"yaxis\":{\"title\":{\"text\":\"y\"},\"range\":[-400,400]},\"zaxis\":{\"title\":{\"text\":\"z\"},\"range\":[-400,400]}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('31fe2dbb-fc40-43f6-a19f-1b9f3f9af487');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "animals = ['lion','tiger','elephant','panda','leopard','cheetah','gorilla','monkey','chimpanzee']\n",
        "\n",
        "word_vectors_train = model_train.wv[animals+sampled_train]\n",
        "\n",
        "tsne = TSNE(n_components=3)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors_train)\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)\n",
        "\n",
        "r = (-400,400)\n",
        "fig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=animals + [None] * 1000)\n",
        "fig.update_traces(marker=dict(size=5,line=dict(width=3)),textfont_size=15)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yaxRI5kPo38"
      },
      "source": [
        "# **Training Models**\n",
        "- BERT\n",
        "- FLAN T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn-WSMx6ZGWA"
      },
      "source": [
        "## FLAN T5\n",
        "We are going to fine tune a pretrained T5 model with beerqa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvYmZws4kYhA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:22:47.519352Z",
          "iopub.status.busy": "2024-05-26T12:22:47.518675Z",
          "iopub.status.idle": "2024-05-26T12:22:53.885514Z",
          "shell.execute_reply": "2024-05-26T12:22:53.884541Z",
          "shell.execute_reply.started": "2024-05-26T12:22:47.519322Z"
        },
        "id": "F60T3oLoZHwu",
        "outputId": "3756bf29-cc2b-4c60-cf74-c07e91cf0e58",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import T5Tokenizer\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2tpykQnZQC2"
      },
      "source": [
        "### *Data Pre-Processing*\n",
        "For starters we need to convert our dataset into the correct format:\n",
        "\n",
        "**input**\n",
        "question: question_text  context: context\n",
        "\n",
        "**target**\n",
        "*answer_text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:24:58.265529Z",
          "iopub.status.busy": "2024-05-26T12:24:58.265150Z",
          "iopub.status.idle": "2024-05-26T12:24:58.617818Z",
          "shell.execute_reply": "2024-05-26T12:24:58.617088Z",
          "shell.execute_reply.started": "2024-05-26T12:24:58.265503Z"
        },
        "id": "-Y-pVZkUZKSn",
        "outputId": "bba08ffc-5a66-49b9-8858-6ccbb2c76648",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Import the model's tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:24:58.619664Z",
          "iopub.status.busy": "2024-05-26T12:24:58.619389Z",
          "iopub.status.idle": "2024-05-26T12:24:58.627671Z",
          "shell.execute_reply": "2024-05-26T12:24:58.626718Z",
          "shell.execute_reply.started": "2024-05-26T12:24:58.619640Z"
        },
        "id": "nbLVKfxyZWKJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to build input sequence. Note that in addition to the format question: 'question' context: 'context' we also need an eof token\n",
        "def add_eos_to_examples(example):\n",
        "    # Since there may be multiple hops, unify the contexts of each example in order to get a single string\n",
        "    # example['context'] = ' '.join([' '.join(context) for context in example['context']])\n",
        "    # Build the input\n",
        "    example['input_text'] = 'question: %s  context: %s </s>' % (example['question'], example['context'])\n",
        "    # Build the target\n",
        "    example['target_text'] = '%s </s>' % example['answers'][0]\n",
        "    return example\n",
        "\n",
        "# Function to tokenize the examples made\n",
        "def convert_to_features(example_batch):\n",
        "    # Encode the inputs and the outputs using the T5 tokenizer. Note that we pad the inputs to a maximum length of 512 and the\n",
        "    # outputs to a maximum length of 16 (zero-padding)\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=512)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=16)\n",
        "    # Set the newly obtained encoding\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'target_ids': target_encodings['input_ids'],\n",
        "        'target_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:24:58.629180Z",
          "iopub.status.busy": "2024-05-26T12:24:58.628921Z",
          "iopub.status.idle": "2024-05-26T12:24:58.644614Z",
          "shell.execute_reply": "2024-05-26T12:24:58.643836Z",
          "shell.execute_reply.started": "2024-05-26T12:24:58.629157Z"
        },
        "id": "Ch1nswXNZYWL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to split into train and validation\n",
        "def train_val_split(dataset, val=0.2, seed=42):\n",
        "    \"\"\"\n",
        "    Divide the list into train and validation sets\n",
        "\n",
        "    :param data: original dataset.\n",
        "    :param val: percentage of data used for building the validation set. Default is 0.2 (20%).\n",
        "    :param seed: Reproducibility seed. Default is 42.\n",
        "    :return: tuple (train, validation).\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    val_size = int(len(dataset) * val)\n",
        "    val_set = random.sample(dataset, val_size)\n",
        "    # Now, get all the indices of validation set and use it to find remaining data, which will be the train set\n",
        "    val_indices = [doc['id'] for doc in val_set]\n",
        "    train_set = [doc for doc in dataset if doc['id'] not in val_indices]\n",
        "    # Now remove all fields but answers, question, and context\n",
        "    train_set = [{'answers': [ans for ans in doc['answers']], 'question': doc['question'], 'context': [context for context in doc['context']]} for doc in train_set]\n",
        "    val_set = [{'answers': [ans for ans in doc['answers']], 'question': doc['question'], 'context': [context for context in doc['context']]} for doc in val_set]\n",
        "\n",
        "    return train_set, val_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:24:58.645864Z",
          "iopub.status.busy": "2024-05-26T12:24:58.645603Z",
          "iopub.status.idle": "2024-05-26T12:25:25.794199Z",
          "shell.execute_reply": "2024-05-26T12:25:25.793394Z",
          "shell.execute_reply.started": "2024-05-26T12:24:58.645843Z"
        },
        "id": "BT57dvbqZdz4",
        "outputId": "92afa602-cdf1-4506-9a01-896b8e844e5a",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a4088af8aea14c28987ff779c3acc182",
            "97c17bf93f854949ba3fcb0d6347a9f6",
            "55a7ce50626b4a60a0845bcad9234aee",
            "980b850568a84bc9941167133d8283a4",
            "0b7260d4f2ea4792b4ee821fd05ed9e7",
            "c8862e7f5cda4c40aa73fc511a72b516"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4088af8aea14c28987ff779c3acc182",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97c17bf93f854949ba3fcb0d6347a9f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:309: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55a7ce50626b4a60a0845bcad9234aee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "980b850568a84bc9941167133d8283a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b7260d4f2ea4792b4ee821fd05ed9e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8862e7f5cda4c40aa73fc511a72b516",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Divide train in train and validation split.\n",
        "val = 0.2\n",
        "# For simplicity we are going to use not the total training data\n",
        "train_dataset, valid_dataset = train_val_split(json_train['data'][:7000], val)\n",
        "\n",
        "# Build the datasets for training. For simplicity we first convert each of the two datasets into pandas dataframes,\n",
        "#and then build the Dataset object using Dataset\n",
        "train_dataset = Dataset.from_pandas(pd.DataFrame(train_dataset))\n",
        "valid_dataset = Dataset.from_pandas(pd.DataFrame(valid_dataset))\n",
        "# Build the dataset for evaluation. Here too we use dataframes for simplicity and a smaller version of the dev dataset\n",
        "eval_dataset = Dataset.from_pandas(pd.DataFrame(dev[:7000]))\n",
        "\n",
        "# Map add_eos_to_examples function to the dataset example wise. Basically add the needed tokens to each document.\n",
        "train_dataset = train_dataset.map(add_eos_to_examples)\n",
        "# Map convert_to_features batch wise. Convert to the format required by the model\n",
        "train_dataset = train_dataset.map(convert_to_features, batched=True)\n",
        "# Same reasoning for the validation set and the eval_dataset\n",
        "valid_dataset = valid_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
        "eval_dataset = eval_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "eval_dataset = eval_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
        "\n",
        "# Set the tensor type and the columns which the dataset should return\n",
        "columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\n",
        "train_dataset.set_format(type='torch', columns=columns)\n",
        "valid_dataset.set_format(type='torch', columns=columns)\n",
        "eval_dataset.set_format(type='torch', columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:25:25.796628Z",
          "iopub.status.busy": "2024-05-26T12:25:25.796350Z",
          "iopub.status.idle": "2024-05-26T12:25:26.592764Z",
          "shell.execute_reply": "2024-05-26T12:25:26.591983Z",
          "shell.execute_reply.started": "2024-05-26T12:25:25.796605Z"
        },
        "id": "8h9wmZcaZgO8",
        "outputId": "05f0cee6-4c25-46bd-e4e4-b97894a4f9e1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size:  5600 \n",
            "Validation set size:  1400 \n",
            "Evaluation set size:  7000\n"
          ]
        }
      ],
      "source": [
        "# Check the length of the new sets\n",
        "print('Train set size: ', len(train_dataset), '\\nValidation set size: ', len(valid_dataset), '\\nEvaluation set size: ', len(eval_dataset))\n",
        "# Cach the dataset, so we can load it directly for training\n",
        "torch.save(train_dataset, 'train_data.pt')\n",
        "torch.save(valid_dataset, 'valid_data.pt')\n",
        "torch.save(eval_dataset, 'eval_data.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyzf8BP4ZiT7"
      },
      "source": [
        "### *Fine Tuning*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:25:26.594111Z",
          "iopub.status.busy": "2024-05-26T12:25:26.593827Z",
          "iopub.status.idle": "2024-05-26T12:25:38.364594Z",
          "shell.execute_reply": "2024-05-26T12:25:38.363687Z",
          "shell.execute_reply.started": "2024-05-26T12:25:26.594087Z"
        },
        "id": "SStr9t2dZkZ6",
        "trusted": true,
        "outputId": "928b9fe4-84ea-4088-8202-818a29262b29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-26 12:25:28.579459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-26 12:25:28.579559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-26 12:25:28.732027: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "# Define the collator for our dataset\n",
        "# We need a customised collator to map the target_ids tl the 'labels' field of the elements of the batch.\n",
        "# prepares labels from target_ids, returns examples with keys as expected by the forward method\n",
        "def collate_batch(batch: List, tokenizer:tokenizer) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Take a list of samples from a Dataset and collate them into a batch.\n",
        "        Returns:\n",
        "            A dictionary of tensors\n",
        "        \"\"\"\n",
        "        input_ids = torch.stack([example['input_ids'] for example in batch])\n",
        "        # lm_labels are now simply called labels in T5ForConditionalGenerator\n",
        "        lm_labels = torch.stack([example['target_ids'] for example in batch])\n",
        "        # Here we put to -100 the value of the tokens with 0-value, which are present due to 0 padding.\n",
        "        # This way they are not considered when computing the loss.\n",
        "        lm_labels[lm_labels[:, :] == 0] = -100\n",
        "        attention_mask = torch.stack([example['attention_mask'] for example in batch])\n",
        "        decoder_attention_mask = torch.stack([example['target_attention_mask'] for example in batch])\n",
        "\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': lm_labels,\n",
        "            'decoder_attention_mask': decoder_attention_mask\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:25:38.366606Z",
          "iopub.status.busy": "2024-05-26T12:25:38.365887Z",
          "iopub.status.idle": "2024-05-26T12:25:38.433694Z",
          "shell.execute_reply": "2024-05-26T12:25:38.432617Z",
          "shell.execute_reply.started": "2024-05-26T12:25:38.366568Z"
        },
        "id": "Fe2GGudqZzuf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Prepare the arguments for the trainer\n",
        "training_args = TrainingArguments(\n",
        "    \"t5_trainer\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # Gradient accumulation to use batch sized larger the available VRAM\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs= 10,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    remove_unused_columns=False,\n",
        "    log_level='info',\n",
        "    do_train=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:25:38.436521Z",
          "iopub.status.busy": "2024-05-26T12:25:38.436108Z",
          "iopub.status.idle": "2024-05-26T12:25:43.886091Z",
          "shell.execute_reply": "2024-05-26T12:25:43.885180Z",
          "shell.execute_reply.started": "2024-05-26T12:25:38.436485Z"
        },
        "id": "FvzDEVucZ7Hd",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "b7ac2cbe8ccd4063b959af9c0c8fef8b",
            "847a6bfe80d34e91acb541158f17d0e9"
          ]
        },
        "outputId": "a538ae48-794b-42c2-abc3-6cb8f44f36ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7ac2cbe8ccd4063b959af9c0c8fef8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "847a6bfe80d34e91acb541158f17d0e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, EvalPrediction\n",
        "model = T5ForConditionalGeneration.from_pretrained(\n",
        "    't5-base'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:25:43.887514Z",
          "iopub.status.busy": "2024-05-26T12:25:43.887224Z",
          "iopub.status.idle": "2024-05-26T12:25:44.997704Z",
          "shell.execute_reply": "2024-05-26T12:25:44.996591Z",
          "shell.execute_reply.started": "2024-05-26T12:25:43.887491Z"
        },
        "id": "u-P50YvNZ9NL",
        "trusted": true,
        "outputId": "2a58091f-3b5e-48be-aa1f-85b607017cef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Build the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    data_collator=lambda data: collate_batch(data, tokenizer)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T12:25:45.000089Z",
          "iopub.status.busy": "2024-05-26T12:25:44.999152Z",
          "iopub.status.idle": "2024-05-26T13:54:05.036239Z",
          "shell.execute_reply": "2024-05-26T13:54:05.035294Z",
          "shell.execute_reply.started": "2024-05-26T12:25:45.000053Z"
        },
        "id": "RzYKxHIyZ_XA",
        "trusted": true,
        "outputId": "f7baf97c-4a36-4e75-e1af-9bb00cff344a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 5,600\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 4\n",
            "  Training with DataParallel so batch size has been adjusted to: 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 870\n",
            "  Number of trainable parameters = 222,903,552\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ········································\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_122608-6t2qc9vq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/red-men/huggingface/runs/6t2qc9vq' target=\"_blank\">expert-thunder-7</a></strong> to <a href='https://wandb.ai/red-men/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/red-men/huggingface' target=\"_blank\">https://wandb.ai/red-men/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/red-men/huggingface/runs/6t2qc9vq' target=\"_blank\">https://wandb.ai/red-men/huggingface/runs/6t2qc9vq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [870/870 1:27:29, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.393507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.321149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.304805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.404100</td>\n",
              "      <td>0.299803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.404100</td>\n",
              "      <td>0.297932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.404100</td>\n",
              "      <td>0.297872</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5_trainer/checkpoint-500\n",
            "Configuration saved in t5_trainer/checkpoint-500/config.json\n",
            "Configuration saved in t5_trainer/checkpoint-500/generation_config.json\n",
            "Model weights saved in t5_trainer/checkpoint-500/model.safetensors\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=870, training_loss=0.3652862373439745, metrics={'train_runtime': 5299.2966, 'train_samples_per_second': 10.567, 'train_steps_per_second': 0.164, 'total_flos': 3.39067753463808e+16, 'train_loss': 0.3652862373439745, 'epoch': 9.94})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T13:54:05.038641Z",
          "iopub.status.busy": "2024-05-26T13:54:05.037874Z",
          "iopub.status.idle": "2024-05-26T13:54:06.289981Z",
          "shell.execute_reply": "2024-05-26T13:54:06.288967Z",
          "shell.execute_reply.started": "2024-05-26T13:54:05.038602Z"
        },
        "id": "J3YeAx8HaBVW",
        "trusted": true,
        "outputId": "1f77a88a-f9c5-4f60-ebd6-4054bc20943b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tokenizer config file saved in t5_fine_tuning_2024_05_26_13_54_05/tokenizer_config.json\n",
            "Special tokens file saved in t5_fine_tuning_2024_05_26_13_54_05/special_tokens_map.json\n",
            "added tokens file saved in t5_fine_tuning_2024_05_26_13_54_05/added_tokens.json\n",
            "Configuration saved in t5_fine_tuning_2024_05_26_13_54_05/config.json\n",
            "Configuration saved in t5_fine_tuning_2024_05_26_13_54_05/generation_config.json\n",
            "Model weights saved in t5_fine_tuning_2024_05_26_13_54_05/model.safetensors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved at: 't5_fine_tuning_2024_05_26_13_54_05'\n"
          ]
        }
      ],
      "source": [
        "# Save the fine tuned model, plus the tokenizer\n",
        "from datetime import datetime\n",
        "\n",
        "checkpoint_path = f\"t5_fine_tuning_{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "tokenizer.save_pretrained(checkpoint_path)\n",
        "model.save_pretrained(checkpoint_path)\n",
        "print(f\"Checkpoint saved at: \\'{checkpoint_path}\\'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLkfImeYaLds"
      },
      "source": [
        "### *Evaluation*\n",
        "Now we are going to evaluate our newly fine-tuned model on the dev beerqa set. The evaluation script is taken, but slightly modified, from the T5 Fine tuning [guide](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil), which is in turn adapted from the SQuAD evaluation script available [here](https://github.com/allenai/bi-att-flow/blob/master/squad/evaluate-v1.1.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T13:54:06.291692Z",
          "iopub.status.busy": "2024-05-26T13:54:06.291410Z",
          "iopub.status.idle": "2024-05-26T13:54:07.327886Z",
          "shell.execute_reply": "2024-05-26T13:54:07.326885Z",
          "shell.execute_reply.started": "2024-05-26T13:54:06.291667Z"
        },
        "id": "GRd-CFnULvyf",
        "trusted": true,
        "outputId": "e759be1f-d32b-4722-e7b3-b6f83003032a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file spiece.model\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading file tokenizer.json\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "loading configuration file t5_fine_tuning_2024_05_26_13_54_05/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file t5_fine_tuning_2024_05_26_13_54_05/model.safetensors\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5_fine_tuning_2024_05_26_13_54_05.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file t5_fine_tuning_2024_05_26_13_54_05/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build a dataloader to feed the eval_dataset to the model\n",
        "dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=32, collate_fn=lambda data: collate_batch(data, tokenizer))\n",
        "# Restore the model\n",
        "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(checkpoint_path).to(device)\n",
        "# Set the model to evaluation\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T13:54:07.329642Z",
          "iopub.status.busy": "2024-05-26T13:54:07.329287Z",
          "iopub.status.idle": "2024-05-26T13:54:07.347371Z",
          "shell.execute_reply": "2024-05-26T13:54:07.346387Z",
          "shell.execute_reply.started": "2024-05-26T13:54:07.329610Z"
        },
        "id": "0NN8OWI-aQbT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "## SQuAD evaluation script. Modifed slightly for this notebook\n",
        "\n",
        "from __future__ import print_function\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "# Safety in case the strings have different length.\n",
        "def pad_strings(str1, str2):\n",
        "    len1 = len(str1)\n",
        "    len2 = len(str2)\n",
        "\n",
        "    max_len = max(len1, len2)\n",
        "\n",
        "    if len1 < max_len:\n",
        "        str1 = str1.ljust(max_len)\n",
        "    if len2 < max_len:\n",
        "        str2 = str2.ljust(max_len)\n",
        "\n",
        "    return str1, str2\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        if len(ground_truth)!=len(prediction):\n",
        "              ground_truth, prediction = pad_strings(ground_truth, prediction)\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "\n",
        "def evaluate(gold_answers, predictions):\n",
        "    f1 = exact_match = total = 0\n",
        "\n",
        "    for ground_truths, prediction in zip(gold_answers, predictions):\n",
        "        total += 1\n",
        "        exact_match += metric_max_over_ground_truths(\n",
        "                    exact_match_score, prediction, ground_truths)\n",
        "        f1 += metric_max_over_ground_truths(\n",
        "          f1_score, prediction, ground_truths)\n",
        "\n",
        "    exact_match = 100.0 * exact_match / total\n",
        "    f1 = 100.0 * f1 / total\n",
        "\n",
        "    return {'exact_match': exact_match, 'f1': f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T13:54:07.353806Z",
          "iopub.status.busy": "2024-05-26T13:54:07.353531Z",
          "iopub.status.idle": "2024-05-26T14:00:16.810800Z",
          "shell.execute_reply": "2024-05-26T14:00:16.809893Z",
          "shell.execute_reply.started": "2024-05-26T13:54:07.353777Z"
        },
        "id": "RIzcVn1ybINm",
        "trusted": true,
        "outputId": "3aaa7944-260d-485e-8dc4-966184c34561"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/219 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "100%|██████████| 219/219 [06:09<00:00,  1.69s/it]\n"
          ]
        }
      ],
      "source": [
        "# Get the predictions from our model\n",
        "answers = []\n",
        "# For each batch made by the data loader generate an answer, then decode it using the T5 tokenizer\n",
        "for batch in tqdm.tqdm(dataloader):\n",
        "    outs = model.generate(input_ids=batch['input_ids'].to(device),\n",
        "                        attention_mask=batch['attention_mask'].to(device),\n",
        "                        max_length=16,\n",
        "                        early_stopping=True)\n",
        "    outs = [tokenizer.decode(ids) for ids in outs]\n",
        "    answers.extend(outs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T14:00:16.813453Z",
          "iopub.status.busy": "2024-05-26T14:00:16.812607Z",
          "iopub.status.idle": "2024-05-26T14:04:34.820932Z",
          "shell.execute_reply": "2024-05-26T14:04:34.819637Z",
          "shell.execute_reply.started": "2024-05-26T14:00:16.813410Z"
        },
        "id": "EbrsI3d5MLQc",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "23cfd317b10140c68ed834503099d4a8"
          ]
        },
        "outputId": "ed39d9cd-6399-4660-f5cf-f6dba77757bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23cfd317b10140c68ed834503099d4a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Restore the ground truth of the evaluation dataset\n",
        "def add_answers(example, idx):\n",
        "    example['answer'] = eval_dataset['answers'][idx]\n",
        "    return example\n",
        "# Add the correct answer to each element of the dataset\n",
        "eval_dataset_ = eval_dataset.map(add_answers, with_indices=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T14:04:34.822410Z",
          "iopub.status.busy": "2024-05-26T14:04:34.822103Z",
          "iopub.status.idle": "2024-05-26T14:04:38.188425Z",
          "shell.execute_reply": "2024-05-26T14:04:38.187177Z",
          "shell.execute_reply.started": "2024-05-26T14:04:34.822384Z"
        },
        "id": "ldGP37dYMYjg",
        "trusted": true,
        "outputId": "4f6c828b-913a-4fd7-d759-f0793b0970f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact_match': 68.52857142857142, 'f1': 80.32793970461822}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = []\n",
        "references = []\n",
        "# Build golden answer and prediction dictionary which will be fed to the evaluate function\n",
        "for ref, pred in zip(eval_dataset_, answers):\n",
        "    # Here we had to remove the padding and the end of string tokens which are added to the output by the model\n",
        "    predictions.append(pred.replace(\"<pad>\", \"\").replace(\"</s>\", \"\"))\n",
        "    references.append(ref['answer'])\n",
        "\n",
        "# Call the evaluate function\n",
        "evaluate(references, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T14:04:38.190264Z",
          "iopub.status.busy": "2024-05-26T14:04:38.189871Z",
          "iopub.status.idle": "2024-05-26T14:04:38.201046Z",
          "shell.execute_reply": "2024-05-26T14:04:38.199908Z",
          "shell.execute_reply.started": "2024-05-26T14:04:38.190209Z"
        },
        "id": "-XRoQ38xMeZo",
        "trusted": true,
        "outputId": "b81fc80d-c345-4eab-8a52-f84d4a3198ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground truth: ['The Spinners'], Prediction:  The Spinners\n",
            "\n",
            "Ground truth: ['The Spiral'], Prediction:  New York World Building\n",
            "\n",
            "Ground truth: [\"'gifts' and biased information\"], Prediction:  marketing 'gifts' and biased information\n",
            "\n",
            "Ground truth: ['American War of Independence'], Prediction:  American War of Independence\n",
            "\n",
            "Ground truth: ['Eddie Izzard'], Prediction:  Eddie Izzard\n",
            "\n",
            "Ground truth: ['Egremont'], Prediction:  Egremont\n",
            "\n",
            "Ground truth: ['Funafuti International Airport'], Prediction:  Funafuti International Airport\n",
            "\n",
            "Ground truth: ['Gamal Abdul Nasser'], Prediction:  Gamal Abdul Nasser\n",
            "\n",
            "Ground truth: ['Maurice Hilleman'], Prediction:  Maurice Hilleman\n",
            "\n",
            "Ground truth: ['Latka Gravas'], Prediction:  Latka Gravas\n",
            "\n",
            "Ground truth: ['Jeremy Renner'], Prediction:  Jeremy Lee Renner\n",
            "\n",
            "Ground truth: ['1895'], Prediction:  1895\n",
            "\n",
            "Ground truth: ['A bantam'], Prediction:  A bantam\n",
            "\n",
            "Ground truth: ['Melanie Oudin'], Prediction:  Melanie Oudin\n",
            "\n",
            "Ground truth: ['Othonna'], Prediction:  Stangeria\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print some random examples of pairs ground truth, prediction\n",
        "n_of_samples = 15\n",
        "for i in range(n_of_samples):\n",
        "    idx = random.randint(0, len(predictions)-1)\n",
        "    print('Ground truth: {}, Prediction: {}\\n'.format(references[idx], predictions[idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T14:50:47.939665Z",
          "iopub.status.busy": "2024-05-26T14:50:47.939325Z",
          "iopub.status.idle": "2024-05-26T14:50:47.945746Z",
          "shell.execute_reply": "2024-05-26T14:50:47.944609Z",
          "shell.execute_reply.started": "2024-05-26T14:50:47.939641Z"
        },
        "trusted": true,
        "id": "71ti4ZuU_kvp"
      },
      "outputs": [],
      "source": [
        "# Clean cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRF7pbt4Ofm"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T14:04:38.202712Z",
          "iopub.status.busy": "2024-05-26T14:04:38.202143Z",
          "iopub.status.idle": "2024-05-26T14:04:38.304402Z",
          "shell.execute_reply": "2024-05-26T14:04:38.303450Z",
          "shell.execute_reply.started": "2024-05-26T14:04:38.202680Z"
        },
        "id": "HUCchxNv440g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7fPAlYL4dVH"
      },
      "source": [
        "### *Data Pre-Processing*\n",
        "Moving data to a pd DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:33:52.373337Z",
          "iopub.status.busy": "2024-05-26T15:33:52.372419Z",
          "iopub.status.idle": "2024-05-26T15:33:52.420639Z",
          "shell.execute_reply": "2024-05-26T15:33:52.419535Z",
          "shell.execute_reply.started": "2024-05-26T15:33:52.373301Z"
        },
        "id": "vKUrjTZi4zkT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(train[:int(0.2*len(train))])\n",
        "df_dev = pd.DataFrame(dev[:int(0.2*len(dev))])\n",
        "df_test = pd.DataFrame(test[:int(0.2*len(test))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:33:54.695029Z",
          "iopub.status.busy": "2024-05-26T15:33:54.694306Z",
          "iopub.status.idle": "2024-05-26T15:33:54.714195Z",
          "shell.execute_reply": "2024-05-26T15:33:54.713083Z",
          "shell.execute_reply.started": "2024-05-26T15:33:54.695000Z"
        },
        "id": "WFRwVzS_5abc",
        "outputId": "4380d975-3afe-47ed-fed3-dca89174ec46",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1793]</td>\n",
              "      <td>When did Wordsworth initially attack Burke?</td>\n",
              "      <td>[[Edmund Burke, In the 19th century, Burke was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Investiture Controversy]</td>\n",
              "      <td>The clash between Henry IV and the pope was pa...</td>\n",
              "      <td>[[Middle Ages, During the early High Middle Ag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[the Thermidorian Reaction]</td>\n",
              "      <td>What historical event brought about the fall o...</td>\n",
              "      <td>[[Napoleon, Some contemporaries alleged that B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Morales]</td>\n",
              "      <td>Who came up with a policy for indigenous auton...</td>\n",
              "      <td>[[Indigenous peoples of the Americas, Morales ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Darren Lynn Bousman]</td>\n",
              "      <td>Greg Hoffman was working on \"Saw III,\" a 2006 ...</td>\n",
              "      <td>[[Saw III, Saw III is a 2006 horror film direc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       answers  \\\n",
              "0                       [1793]   \n",
              "1    [Investiture Controversy]   \n",
              "2  [the Thermidorian Reaction]   \n",
              "3                    [Morales]   \n",
              "4        [Darren Lynn Bousman]   \n",
              "\n",
              "                                            question  \\\n",
              "0        When did Wordsworth initially attack Burke?   \n",
              "1  The clash between Henry IV and the pope was pa...   \n",
              "2  What historical event brought about the fall o...   \n",
              "3  Who came up with a policy for indigenous auton...   \n",
              "4  Greg Hoffman was working on \"Saw III,\" a 2006 ...   \n",
              "\n",
              "                                             context  \n",
              "0  [[Edmund Burke, In the 19th century, Burke was...  \n",
              "1  [[Middle Ages, During the early High Middle Ag...  \n",
              "2  [[Napoleon, Some contemporaries alleged that B...  \n",
              "3  [[Indigenous peoples of the Americas, Morales ...  \n",
              "4  [[Saw III, Saw III is a 2006 horror film direc...  "
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHZFSr1w5tRI"
      },
      "source": [
        "We need to extract answers from lists and also combine lists in context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:33:56.393549Z",
          "iopub.status.busy": "2024-05-26T15:33:56.393148Z",
          "iopub.status.idle": "2024-05-26T15:33:56.421189Z",
          "shell.execute_reply": "2024-05-26T15:33:56.420030Z",
          "shell.execute_reply.started": "2024-05-26T15:33:56.393520Z"
        },
        "id": "lqpP67Vf6Sma",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train['answers'] = df_train['answers'].apply(lambda x: x[0])\n",
        "df_dev['answers'] = df_dev['answers'].apply(lambda x: x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:33:57.799768Z",
          "iopub.status.busy": "2024-05-26T15:33:57.799051Z",
          "iopub.status.idle": "2024-05-26T15:33:57.805995Z",
          "shell.execute_reply": "2024-05-26T15:33:57.804906Z",
          "shell.execute_reply.started": "2024-05-26T15:33:57.799736Z"
        },
        "id": "_oAg0wd152EA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def combine_context(context):\n",
        "    combined_text = \"\"\n",
        "    for passage in context:\n",
        "        combined_text += (\". \").join(passage) + \". \"\n",
        "    return combined_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:33:59.236081Z",
          "iopub.status.busy": "2024-05-26T15:33:59.235506Z",
          "iopub.status.idle": "2024-05-26T15:33:59.343330Z",
          "shell.execute_reply": "2024-05-26T15:33:59.342284Z",
          "shell.execute_reply.started": "2024-05-26T15:33:59.236038Z"
        },
        "id": "XtvEfeRM55-B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train['context'] = df_train['context'].apply(combine_context)\n",
        "df_dev['context'] = df_dev['context'].apply(combine_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:34:00.406590Z",
          "iopub.status.busy": "2024-05-26T15:34:00.405547Z",
          "iopub.status.idle": "2024-05-26T15:34:00.426764Z",
          "shell.execute_reply": "2024-05-26T15:34:00.425265Z",
          "shell.execute_reply.started": "2024-05-26T15:34:00.406549Z"
        },
        "id": "sSQePTvP52BW",
        "outputId": "fbdcd167-fe9d-48e2-dbcf-627b28844ba9",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1793</td>\n",
              "      <td>When did Wordsworth initially attack Burke?</td>\n",
              "      <td>Edmund Burke. In the 19th century, Burke was p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Investiture Controversy</td>\n",
              "      <td>The clash between Henry IV and the pope was pa...</td>\n",
              "      <td>Middle Ages. During the early High Middle Ages...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the Thermidorian Reaction</td>\n",
              "      <td>What historical event brought about the fall o...</td>\n",
              "      <td>Napoleon. Some contemporaries alleged that Bon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Morales</td>\n",
              "      <td>Who came up with a policy for indigenous auton...</td>\n",
              "      <td>Indigenous peoples of the Americas. Morales be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Darren Lynn Bousman</td>\n",
              "      <td>Greg Hoffman was working on \"Saw III,\" a 2006 ...</td>\n",
              "      <td>Saw III. Saw III is a 2006 horror film directe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     answers  \\\n",
              "0                       1793   \n",
              "1    Investiture Controversy   \n",
              "2  the Thermidorian Reaction   \n",
              "3                    Morales   \n",
              "4        Darren Lynn Bousman   \n",
              "\n",
              "                                            question  \\\n",
              "0        When did Wordsworth initially attack Burke?   \n",
              "1  The clash between Henry IV and the pope was pa...   \n",
              "2  What historical event brought about the fall o...   \n",
              "3  Who came up with a policy for indigenous auton...   \n",
              "4  Greg Hoffman was working on \"Saw III,\" a 2006 ...   \n",
              "\n",
              "                                             context  \n",
              "0  Edmund Burke. In the 19th century, Burke was p...  \n",
              "1  Middle Ages. During the early High Middle Ages...  \n",
              "2  Napoleon. Some contemporaries alleged that Bon...  \n",
              "3  Indigenous peoples of the Americas. Morales be...  \n",
              "4  Saw III. Saw III is a 2006 horror film directe...  "
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfF41Zzn6iu6"
      },
      "source": [
        "Now data looks ready to be processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_GWwPYt6qzn"
      },
      "source": [
        "#### Tokenizer\n",
        "As BERT can process not more than 512 tokens (including CLS and SEP), we need to check if the data has more than 512 tokens in context + question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:34:05.468519Z",
          "iopub.status.busy": "2024-05-26T15:34:05.467756Z",
          "iopub.status.idle": "2024-05-26T15:34:05.672618Z",
          "shell.execute_reply": "2024-05-26T15:34:05.671641Z",
          "shell.execute_reply.started": "2024-05-26T15:34:05.468488Z"
        },
        "id": "K-rvDcon517U",
        "outputId": "89a5908e-bb7c-4ead-bb8c-b577b91b262d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx46xFCZ7UFY"
      },
      "source": [
        "First of all, let's see if there're more than 510 words in each context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:34:08.234972Z",
          "iopub.status.busy": "2024-05-26T15:34:08.234129Z",
          "iopub.status.idle": "2024-05-26T15:34:10.301177Z",
          "shell.execute_reply": "2024-05-26T15:34:10.300045Z",
          "shell.execute_reply.started": "2024-05-26T15:34:08.234944Z"
        },
        "id": "4e-_VF4c7h0e",
        "outputId": "bdc261ab-dde6-4a50-edf8-aa500af1a10a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of > 510 words in train data:  0.17 %\n",
            "Percentage of > 510 words in dev data:  0.07 %\n"
          ]
        }
      ],
      "source": [
        "greater_than_510_words = len([1 for i, row in df_train.iterrows() if len(row['context'].split()) + len(row['question'].split()) > 510])\n",
        "dev_greater_than_510_words = len([1 for i, row in df_dev.iterrows() if len(row['context'].split()) + len(row['question'].split()) > 510])\n",
        "print(\"Percentage of > 510 words in train data: \", round(greater_than_510_words/len(df_train) * 100, 2), \"%\")\n",
        "print(\"Percentage of > 510 words in dev data: \", round(dev_greater_than_510_words/len(df_dev) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lB8MZba8EAE"
      },
      "source": [
        "As we can see, it's very small so we just drop it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:34:10.304183Z",
          "iopub.status.busy": "2024-05-26T15:34:10.303148Z",
          "iopub.status.idle": "2024-05-26T15:34:11.088791Z",
          "shell.execute_reply": "2024-05-26T15:34:11.087521Z",
          "shell.execute_reply.started": "2024-05-26T15:34:10.304143Z"
        },
        "id": "jJcqskXO7TNR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train = df_train[df_train.apply(lambda row: len(row['context'].split(' ')) + len(row['question'].split(' ')) <= 510, axis=1)]\n",
        "df_dev = df_dev[df_dev.apply(lambda row: len(row['context'].split(' ')) + len(row['question'].split(' ')) <= 510, axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7mCW62u8bvr"
      },
      "source": [
        "Now let's tokenize and see if ther're are samples with more than 512 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:34:38.164391Z",
          "iopub.status.busy": "2024-05-26T15:34:38.164000Z",
          "iopub.status.idle": "2024-05-26T15:37:45.079574Z",
          "shell.execute_reply": "2024-05-26T15:37:45.078298Z",
          "shell.execute_reply.started": "2024-05-26T15:34:38.164356Z"
        },
        "id": "5gHFOAd68NX4",
        "outputId": "1da95d65-af07-4451-af40-25077b357bd3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26763/26763 [03:06<00:00, 143.19it/s]\n"
          ]
        }
      ],
      "source": [
        "sen_length = []\n",
        "\n",
        "for idx, (sentence, question) in tqdm(enumerate(zip(df_train['context'], df_train['question'])), total=len(df_train)):\n",
        "    token_words = tokenizer_bert.encode_plus(sentence, question)[\"input_ids\"]\n",
        "    sen_length.append(len(token_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:37:45.081795Z",
          "iopub.status.busy": "2024-05-26T15:37:45.081505Z",
          "iopub.status.idle": "2024-05-26T15:38:04.046672Z",
          "shell.execute_reply": "2024-05-26T15:38:04.045750Z",
          "shell.execute_reply.started": "2024-05-26T15:37:45.081770Z"
        },
        "id": "0mryWAyY8NM2",
        "outputId": "bade8865-0667-42ee-c9fe-d9026c07a7cd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2822/2822 [00:18<00:00, 148.88it/s]\n"
          ]
        }
      ],
      "source": [
        "sen_length_dev = []\n",
        "\n",
        "for idx, (sentence, question) in tqdm(enumerate(zip(df_dev['context'], df_dev['question'])), total=len(df_dev)):\n",
        "    token_words = tokenizer_bert.encode_plus(sentence, question)[\"input_ids\"]\n",
        "    sen_length_dev.append(len(token_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:04.048110Z",
          "iopub.status.busy": "2024-05-26T15:38:04.047835Z",
          "iopub.status.idle": "2024-05-26T15:38:04.055557Z",
          "shell.execute_reply": "2024-05-26T15:38:04.054710Z",
          "shell.execute_reply.started": "2024-05-26T15:38:04.048086Z"
        },
        "id": "BV5AsMx6-PYv",
        "outputId": "75fb8a0b-8ccc-4aba-ceeb-6a5939e3c831",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN: Max amount of tokens in sentence is  977\n",
            "DEV: Max amount of tokens in sentence is  655\n"
          ]
        }
      ],
      "source": [
        "print('TRAIN: Max amount of tokens in sentence is ', max(sen_length))\n",
        "print('DEV: Max amount of tokens in sentence is ', max(sen_length_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSRaSL0l-cpy"
      },
      "source": [
        "Let's see the distribution of amount of tokens in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:04.057920Z",
          "iopub.status.busy": "2024-05-26T15:38:04.057659Z",
          "iopub.status.idle": "2024-05-26T15:38:06.502440Z",
          "shell.execute_reply": "2024-05-26T15:38:06.501300Z",
          "shell.execute_reply.started": "2024-05-26T15:38:04.057898Z"
        },
        "id": "kkAbnlgP-P-V",
        "outputId": "95010a6b-2fab-424a-f19a-29c57b684bee",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(sen_length, color='orange', bins=len(set(sen_length)), label='Train data')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(sen_length_dev,color='green', bins=len(set(sen_length_dev)), label='Dev data')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.504039Z",
          "iopub.status.busy": "2024-05-26T15:38:06.503750Z",
          "iopub.status.idle": "2024-05-26T15:38:06.516659Z",
          "shell.execute_reply": "2024-05-26T15:38:06.515635Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.504013Z"
        },
        "id": "-j470mHr-iQt",
        "outputId": "d06fa74c-b5eb-44db-ac05-be3fba2e64c7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data:  26763\n",
            "Number of contexts > 512 tokens:  442\n",
            "Percentage of not suited data for BERT:  1.65 %\n",
            "Number of data:  2822\n",
            "Number of contexts > 512 tokens:  30\n",
            "Percentage of not suited data for BERT:  1.06 %\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "\n",
        "greater_than_512 = len([num for num in sen_length if num > 512])\n",
        "print(\"Number of data: \", len(sen_length))\n",
        "print(\"Number of contexts > 512 tokens: \", greater_than_512)\n",
        "print(\"Percentage of not suited data for BERT: \", round(greater_than_512/len(sen_length) * 100, 2), \"%\")\n",
        "\n",
        "# dev data\n",
        "dev_greater_than_512 = len([num for num in sen_length_dev if num > 512])\n",
        "print(\"Number of data: \", len(sen_length_dev))\n",
        "print(\"Number of contexts > 512 tokens: \", dev_greater_than_512)\n",
        "print(\"Percentage of not suited data for BERT: \", round(dev_greater_than_512/len(sen_length_dev) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY-xzy-4-2Ke"
      },
      "source": [
        "So little not suited data so we just drop it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.520025Z",
          "iopub.status.busy": "2024-05-26T15:38:06.518006Z",
          "iopub.status.idle": "2024-05-26T15:38:06.552545Z",
          "shell.execute_reply": "2024-05-26T15:38:06.551575Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.519992Z"
        },
        "id": "gDpTYhzJ-yAI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train['num_tokens'] = sen_length\n",
        "df_train = df_train[df_train['num_tokens'] <= 510]\n",
        "df_dev['num_tokens'] = sen_length_dev\n",
        "df_dev = df_dev[df_dev['num_tokens'] <= 510]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH_EJszY_Faa"
      },
      "source": [
        "#### Get test data with answers\n",
        "We want to extract 5 random samples from dev data to look at the answers provided by the model and compare them to actual ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.554757Z",
          "iopub.status.busy": "2024-05-26T15:38:06.554111Z",
          "iopub.status.idle": "2024-05-26T15:38:06.561800Z",
          "shell.execute_reply": "2024-05-26T15:38:06.560770Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.554722Z"
        },
        "id": "OLYfnHvJ-iOV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "try_data = df_dev.sample(frac=5/len(df_dev))\n",
        "df_dev = df_dev.drop(try_data.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6ILkrLc_o2U"
      },
      "source": [
        "#### Dataset class for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wys2IY0c_gDF"
      },
      "source": [
        "Let's prepare dataset and dataloader for BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.563511Z",
          "iopub.status.busy": "2024-05-26T15:38:06.563107Z",
          "iopub.status.idle": "2024-05-26T15:38:06.578349Z",
          "shell.execute_reply": "2024-05-26T15:38:06.577389Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.563467Z"
        },
        "id": "pSAuLP4b_aQf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        context = item['context']\n",
        "        question = item['question']\n",
        "        answer = item['answers']\n",
        "\n",
        "        bert_sens = tokenizer_bert.encode_plus(\n",
        "                                question,\n",
        "                                context,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = 510,\n",
        "                                padding='max_length',\n",
        "                                truncation=True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n",
        "\n",
        "        # Convert answer text to start and end token indices\n",
        "        start_token_idx = self.find_sublist(answer.split(), context.split())\n",
        "        if (start_token_idx != -1):\n",
        "              end_token_idx = start_token_idx + len(answer) - 1\n",
        "        else:\n",
        "              end_token_idx = -1\n",
        "        start_idx = torch.tensor(start_token_idx, dtype=torch.long)\n",
        "        end_idx = torch.tensor(end_token_idx, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'start_idx': start_idx,\n",
        "                'end_idx': end_idx\n",
        "            }\n",
        "\n",
        "    def find_sublist(self, sublist, lst):\n",
        "        \"\"\"Find the starting index of sublist in lst.\"\"\"\n",
        "        for i in range(len(lst) - len(sublist) + 1):\n",
        "            if lst[i:i + len(sublist)] == sublist:\n",
        "                return i\n",
        "        return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T14:22:06.893296Z",
          "iopub.status.busy": "2024-05-26T14:22:06.892353Z",
          "iopub.status.idle": "2024-05-26T14:22:06.904052Z",
          "shell.execute_reply": "2024-05-26T14:22:06.902976Z",
          "shell.execute_reply.started": "2024-05-26T14:22:06.893224Z"
        },
        "id": "TbjAGy3M_ybN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Use this if you want to drop some data\n",
        "# df_train = df_train.sample(frac=0.3, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.580541Z",
          "iopub.status.busy": "2024-05-26T15:38:06.579801Z",
          "iopub.status.idle": "2024-05-26T15:38:06.593637Z",
          "shell.execute_reply": "2024-05-26T15:38:06.592929Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.580506Z"
        },
        "id": "uGToPcBT_yY-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_dataset = BERTDataSet(df_train)\n",
        "valid_dataset = BERTDataSet(df_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab0kPp7s4hrw"
      },
      "source": [
        "### *Fine Tuning*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.597703Z",
          "iopub.status.busy": "2024-05-26T15:38:06.597408Z",
          "iopub.status.idle": "2024-05-26T15:38:06.603510Z",
          "shell.execute_reply": "2024-05-26T15:38:06.602502Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.597680Z"
        },
        "id": "B_ZVHllD4z_1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_batch = 16\n",
        "valid_batch = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.605017Z",
          "iopub.status.busy": "2024-05-26T15:38:06.604735Z",
          "iopub.status.idle": "2024-05-26T15:38:06.612754Z",
          "shell.execute_reply": "2024-05-26T15:38:06.611738Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.604993Z"
        },
        "id": "eFMh6_thAA62",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch, shuffle = True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=valid_batch, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:28:35.183669Z",
          "iopub.status.busy": "2024-05-26T15:28:35.183281Z",
          "iopub.status.idle": "2024-05-26T15:28:35.196275Z",
          "shell.execute_reply": "2024-05-26T15:28:35.195161Z",
          "shell.execute_reply.started": "2024-05-26T15:28:35.183642Z"
        },
        "trusted": true,
        "id": "uw5chwWp_kvs",
        "outputId": "4200b27c-1c05-43e0-8682-31633dd30154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla T4\n",
            "Memory Usage:\n",
            "Allocated: 13.9 GB\n",
            "Cached:    14.5 GB\n",
            "Total:    14.7 GB\n"
          ]
        }
      ],
      "source": [
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
        "    print('Total:   ', round(torch.cuda.mem_get_info(0)[1]/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:06.614288Z",
          "iopub.status.busy": "2024-05-26T15:38:06.613976Z",
          "iopub.status.idle": "2024-05-26T15:38:07.084582Z",
          "shell.execute_reply": "2024-05-26T15:38:07.083407Z",
          "shell.execute_reply.started": "2024-05-26T15:38:06.614256Z"
        },
        "id": "jpqUB7NgAHmS",
        "outputId": "621d0df5-f9ee-4f36-fbcb-38e5c825cd3a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to('cuda:1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhQc1CIWDWfV"
      },
      "source": [
        "Let's see how regular BERT answers questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:07.086563Z",
          "iopub.status.busy": "2024-05-26T15:38:07.086168Z",
          "iopub.status.idle": "2024-05-26T15:38:11.437459Z",
          "shell.execute_reply": "2024-05-26T15:38:11.435971Z",
          "shell.execute_reply.started": "2024-05-26T15:38:07.086526Z"
        },
        "id": "ucTlGKVUDVOX",
        "outputId": "2de06ccc-e5da-4c46-ec76-fca595b10773",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:  Which species of trees is larger Dryopteris or Gymnocladus?\n",
            "Real answer:  Dryopteris\n",
            "Model answer: is a small genus of leguminous\n",
            "Score: 4.115424962947145e-05\n",
            "Start index: 100\n",
            "End index: 130\n",
            "\n",
            "Question:  Which host of Sunday Night Safran has the hebrew first name Yehoshua?\n",
            "Real answer:  John Safran\n",
            "Model answer: things ethnic.\" It was hosted by John\n",
            "Score: 0.00015449625789187849\n",
            "Start index: 149\n",
            "End index: 186\n",
            "\n",
            "Question:  Both the 2010–11 UEFA Champions League knockout phase  and 011 UEFA Champions League Final were held at what London stadium?\n",
            "Real answer:  Wembley\n",
            "Model answer: in each of their\n",
            "Score: 0.00011908326268894598\n",
            "Start index: 697\n",
            "End index: 713\n",
            "\n",
            "Question:  What was the first manufactured fiber?\n",
            "Real answer:  rayon\n",
            "Model answer: polyester garments in the 1960s caused economic hardship in cotton-exporting\n",
            "Score: 5.114061787026003e-05\n",
            "Start index: 883\n",
            "End index: 959\n",
            "\n",
            "Question:  What was the title of the article Nasser wrote for his school paper?\n",
            "Real answer:  Voltaire, the Man of Freedom\n",
            "Model answer: prior\n",
            "Score: 8.567239274270833e-05\n",
            "Start index: 436\n",
            "End index: 441\n",
            "\n"
          ]
        }
      ],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer_bert)\n",
        "\n",
        "for idx, example in try_data.iterrows():\n",
        "    question = example['question']\n",
        "    context = example['context']\n",
        "    answer = example['answers']\n",
        "    result = qa_pipeline(context=context, question=question)\n",
        "    print(\"Question: \", question)\n",
        "    print(\"Real answer: \", answer)\n",
        "    print(\"Model answer:\", result['answer'])\n",
        "    print(\"Score:\", result['score'])\n",
        "    print(\"Start index:\", result['start'])\n",
        "    print(\"End index:\", result['end'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1DrsYOfFQCG"
      },
      "source": [
        "What if we train model on the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:11.439831Z",
          "iopub.status.busy": "2024-05-26T15:38:11.439377Z",
          "iopub.status.idle": "2024-05-26T15:38:11.455068Z",
          "shell.execute_reply": "2024-05-26T15:38:11.453791Z",
          "shell.execute_reply.started": "2024-05-26T15:38:11.439770Z"
        },
        "id": "5Kjkuk8ZAK6c",
        "outputId": "9a22226f-9bb1-485b-abcf-a7e53e273494",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUQNNhcAQkn"
      },
      "source": [
        "In [this](https://ai-scholar.tech/en/articles/bert/bert-fine-tuning) article we've seen that the best learning rate with Adam is 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:38:11.457056Z",
          "iopub.status.busy": "2024-05-26T15:38:11.456644Z",
          "iopub.status.idle": "2024-05-26T15:38:11.465832Z",
          "shell.execute_reply": "2024-05-26T15:38:11.464635Z",
          "shell.execute_reply.started": "2024-05-26T15:38:11.457032Z"
        },
        "id": "dU45KSAyANlg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "LR=2e-5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIihhebSAggb"
      },
      "source": [
        "#### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:40:25.421258Z",
          "iopub.status.busy": "2024-05-26T15:40:25.420408Z",
          "iopub.status.idle": "2024-05-26T15:40:25.555476Z",
          "shell.execute_reply": "2024-05-26T15:40:25.554436Z",
          "shell.execute_reply.started": "2024-05-26T15:40:25.421217Z"
        },
        "id": "-gmxS6w0ANjK",
        "trusted": true,
        "outputId": "2f1dd58c-0468-4805-d635-37418791ddb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_train_loss = 0\n",
        "epochs = 1 # specify here amount of epochs to go through\n",
        "model.to('cuda:1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T15:40:28.181783Z",
          "iopub.status.busy": "2024-05-26T15:40:28.181080Z",
          "iopub.status.idle": "2024-05-26T16:23:37.986051Z",
          "shell.execute_reply": "2024-05-26T16:23:37.981304Z",
          "shell.execute_reply.started": "2024-05-26T15:40:28.181752Z"
        },
        "id": "3LOvxZRjANQQ",
        "trusted": true,
        "outputId": "f88a2c76-1c46-4d2d-d209-c05e92bd2610"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1: 100%|██████████| 1645/1645 [43:08<00:00,  1.57s/it]\n",
            "Configuration saved in bert_qa_model_1_epoch/config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss for Epoch 1: 3.383063135103614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in bert_qa_model_1_epoch/model.safetensors\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[239], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Training Loss for Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_qa_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_qa_tokenizer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ids = batch['ids']\n",
        "        mask = batch['mask']\n",
        "        token_type_ids = batch['token_type_ids']\n",
        "        start_idx = batch['start_idx']\n",
        "        end_idx = batch['end_idx']\n",
        "\n",
        "        outputs = model(input_ids=ids.to('cuda:1'),\n",
        "                      attention_mask=mask.to('cuda:1'),\n",
        "                      token_type_ids=token_type_ids.to('cuda:1'),\n",
        "                      start_positions=start_idx.to('cuda:1'),\n",
        "                      end_positions=end_idx.to('cuda:1'))\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f\"Average Training Loss for Epoch {epoch+1}: {avg_train_loss}\")\n",
        "    model.save_pretrained(f'bert_qa_model_{epoch+1}_epoch')\n",
        "    tokenizer_bert.save_pretrained(f'bert_qa_tokenizer_{epoch+1}_epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:24:07.597110Z",
          "iopub.status.busy": "2024-05-26T16:24:07.596660Z",
          "iopub.status.idle": "2024-05-26T16:24:07.651303Z",
          "shell.execute_reply": "2024-05-26T16:24:07.650291Z",
          "shell.execute_reply.started": "2024-05-26T16:24:07.597075Z"
        },
        "trusted": true,
        "id": "gEVqvnLN_kvt",
        "outputId": "4587523c-b349-43f9-bd1a-1b7bef255cb7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tokenizer config file saved in bert_qa_tokenizer_1_epoch/tokenizer_config.json\n",
            "Special tokens file saved in bert_qa_tokenizer_1_epoch/special_tokens_map.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('bert_qa_tokenizer_1_epoch/tokenizer_config.json',\n",
              " 'bert_qa_tokenizer_1_epoch/special_tokens_map.json',\n",
              " 'bert_qa_tokenizer_1_epoch/vocab.txt',\n",
              " 'bert_qa_tokenizer_1_epoch/added_tokens.json')"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_bert.save_pretrained(f'bert_qa_tokenizer_{epoch+1}_epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJQ6zv_94hnI"
      },
      "source": [
        "### *Evaluation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:25:13.153780Z",
          "iopub.status.busy": "2024-05-26T16:25:13.153412Z",
          "iopub.status.idle": "2024-05-26T16:25:13.172672Z",
          "shell.execute_reply": "2024-05-26T16:25:13.171679Z",
          "shell.execute_reply.started": "2024-05-26T16:25:13.153753Z"
        },
        "trusted": true,
        "id": "o9ykgb3U_kvt",
        "outputId": "fdadb0ac-220b-4de3-babe-0245e3d2cde5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to('cuda:1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:26:28.761386Z",
          "iopub.status.busy": "2024-05-26T16:26:28.760995Z",
          "iopub.status.idle": "2024-05-26T16:28:20.643179Z",
          "shell.execute_reply": "2024-05-26T16:28:20.641903Z",
          "shell.execute_reply.started": "2024-05-26T16:26:28.761351Z"
        },
        "id": "5vMqv6JI4PhJ",
        "trusted": true,
        "outputId": "bbf9fe4d-1205-403a-9d9b-855db82eac85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 175/175 [01:51<00:00,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Validation Loss: 3.267399832861764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "total_val_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(valid_dataloader, desc=\"Validating\"):\n",
        "        ids = batch['ids']\n",
        "        mask = batch['mask']\n",
        "        token_type_ids = batch['token_type_ids']\n",
        "        start_idx = batch['start_idx']\n",
        "        end_idx = batch['end_idx']\n",
        "        outputs = model(input_ids=ids.to('cuda:1'), attention_mask=mask.to('cuda:1'), token_type_ids=token_type_ids.to('cuda:1'),\n",
        "                        start_positions=start_idx.to('cuda:1'), end_positions=end_idx.to('cuda:1'))\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "avg_val_loss = total_val_loss / len(valid_dataloader)\n",
        "print(f\"Average Validation Loss: {avg_val_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WUmOK5XA_hX"
      },
      "source": [
        "### *QA*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:28:20.645726Z",
          "iopub.status.busy": "2024-05-26T16:28:20.645367Z",
          "iopub.status.idle": "2024-05-26T16:28:21.660215Z",
          "shell.execute_reply": "2024-05-26T16:28:21.659290Z",
          "shell.execute_reply.started": "2024-05-26T16:28:20.645692Z"
        },
        "id": "Pi03S_uBBCoP",
        "trusted": true,
        "outputId": "96024a93-513a-40ab-c1a0-25202abf688e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file bert_qa_model_1_epoch/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert_qa_model_1_epoch\",\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file bert_qa_model_1_epoch/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert_qa_model_1_epoch\",\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.39.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file bert_qa_model_1_epoch/model.safetensors\n",
            "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
            "\n",
            "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at bert_qa_model_1_epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n"
          ]
        }
      ],
      "source": [
        "model_path = f'bert_qa_model_{epochs}_epoch'\n",
        "tokenizer_path = f'bert_qa_tokenizer_{epochs}_epoch'\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model_path, tokenizer=tokenizer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-26T16:28:21.662055Z",
          "iopub.status.busy": "2024-05-26T16:28:21.661654Z",
          "iopub.status.idle": "2024-05-26T16:28:22.935959Z",
          "shell.execute_reply": "2024-05-26T16:28:22.934261Z",
          "shell.execute_reply.started": "2024-05-26T16:28:21.662017Z"
        },
        "id": "X08NgVj8BPlE",
        "trusted": true,
        "outputId": "2f76253f-8f51-47a4-ce72-a4e7cb8065b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:  Which species of trees is larger Dryopteris or Gymnocladus?\n",
            "Real answer:  Dryopteris\n",
            "Model answer: γυμνὀς, \"gymnos\", naked +\n",
            "Score: 0.0004162282857578248\n",
            "Start index: 48\n",
            "End index: 73\n",
            "\n",
            "Question:  Which host of Sunday Night Safran has the hebrew first name Yehoshua?\n",
            "Real answer:  John Safran\n",
            "Model answer: J, about \"religion, politics and all things ethnic.\" It was\n",
            "Score: 0.00015899456047918648\n",
            "Start index: 112\n",
            "End index: 171\n",
            "\n",
            "Question:  Both the 2010–11 UEFA Champions League knockout phase  and 011 UEFA Champions League Final were held at what London stadium?\n",
            "Real answer:  Wembley\n",
            "Model answer: winners received the European Champion Clubs' Cup (\n",
            "Score: 5.7953457144321874e-05\n",
            "Start index: 236\n",
            "End index: 287\n",
            "\n",
            "Question:  What was the first manufactured fiber?\n",
            "Real answer:  rayon\n",
            "Model answer: succession of new synthetic fibers were introduced by the chemicals industry in the following decades\n",
            "Score: 6.36753611615859e-05\n",
            "Start index: 317\n",
            "End index: 418\n",
            "\n",
            "Question:  What was the title of the article Nasser wrote for his school paper?\n",
            "Real answer:  Voltaire, the Man of Freedom\n",
            "Model answer: Masria school. He took\n",
            "Score: 4.63686665170826e-05\n",
            "Start index: 113\n",
            "End index: 135\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for idx, example in try_data.iterrows():\n",
        "    question = example['question']\n",
        "    context = example['context']\n",
        "    answer = example['answers']\n",
        "    result = qa_pipeline(context=context, question=question)\n",
        "    print(\"Question: \", question)\n",
        "    print(\"Real answer: \", answer)\n",
        "    print(\"Model answer:\", result['answer'])\n",
        "    print(\"Score:\", result['score'])\n",
        "    print(\"Start index:\", result['start'])\n",
        "    print(\"End index:\", result['end'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtTgoimi_kvu"
      },
      "source": [
        "# Conclusions\n",
        "In the Baseline Model IRRR provided with the data the average F1 is 59.3 </br>\n",
        "While T5 model has F1 equal to 80.3 but its value is normalized on the number of predictions made, which is only 7000 due to hardware and time restrictions. </br>\n",
        "For BERT we couldn't reach good results because we were able to learn the model only for one epoch so at the end we got loss equal to 3.27 which is incredibly high. </br>\n",
        "QA examples explicitly show us that T5 model deals well with answering but BERT no.   "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4823666,
          "sourceId": 8154870,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5042562,
          "sourceId": 8459623,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}